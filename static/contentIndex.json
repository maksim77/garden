{"index":{"title":"index","links":["notes/Development/YandexGPT-в-Obsidian-TextGenerator","notes/Development/OpenTelemetry","notes/Development/00_GRPC","notes/Development/Thrift","notes/Development/SSL-on-PostgreSQL","notes/Development/Логическая-репликация-PostgreSQL","notes/Development/Apache-Kafka","notes/Development/Работа-с-teleport","notes/Development/Запуск-LogSeq-в-Ubuntu","notes/Development/kerberos","notes/Development/Locate-в-MacOS","notes/Development/Как-посчитать-количество-планок-памяти-в-Linux","notes/Development/Настройка-WireGuard","notes/Development/WebDAV","tags/reference/kubernetes","notes/Development/microk8s","notes/Development/Krew","notes/Development/konfig","tags/reference/git","notes/Development/Squash-commit-in-git","notes/Development/Частичный-коммит-изменений-файла-в-git","notes/Development/GitHub-issue-search","notes/Development/Neo4j","notes/Development/00_DaVinci-Resolve","notes/Development/Git-user-checks","notes/Development/Draft-actions","notes/Personal/Casio-AW-81"],"tags":["reference/kubernetes","reference/git"],"content":"Добро пожаловать в ещё один цифровой садик.\nПо сути это небольшой кусочек моего Obsidian доступный всем. Большинство заметок здесь я специально не готовил к публикации и они видны “как есть”, что означает местами специфическое форматирование или хвосты каких-то плагинов которые не видны в интерфейсе Quartz.\nTech &amp; Dev\n\nYandexGPT в Obsidian TextGenerator\nOpenTelemetry - мои заметки по работе с OTEL.\nGRPC\nThrift\nPostgreSQL\n\nSSL on PostgreSQL\nЛогическая репликация PostgreSQL\n\n\nApache Kafka\nРабота с teleport\nЗапуск LogSeq в Ubuntu\nРабота с kerberos\nLocate в MacOS\nКак посчитать количество планок памяти в Linux\nНастройка WireGuard\nНастройка WebDAV на nginx\nkubernetes\n\nmicrok8s\nKrew\nkonfig\n\n\ngit\n\nSquash commit in git\nЧастичный коммит изменений файла в git\nGitHub issue search\n\n\nNeo4j\n\n\n\nDaVinci Resolve\nGit user checks\nDraft actions\n\nOther\n\nНастройка времени на Casio AW-81\n"},"notes/Development/00_DaVinci-Resolve":{"title":"00_DaVinci Resolve","links":["notes/Development/00_DaVinci-Resolve","notes/Development/Базовое-редактирование-видео","notes/Development/Ключевые-точки","notes/Development/Цветокоррекция","notes/Development/Синхронизация-двух-камер","notes/Development/Картинка-в-картинке","notes/Development/Добавление-фона-для-вертикального-видео"],"tags":[],"content":"00_DaVinci Resolve\n\nБазовое редактирование видео\nКлючевые точки\nЦветокоррекция\nСинхронизация двух камер\nКартинка в картинке\nДобавление фона для вертикального видео\n"},"notes/Development/00_GRPC":{"title":"00_GRPC","links":["notes/Development/00_GRPC","notes/Development/Установка-GRPC-в-Golang","notes/Development/Компиляция-proto-файла-для-Golang","notes/Development/Подключение-к-GRPC-server'у","notes/Development/Создание-перехватчика-GRPC","notes/Development/GRPC-Reflection","notes/Development/Thrift"],"tags":["reference/golang"],"content":"00_GRPC\n\nУстановка GRPC в Golang\nКомпиляция proto файла для Golang\nПодключение к GRPC server’у\nСоздание перехватчика GRPC\nGRPC Reflection\n\nFriend:: Thrift"},"notes/Development/00_Swagger--and--OpenAPI":{"title":"00_Swagger & OpenAPI","links":["notes/Development/00_Swagger--and--OpenAPI","notes/Development/Install-swagger-on-Mac-OS","notes/Development/Компиляция-swagger-для-Golang"],"tags":[],"content":"00_Swagger &amp; OpenAPI\n\nInstall swagger on Mac OS\nКомпиляция swagger для Golang\n"},"notes/Development/Apache-Kafka":{"title":"Apache Kafka","links":["notes/Development/Apache-Kafka","notes/Development/Topic","notes/Development/ZooKeeper","notes/Development/Работа-с-Kafka-в-Golang","notes/Development/Kafka-Connect","notes/Development/RedPanda"],"tags":[],"content":"Apache Kafka\nApache Kafka — это распределенная платформа потоковой обработки, которая позволяет обрабатывать и передавать потоки данных в реальном времени с высокой пропускной способностью и низкой задержкой. Она используется для сбора, хранения и обработки сообщений, а также для обеспечения надежной передачи данных между различными системами и приложениями.\n\n\n                  \n                  Брокер (Broker) \n                  \n                \n\nБрокер — это отдельный сервер в кластере Kafka, который отвечает за хранение сообщений, их обработку и передачу. Брокеры работают совместно, образуя распределенную систему, которая обеспечивает высокую доступность и отказоустойчивость.\n\n\n\n\n                  \n                  Топик (Topic) \n                  \n                \n\nТопик Topic — это логический канал, по которому передаются сообщения в Kafka. Каждый топик имеет уникальное имя и может содержать множество сообщений. Топики используются для разделения потоков данных на логические категории, что упрощает их обработку и управление.\n\n\n\n\n                  \n                  Партиция (Partition) \n                  \n                \n\nПартиция — это часть топика, которая распределяется по брокерам. Каждый топик может состоять из одной или нескольких партиций, что позволяет распределить нагрузку и обеспечить параллельную обработку сообщений. Партиции обеспечивают горизонтальное масштабирование и улучшают производительность системы.\n\n\n\n\n                  \n                  Фактор репликации (Replication Factor) \n                  \n                \n\nФактор репликации — это количество копий партиции, которые создаются и хранятся в кластере. Например, если фактор репликации равен 3, то каждая партиция будет иметь три копии, распределенные по разным брокерам. Фактор репликации определяет уровень отказоустойчивости и надежности данных: чем выше фактор репликации, тем больше брокеров могут выйти из строя без потери данных, но при этом увеличивается нагрузка на кластер.\n\n\nZookeeper\nВ кластере Apache Kafka, ZooKeeper выполняет роль координатора, который управляет конфигурацией и состоянием кластера. Основные функции ZooKeeper включают:\n\nУправление конфигурацией: ZooKeeper хранит метаданные о брокерах, топиках и партициях, что позволяет Kafka динамически обновлять конфигурацию и перераспределять нагрузку.\nОбнаружение отказов: ZooKeeper отслеживает состояние брокеров и уведомляет остальные компоненты кластера о любых сбоях, что позволяет Kafka быстро реагировать на отказы и восстанавливать работу.\nВыбор лидера партиций: ZooKeeper помогает выбрать лидера для каждой партиции, что важно для обеспечения консистентности данных и отказоустойчивости.\n\nВ более новых версиях Kafka (начиная с версии 2.8) появилась возможность работы без ZooKeeper, используя собственный механизм управления состоянием кластера, называемый KRaft. Однако, в большинстве существующих установок Kafka по-прежнему используется ZooKeeper для управления кластером.\n\nРабота с Kafka в Golang\nKafka Connect\nRedPanda\n"},"notes/Development/Cypher":{"title":"Cypher","links":["notes/Development/Cypher","PublicMedia/openCypher9.pdf"],"tags":[],"content":"Cypher\n\nСоздание узлов с помощью MERGE\nЗапрос:\nMERGE (a:Person {name: $name, age: $age})\nОбъяснение:\n\nMERGE: Проверяет, существует ли узел с указанными свойствами. Если не существует, создаёт его. Если существует, повторного создания не будет.\n\nMERGE Reference\n\n\n(a:Person ...): Создаётся или ищется узел с меткой Person. Метка (label) описывает тип сущности (например, Person для человека).\n{name: $name, age: $age}: Свойства узла. name и age задаются через параметры (обозначены как $name и $age), значения которых передаются из кода.\n\nСоздание уникальных связей с помощью MERGE\nЗапрос:\nMATCH (a:Person {name: $name1}), (b:Person {name: $name2})\nMERGE (a)-[:FRIENDS]-&gt;(b)\nОбъяснение:\n\nMATCH (a:Person {name: $name1}): Ищет узел с меткой Person, у которого свойство name равно значению параметра $name1. Этот узел связывается с переменной a.\n\nMATCH Reference\n\n\nMATCH (b:Person {name: $name2}): Аналогично, ищет узел Person с именем $name2 и связывает его с переменной b.\nMERGE (a)-[:FRIENDS]-&gt;(b): Проверяет, существует ли связь FRIENDS от узла a к узлу b. Если такая связь существует, ничего не делает. Если не существует, создаёт её.\n[:FRIENDS]: Определяет тип связи. В данном случае это “дружба”.\n-&gt;: Направление связи. Стрелка указывает, что a дружит с b.\n\nПоиск друзей конкретного человека\nЗапрос:\nMATCH (a:Person {name: $name})-[:FRIENDS]-&gt;(friend)\nRETURN friend.name AS name, friend.age AS age\nОбъяснение:\n\nMATCH (a:Person {name: $name}): Ищет узел Person с именем, равным значению $name. Этот узел связывается с переменной a.\n-[:FRIENDS]-&gt;(friend): Находит все узлы, связанные с узлом a связью типа FRIENDS. Эти узлы связываются с переменной friend.\nRETURN friend.name AS name, friend.age AS age: Возвращает свойства найденных узлов:\n\nfriend.name — имя друга.\nfriend.age — возраст друга.\nRETURN Reference\n\n\nAS используется для задания алиасов, чтобы упростить доступ к возвращённым данным.\n\nПоиск кратчайшего пути между двумя людьми\nЗапрос:\nMATCH p = shortestPath((a:Person {name: $start})-[:FRIENDS*]-(b:Person {name: $end}))\nRETURN p\nОбъяснение:\n\nMATCH p = shortestPath(...): Начинает поиск пути, который будет присвоен переменной p. Функция shortestPath ищет наименьшее количество связей между узлами.\n(a:Person {name: $start}): Ищет узел с меткой Person, у которого свойство name равно значению параметра $start. Этот узел связывается с переменной a.\n-[:FRIENDS*]-: Находит любые связи типа FRIENDS (обозначенные *, что означает “любое количество связей”) между узлом a и узлом b. Направление связи не имеет значения благодаря использованию -.\n(b:Person {name: $end}): Ищет узел с меткой Person, у которого свойство name равно значению параметра $end. Этот узел связывается с переменной b.\nRETURN p: Возвращает найденный путь p, который представляет собой последовательность узлов и связей от a до b.\n\nПоиск самого длинного пути между двумя людьми\nЗапрос:\nMATCH p = (a:Person {name: $start})-[:FRIENDS*]-(b:Person {name: $end})\nRETURN p, length(p) AS pathLength\nORDER BY pathLength DESC\nLIMIT 1\nОбъяснение:\n\nMATCH p = (...): Начинает поиск пути, который будет присвоен переменной p.\n(a:Person {name: $start}): Ищет узел с меткой Person, у которого свойство name равно значению параметра $start. Этот узел связывается с переменной a.\n-[:FRIENDS*]-: Находит любые связи типа FRIENDS между узлом a и узлом b, независимо от их направления.\n(b:Person {name: $end}): Ищет узел с меткой Person, у которого свойство name равно значению параметра $end. Этот узел связывается с переменной b.\nRETURN p, length(p) AS pathLength: Возвращает найденный путь p и длину этого пути, которая определяется количеством связей (length(p)), присваивая результат алиасу pathLength.\nORDER BY pathLength DESC: Сортирует результаты по длине пути в порядке убывания, чтобы самые длинные пути шли первыми.\nLIMIT 1: Ограничивает результат одним самым длинным путем.\n"},"notes/Development/Deployment":{"title":"Deployment","links":["notes/Development/Deployment","notes/Development/Pod","notes/Development/ReplicaSet"],"tags":["reference/kubernetes"],"content":"Deployment\nDeployment это ресурс Kubernetes представляющий собой абстракцию над Pod и ReplicaSet.\nUse Cases\n\nАвтоматическое декларативное создание ReplicaSet.\nОбновление спецификаций Pod и пересоздание RS\nОткат к предыдущему состоянию в случае не стабильной работы нового (хранится несколько последних версий развертывания).\nМасштабирование количества подов.\nВозможность поставить rollout update на паузу.\n\nСоздание Deployment\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-container\n        image: my-image:latest"},"notes/Development/Draft-actions":{"title":"Draft actions","links":["notes/Development/Draft-actions"],"tags":[],"content":"Draft actions\nI really like the Draft app, and I have written a number of actions for it. I wrote them for myself, but some of them seemed interesting enough for me to share with everyone.\n\nMastodon Reply - simple action that allows you to reply to Mastodon toot directly from within Draft.\nCalendar - this action takes all of today’s events from the calendar and creates a markdown for Obsidian Daily Notes.\n"},"notes/Development/GRPC-Reflection":{"title":"GRPC Reflection","links":["notes/Development/GRPC-Reflection"],"tags":["reference/golang"],"content":"GRPC Reflection\nСуществует возможность получать список методов, узнавать описания сообщений и даже вызывать методы с помощью утилиты командной строки grpc_cli.\nСборка утилиты\n\nКлонировать grpc репозиторий\ngit submodule update --init\nmkdir -p cmake/build\ncd cmake/build\ncmake -DgRPC_BUILD_TESTS=ON ../..\nmake grpc_cli\n\nНастройка севера для работы с reflection\nimport &quot;google.golang.org/grpc/reflection&quot;\n \ns := grpc.NewServer()\nreflection.Register(s)"},"notes/Development/Git-user-checks":{"title":"Git user checks","links":["notes/Development/Git-user-checks"],"tags":[],"content":"Git user checks\n\nVSCode Marketplace\nGitHub\n\nSometimes, after cloning a repository from a corporate git server and sending several commits to it, you realize that you forgot to change the user settings in git.\nThis extension was written to avoid that.\nYou only need to define three parameters. The first is the domain that the extension will look for in the origin section of the repository that you opened in VSCode.\nThe other two are user settings that need to be set for the repository cloned from the domain specified in the first paragraph.\n\nThat’s it! The extension will warn you that you are working with a repository for which user settings should be set (if they are not already set). Clicking the “Overwrite” button will automatically add the necessary parameters to the git settings of the current project.\n"},"notes/Development/GitHub-issue-search":{"title":"GitHub issue search","links":["notes/Development/GitHub-issue-search"],"tags":["reference/git"],"content":"GitHub issue search\nДля того чтобы найти все комментарии к issue которые оставил пользователь можно использовать директиву поиска involves. Например так: is:issue involves:maksim77"},"notes/Development/Install-swagger-on-Mac-OS":{"title":"Install swagger on Mac OS","links":["notes/Development/Install-swagger-on-Mac-OS"],"tags":[],"content":"Install swagger on Mac OS\nbrew install swagger-codegen"},"notes/Development/Kafka-Connect":{"title":"Kafka Connect","links":["notes/Development/Kafka-Connect"],"tags":[],"content":"Kafka Connect\nЗапуск сервиса\nВ папке дистриубтива Kafka есть скрипт ./bin/connect-standalone.sh который надо запустить указав путь до файла конфига в формате properties:\nbootstrap.servers=127.0.0.1:29092,127.0.0.1:39092,127.0.0.1:49092\ngroup.id=myconnect\n \nkey.converter=org.apache.kafka.connect.json.JsonConverter\nvalue.converter=org.apache.kafka.connect.json.JsonConverter\n \noffset.storage.topic=connector_offset\noffset.storage.file.filename=offset\nconfig.storage.topic=connector_config\nstatus.storage.topic=connector_status\nДрайвер MongoDB Connect\nДокументация: www.mongodb.com/docs/kafka-connector/current/introduction/install/\nMaven: central.sonatype.com/artifact/org.mongodb.kafka/mongo-kafka-connect\nJar файл архива надо положить в паку libs дистрибутива Kafka.\nСоздать коннектор\nhttp POST http://localhost:8083/connectors @mongodb.json\nгде mongodb.json:\n{&quot;name&quot;: &quot;mongo-source&quot;,\n &quot;config&quot;: { &quot;connector.class&quot;:&quot;com.mongodb.kafka.connect.MongoSourceConnector&quot;,\n     &quot;connection.uri&quot;:&quot;mongodb://localhost:27017&quot;,\n     &quot;database&quot;:&quot;strava&quot;,\n     &quot;collection&quot;:&quot;workout&quot;,\n     &quot;copy.existing&quot;: true\n }\n}"},"notes/Development/Krew":{"title":"Krew","links":[],"tags":["reference/kubernetes"],"content":"Krew\nМенеджер плагинов для kubectl.\nGitHub\nДокументация\nУстановка\n\nДля установки необходим git\nВыполнить эту команду в консоли\n\n(\n  set -x; cd &quot;$(mktemp -d)&quot; &amp;&amp;\n  OS=&quot;$(uname | tr &#039;[:upper:]&#039; &#039;[:lower:]&#039;)&quot; &amp;&amp;\n  ARCH=&quot;$(uname -m | sed -e &#039;s/x86_64/amd64/&#039; -e &#039;s/\\(arm\\)\\(64\\)\\?.*/\\1\\2/&#039; -e &#039;s/aarch64$/arm64/&#039;)&quot; &amp;&amp;\n  KREW=&quot;krew-${OS}_${ARCH}&quot; &amp;&amp;\n  curl -fsSLO &quot;github.com/kubernetes-sigs/krew/releases/latest/download/${KREW}.tar.gz&quot; &amp;&amp;\n  tar zxvf &quot;${KREW}.tar.gz&quot; &amp;&amp;\n  ./&quot;${KREW}&quot; install krew\n)\n\nДобавить путь $HOME/.krew/bin в $PATH.\nЗапустить kubectl krew чтобы проверить, что всё нормально.\n"},"notes/Development/Locate-в-MacOS":{"title":"Locate в MacOS","links":["notes/Development/Locate-в-MacOS"],"tags":["reference/macos"],"content":"Locate в MacOS\nАналог линуксового updatedb: sudo /usr/libexec/locate.updatedb"},"notes/Development/Neo4j":{"title":"Neo4j","links":["notes/Development/Neo4j","notes/Development/Cypher","notes/Development/neo4j-в-Golang"],"tags":[],"content":"Neo4j\nNeo4j — это графовая база данных, которая позволяет хранить и обрабатывать данные в виде графов. В отличие от традиционных реляционных баз данных, Neo4j использует узлы (nodes) и связи (relationships) для представления информации, что делает её особенно эффективной для работы с сложными взаимосвязями между данными.\nС помощью языка запросов Cypher пользователи могут легко выполнять операции по извлечению, обновлению и анализу данных. Neo4j находит широкое применение в различных областях, таких как анализ социальных сетей, управление логистикой, рекомендации и многие другие приложения, где важны связи между объектами.\nDocker\nКоманда запуска сервера в Docker для локальной разработки:\n \ndocker run -d --name neo4j -p7474:7474 -p7687:7687 -e NEO4J_AUTH=neo4j/password neo4j\n \n\nНа порту 7474 будет доступен веб интерфейс Neo4j: http://localhost:7474\nПорт 7687 используется для подключения к базе данных через Bolt-протокол.\nПро Bolt можно детальнее почитать тут.\n\nChildren:: neo4j в Golang"},"notes/Development/OTEL-Baggage.-Golang":{"title":"OTEL Baggage. Golang","links":["notes/Development/OTEL-Baggage.-Golang"],"tags":["reference/golang"],"content":"OTEL Baggage. Golang\nb, _ := baggage.NewMember(&quot;key&quot;, &quot;value&quot;)\nbag, _ := baggage.New(b)\nctx = baggage.ContextWithBaggage(ctx, bag)\nИсходный контекст в этом примере мог быть создан например при старте нового span’а. И если потом сделать его Inject то он передастся как http заголовок:\notel.GetTextMapPropagator().Inject(ctx, propagation.HeaderCarrier(w.Header()))\nИзвлечение пришедшей таким образом информации:\nctx := otel.GetTextMapPropagator().Extract(r.Context(), propagation.HeaderCarrier(r.Header))\n \nbag := baggage.FromContext(ctx)\n_, span := tracer.Start(ctx, &quot;second&quot;)\ndefer span.End() \nfmt.Println(bag.Member(&quot;key&quot;).Value())\n\n\n                  \n                  TextMapPropogator \n                  \n                \n\nВажно при объявлении TextMapPropogator использовать следующую структуру: otel.SetTextMapPropagator(propagation.NewCompositeTextMapPropagator(propagation.TraceContext{}, propagation.Baggage{})).\n\n"},"notes/Development/OTEL-initialization":{"title":"OTEL initialization","links":["notes/Development/OTEL-initialization","notes/Development/Инициализация-OTEL-в-go","notes/Development/Базовая-настройка-OTEL-для-работы-с-Jaeger"],"tags":[],"content":"OTEL initialization\n\nChildren:: Инициализация OTEL в go\nChildren:: Базовая настройка OTEL для работы с Jaeger\n"},"notes/Development/OTEL-and-Jaeger-local-dev":{"title":"OTEL&Jaeger local dev","links":["notes/Development/OTEL-and-Jaeger-local-dev"],"tags":[],"content":"OTEL&amp;Jaeger local dev\nDocker compose\nversion: &#039;3.8&#039;\n \nservices:\n  otel-collector:\n    image: otel/opentelemetry-collector:latest\n    container_name: otel-collector\n    command: [&quot;--config=/etc/otel-collector-config.yaml&quot;]\n    volumes:\n      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml\n    ports:\n      - &quot;4317:4317&quot;  # OTLP gRPC receiver\n      - &quot;4318:4318&quot;  # OTLP HTTP receiver\n      - &quot;55679:55679&quot;  # Prometheus exporter\n      - &quot;8889:8889&quot;\n    depends_on:\n      - jaeger\n \n  jaeger:\n    image: jaegertracing/all-in-one:latest\n    container_name: jaeger\n    environment:\n      - COLLECTOR_OTLP_ENABLED=true\n      - COLLECTOR_OTLP_GRPC_HOST-PORT=:4317\n      - COLLECTOR_OTLP_GRPC_HOST_PORT=:4317\n    ports:\n      - &quot;16686:16686&quot;\n      # - &quot;4317:4317&quot;\n \notel-collector-config.yaml\nreceivers:\n  otlp:\n    protocols:\n      grpc:\n        endpoint: 0.0.0.0:4317\n \nprocessors:\n  batch:\n  attributes:\n    actions:\n      - key: solObjectID\n        value: &quot;7652&quot;\n        action: upsert\n      - key: imsSystemID\n        value: &quot;DataOps Data Virtualization&quot;\n        action: upsert\nexporters:\n  otlp:\n    endpoint: &quot;http://jaeger:4317&quot;\n    tls:\n      insecure: true\n  debug:\n    verbosity: detailed\n  prometheus:\n    endpoint: 0.0.0.0:8889\nservice:\n  pipelines:\n    traces:\n      receivers: [otlp]\n      processors: [attributes]\n      exporters: [otlp]\n    metrics:\n      receivers: [otlp]\n      processors: []\n      exporters: [prometheus]\n    logs:\n      receivers: [otlp]\n      processors: [batch]\n      exporters: [debug]\n \nУстарело\nЗапуск локального Jaeger для тестов:\ndocker run -p 16686:16686 -p 14250:14250 -p 4317:4317 -p 14268:14268 jaegertracing/all-in-one:latest\nили то же самое но с поддержкой OTLP протокола:\nversion: &quot;3.9&quot;\nservices:\n  jaeger:\n    image: &quot;jaegertracing/all-in-one:1.38&quot;\n    environment:\n      - COLLECTOR_OTLP_ENABLED=true\n    ports:\n      - 4317:4317\n      - 4318:4318\n      - 16686:16686"},"notes/Development/OTEL.-Golang":{"title":"OTEL. Golang","links":["notes/Development/OTEL.-Golang","notes/Development/Инициализация-OTEL-в-go","notes/Development/Автоматическое-инструментирование-http.Handler-OTEL","notes/Development/Проброс-span-через-HTTP-в-Opentelemetry","notes/Development/Проброс-span-Opentelemetry-через-текстовое-поле","notes/Development/OTEL-Baggage.-Golang","notes/Development/Базовая-настройка-OTEL-для-работы-с-Jaeger","notes/Development/Инструментирование-OTEL-MongoDB","notes/Development/Инструментирование-OTEL-Redis-(KeyDB)","notes/Development/Инструментирование-OTEL-neo4j"],"tags":["reference/golang"],"content":"OTEL. Golang\n\nChildren:: Инициализация OTEL в go\nChildren:: Автоматическое инструментирование http.Handler OTEL\nChildren:: Проброс span через HTTP в Opentelemetry\nChildren:: Проброс span Opentelemetry через текстовое поле\nChildren:: OTEL Baggage. Golang\nChildren:: Базовая настройка OTEL для работы с Jaeger\n\nИнструментирование сервисов\n\nChildren:: Инструментирование OTEL MongoDB\nChildren:: Инструментирование OTEL Redis (KeyDB)\nChildren:: Инструментирование OTEL neo4j\n"},"notes/Development/OTEL.-Java":{"title":"OTEL. Java","links":["notes/Development/OTEL.-Java"],"tags":[],"content":"OTEL. Java\nSource:: github.com/open-telemetry/opentelemetry-java-examples/tree/main"},"notes/Development/OpenTelemetry-Baggage":{"title":"OpenTelemetry Baggage","links":["notes/Development/OpenTelemetry-Baggage","notes/Development/OTEL-Baggage.-Golang"],"tags":[],"content":"OpenTelemetry Baggage\nЕсли возникает ситуация при которой вместо с trace’ом необходимо передать так же и некую метаинформацию Open Telemetry предлагает использовать механизм Baggage.\nПо сути baggage это способ передать key-value пары (возможно с некоторыми дополнительными свойствами) независимым от платформы способом. Точно так же как мы извлекаем информацию о span можно извлечь информацию о таких парах.\nChild:: OTEL Baggage. Golang\nSource:: opentelemetry.io/docs/concepts/signals/baggage/"},"notes/Development/OpenTelemetry-в-K8S":{"title":"OpenTelemetry в K8S","links":["notes/Development/OpenTelemetry-в-K8S","notes/Development/Инициализация-OTEL-в-go","notes/Development/Deployment"],"tags":["reference/kubernetes"],"content":"OpenTelemetry в K8S\nОписание\nOpenTelemetry Operator позволяет:\n\nСоздавать инстансы opentelemetrycollector в различных режимах.\nСоздавать шаблон sidecar контейнера который будет запущен в тех подах на которые повесим нужную аннотацию.\nСоздавать объекты instrumentation которые (при соответствующей аннотации) автоматически настроят код сервиса на работу с otel.\n\nУстановка\ncert-manager\nkubectl apply -f github.com/cert-manager/cert-manager/releases/download/v1.13.2/cert-manager.yaml\nOpenTelemetry Operator\nkubectl apply -f github.com/open-telemetry/opentelemetry-operator/releases/latest/download/opentelemetry-operator.yaml \nJaeger\nЭто лишь бэкенд для хранения метрик. Можно настроить любую другую систему\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: opentelemetry\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: jaeger-all-in-one\n  namespace: opentelemetry\n  labels:\n    app: opentelemetry\n    component: otel-collector\nspec:\n  ports:\n    - port: 4317\n      protocol: TCP\n      targetPort: grpc\n  selector:\n    component: otel-collector\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: jaeger-all-in-one-ui\n  namespace: opentelemetry\n  labels:\n    app: opentelemetry\n    component: otel-collector\nspec:\n  ports:\n    - name: jaeger\n      port: 16686\n      protocol: TCP\n      targetPort: 16686\n  selector:\n    component: otel-collector\n  type: LoadBalancer\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger-all-in-one\n  namespace: opentelemetry\n  labels:\n    app: opentelemetry\n    component: otel-collector\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: opentelemetry\n      component: otel-collector\n  template:\n    metadata:\n      labels:\n        app: opentelemetry\n        component: otel-collector\n    spec:\n      containers:\n        - image: jaegertracing/all-in-one:1.52\n          name: jaeger\n          ports:\n            - containerPort: 16686\n            - containerPort: 14268\n            - containerPort: 14250\n            - containerPort: 4317\n              name: grpc\nOtelcoll\nЭтот коллектор otel в текущем примере будет являться общим шлюзом получающим данные от sidecar контейнеров. Таким образом достаточно поменять лишь его настройки, а основную систему не трогать.\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  name: otel-collector\n  namespace: opentelemetry\n  labels:\n    app: opentelemetry\n    component: otel-collector\nspec:\n  ports:\n    - port: 4318\n      name: &quot;grpc&quot;\n  config: |\n    receivers:\n      otlp:\n        protocols:\n          grpc:\n          http:\n    exporters:\n      otlp:\n        endpoint: jaeger-all-in-one.opentelemetry.svc.cluster.local:4317\n        tls:\n          insecure: true\n      logging:\n    processors:\n      batch:\n      resource:\n        attributes:\n          - key: test.key\n            value: &quot;test-value&quot;\n            action: insert\n    extensions:\n      health_check:\n      zpages:\n        endpoint: :55679\n    service:\n      telemetry:\n        logs:\n          level: &quot;debug&quot;\n      extensions: [zpages, health_check]\n      pipelines:\n        traces:\n          receivers: [otlp]\n          processors: [batch, resource]\n          exporters: [logging, otlp]\nSIdecar\nЭто в своём роде шаблон контейнера который будет запускаться внутри каждого пода имеющего соответствующую аннотацию.\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  name: sidecar\nspec:\n  mode: sidecar\n  config: |\n    receivers:\n      otlp:\n        protocols:\n          grpc:\n          http:\n    processors:\n      batch:\n    exporters:\n      logging:\n      otlp:\n        endpoint: &quot;otel-collector-collector.opentelemetry.svc.cluster.local:4317&quot;\n        tls:\n          insecure: true\n    service:\n      telemetry:\n        logs:\n          level: &quot;debug&quot;\n      pipelines:\n        traces:\n          receivers: [otlp]\n          processors: []\n          exporters: [logging, otlp]\nInstrumentation\nРесурс k8s, что определяет настройки otel которые будут вставлены в запущенный сервис. Иными словами например Инициализация OTEL в go не требуется. Достаточно создать такой объект и повесить нужные аннотации.\napiVersion: opentelemetry.io/v1alpha1\nkind: Instrumentation\nmetadata:\n  name: demo-instrumentation\nspec:\n  propagators:\n    - tracecontext\n    - baggage\n  sampler:\n    type: parentbased_traceidratio\n    argument: &quot;1&quot;\nАннотации сервиса\n\nsidecar.opentelemetry.io/inject: &quot;sidecar&quot; - подключит в pod sidecar.\ninstrumentation.opentelemetry.io/inject-java: &quot;true&quot; - подключит код внутрь запущенного сервиса. На GolangS у меня не завелось\n\nDeployment целиком\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rules-generator\n  labels:\n    app: rules-generator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rules-generator\n  template:\n    metadata:\n      labels:\n        app: rules-generator\n      annotations:\n        sidecar.opentelemetry.io/inject: &quot;sidecar&quot;\n        instrumentation.opentelemetry.io/inject-java: &quot;true&quot;\n    spec:\n      containers:\n        - name: rules-generator\n          image: maksim77/rules:0.0.1\n          ports:\n            - containerPort: 12346\n            - containerPort: 9999\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: rules-generator-service\n  labels:\n    app: rules-generator\nspec:\n  selector:\n    app: rules-generator\n  type: NodePort\n  ports:\n    - protocol: TCP\n      port: 9999\n      targetPort: 9999"},"notes/Development/OpenTelemetry":{"title":"OpenTelemetry","links":["notes/Development/OpenTelemetry","notes/Development/OTEL-and-Jaeger-local-dev","notes/Development/OTEL-initialization","notes/Development/OTEL.-Golang","notes/Development/OTEL.-Java","notes/Development/Структура-HTTP-Header-трэйсинга","notes/Development/OpenTelemetry-Baggage","notes/Development/OpenTelemetry-в-K8S","notes/Development/Observability-local-stand"],"tags":[],"content":"OpenTelemetry\n\n\nChildren:: OTEL&amp;Jaeger local dev\nChildren:: OTEL initialization\nChildren:: OTEL. Golang\nChildren:: OTEL. Java\nChildren:: Структура HTTP Header трэйсинга\nChildren:: OpenTelemetry Baggage\nChildren:: OpenTelemetry в K8S\nChildren:: Observability local stand\n\nFriend:: OpenTelemetry Registry"},"notes/Development/Pod":{"title":"Pod","links":["notes/Development/Pod"],"tags":["reference/kubernetes"],"content":"Pod\nPod — это базовая единица вычислений в Kubernetes, представляющая собой группу одно или несколько контейнеров, которые запускаются на одном узле. Эти контейнеры разделяют ресурсы, такие как сеть и хранилище, и могут быть сконфигурированы для взаимодействия друг с другом в рамках одного окружения Pod. Каждый Pod имеет уникальный IP-адрес в рамках кластера, что позволяет контейнерам в его составе обмениваться данными через localhost.\nПример манифеста создания Pod\napiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\n  labels:\n    app: my-app\nspec:\n  containers:\n  - name: my-container\n    image: nginx:latest\n    ports:\n    - containerPort: 80\nВ этом манифесте создается Pod с именем my-pod, который имеет метку app: my-app. Внутри Pod запускается контейнер с именем my-container, использующий образ nginx:latest и слушающий порт 80."},"notes/Development/RedPanda-docker-quick-start":{"title":"RedPanda docker quick start","links":["notes/Development/RedPanda-docker-quick-start"],"tags":[],"content":"RedPanda docker quick start\nname: redpanda-quickstart-one-broker\nnetworks:\n  redpanda_network:\n    driver: bridge\nvolumes:\n  redpanda-0: null\nservices:\n  redpanda-0:\n    command:\n      - redpanda\n      - start\n      - --kafka-addr internal://0.0.0.0:9092,external://0.0.0.0:19092\n      # Address the broker advertises to clients that connect to the Kafka API.\n      # Use the internal addresses to connect to the Redpanda brokers&#039;\n      # from inside the same Docker network.\n      # Use the external addresses to connect to the Redpanda brokers&#039;\n      # from outside the Docker network.\n      - --advertise-kafka-addr internal://redpanda-0:9092,external://localhost:19092\n      - --pandaproxy-addr internal://0.0.0.0:8082,external://0.0.0.0:18082\n      # Address the broker advertises to clients that connect to the HTTP Proxy.\n      - --advertise-pandaproxy-addr internal://redpanda-0:8082,external://localhost:18082\n      - --schema-registry-addr internal://0.0.0.0:8081,external://0.0.0.0:18081\n      # Redpanda brokers use the RPC API to communicate with each other internally.\n      - --rpc-addr redpanda-0:33145\n      - --advertise-rpc-addr redpanda-0:33145\n      # Mode dev-container uses well-known configuration properties for development in containers.\n      - --mode dev-container\n      # Tells Seastar (the framework Redpanda uses under the hood) to use 1 core on the system.\n      - --smp 1\n      - --default-log-level=info\n    image: docker.redpanda.com/redpandadata/redpanda:v24.2.8\n    container_name: redpanda-0\n    volumes:\n      - redpanda-0:/var/lib/redpanda/data\n    networks:\n      - redpanda_network\n    ports:\n      - 18081:18081\n      - 18082:18082\n      - 19092:19092\n      - 19644:9644\n  console:\n    container_name: redpanda-console\n    image: docker.redpanda.com/redpandadata/console:v2.7.2\n    networks:\n      - redpanda_network\n    entrypoint: /bin/sh\n    command: -c &#039;echo &quot;$$CONSOLE_CONFIG_FILE&quot; &gt; /tmp/config.yml; /app/console&#039;\n    environment:\n      CONFIG_FILEPATH: /tmp/config.yml\n      CONSOLE_CONFIG_FILE: |\n        kafka:\n          brokers: [&quot;redpanda-0:9092&quot;]\n          schemaRegistry:\n            enabled: true\n            urls: [&quot;http://redpanda-0:8081&quot;]\n        redpanda:\n          adminApi:\n            enabled: true\n            urls: [&quot;http://redpanda-0:9644&quot;]\n    ports:\n      - 8080:8080\n    depends_on:\n      - redpanda-0"},"notes/Development/RedPanda":{"title":"RedPanda","links":["notes/Development/RedPanda","notes/Development/ZooKeeper","notes/Development/RedPanda-docker-quick-start"],"tags":[],"content":"RedPanda\n\nRedPanda — это современная система управления потоками данных, разработанная для обеспечения высокой производительности и низкой задержки при обработке событий. Она совместима с клиентами Apache Kafka, что позволяет использовать существующие приложения и инструменты без значительных изменений.\nОсновные отличия RedPanda от Apache Kafka:\n\nПроизводительность: RedPanda оптимизирован для работы с SSD и использует более эффективные алгоритмы, что позволяет достигать большей пропускной способности и снижать задержки.\nАрхитектура: RedPanda построена на едином процессе, что упрощает развертывание и управление по сравнению с архитектурой Kafka, которая может требовать несколько компонентов (ZooKeeper) 1\nПростота использования: RedPanda предлагает более простую настройку и управление, что делает его более доступным для разработчиков.\nСовместимость: RedPanda полностью совместим с API Kafka, что позволяет пользователям легко мигрировать или интегрировать его в существующие системы.\n\nChild:: RedPanda docker quick start\nFootnotes\n\n\nНе актуально для современных версий ↩\n\n\n"},"notes/Development/ReplicaSet":{"title":"ReplicaSet","links":["notes/Development/ReplicaSet"],"tags":["reference/kubernetes"],"content":"ReplicaSet\nReplicaSet в Kubernetes — это контроллер, который обеспечивает высокую доступность и масштабируемость приложений. Он управляет множеством одинаковых Pod’ов, обеспечивая их поддержание в заданном количестве и автоматическое восстановление в случае сбоев.\nПример манифеста ReplicaSet\napiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: my-replicaset\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-app-container\n        image: my-app:latest\n        ports:\n        - containerPort: 8080\nВ этом примере создается ReplicaSet с именем my-replicaset, который управляет тремя Pod’ами с меткой app: my-app. Каждый Pod содержит контейнер с образом my-app:latest и открывает порт 8080."},"notes/Development/SSL-on-PostgreSQL":{"title":"SSL on PostgreSQL","links":["notes/Development/SSL-on-PostgreSQL"],"tags":[],"content":"SSL on PostgreSQL\nУстановка Certbot и сертификатов\n\nПроверяем работу snap\n\nsudo snap install core; sudo snap refresh core\n\nУдаляем на всякий случай certbot если он был.\n\nsudo apt-get remove certbot\n\nУстанавливаем snap\n\nsudo snap install --classic certbot\n\nСоздаем симлинк на бианрник (не уверен зачем)\n\nsudo ln -s /snap/bin/certbot /usr/bin/certbot\n\nПолучение сертификата\n\nsudo certbot certonly --standalone -d db.mak-sim.ru\nНастройка hook’а для PG\nСоздаём файл /etc/letsencrypt/renewal-hooks/deploy/postgresql.deploy:\n #!/bin/bash\n umask 0177\n DOMAIN=db.mak-sim.ru\n DATA_DIR=/var/lib/postgresql/12/main\n cp /etc/letsencrypt/live/$DOMAIN/fullchain.pem $DATA_DIR/server.crt\n cp /etc/letsencrypt/live/$DOMAIN/privkey.pem $DATA_DIR/server.key\n chown postgres:postgres $DATA_DIR/server.crt $DATA_DIR/server.key\nDATA_DIR можно узнать выполнив команду:\nsudo -u postgres psql -U postgres -c &#039;SHOW data_directory&#039;\n\nФайлу необходимо выдать права на исполнение.\nНастройки PostgreSQL\npostgresql.conf\nВ файле postgresql.conf необходимо поправить:\n ssl = on  \n ssl_cert_file = &#039;server.crt&#039;  \n ssl_key_file = &#039;server.key&#039;  \n ssl_prefer_server_ciphers = on\n\nМестоположение файла можно узнать выпонив:\nsudo -u postgres psql -U postgres -c &#039;SHOW config_file&#039;\npg_hba.conf\nДобавляем строку\n hostssl all all 0.0.0.0/0 md5\n"},"notes/Development/Squash-commit-in-git":{"title":"Squash commit in git","links":["notes/Development/Частичный-коммит-изменений-файла-в-git"],"tags":["reference/git"],"content":"Squash commit in git\nДля того чтобы схлопнуть к последнему коммиту следующие перед ним необходимо выполнить: git rebase -i HEAD~2  где 2 это количество коммитов которые будем схлопывать. Откроется редактор:\n\nВерхний коммит следует оставить как pick, тогда как все что требуется схлопнуть надо отметить как squash или просто s. После закрытия редактора он откроется снова для создания сообщения нового коммита.\nЕсли требуется обновить удаленный репозиторий то команду git push следует выполнять с ключом —force\nFriend:: Частичный коммит изменений файла в git"},"notes/Development/Teleport-CLI":{"title":"Teleport CLI","links":["notes/Development/Teleport-CLI","Teleport-MTS","notes/Development/Teleport.-Golang"],"tags":[],"content":"Teleport CLI\nТелепорт можно установить различными способами в том числе и пакетами для OS, но так как мне требуется только авторизация для использования в коде и работа с командно строкой то проще всего скачать tar.gz файл и получить таким образом нужные бинарники.\n\n\n                  \n                  Важно \n                  \n                \n\nСначала следует узнать версию самого сервиса teleport запущенного в нашей инфре и скачать ровно ту же. Даже небольшие расхождения приводят к несовместимости API.\n\n\ntsh\nОсновная утилита для работы из CLI это tsh.\nАутентификация в teleport\n./tsh login --proxy=teleport.host --user=mylogin --skip-version-check --auth=local --ttl 5256000\n1\nTeleport MTS\nЕсли добавить ключ -o &lt;имя_файла&gt; то будет сгенерирован текстовый файл содержащий в себе все необходимые сертификаты для работы с телепортом, что потребуется позже для Teleport. Golang.\nНастройка сохраняются в ~/.tsh/. Из интересного там находится файл current-profile который указывает на активный профиль если настроено подключение более чем к одному телепорту.\nОсновные команды\nenv\n./tsh env --proxy teleport.***:443\nвыведет список переменных которые надо задать для работы с этим proxy.\nls\nВыводит список доступных через этот proxy хостов.\n❯ ./tsh ls --proxy teleport.***.ru:443\n \nNode Name                                                     Address    Labels                                                                                                                                                                \n------------------------------------------------------------- ---------- --------------------------------------------------------------------------------------------------------------------------------------------------------------------- \nklktest-ch-1.******.******.mts.ru ⟵ Tunnel   bios=c4b72c42-29c3-d71d-0a16-954d87a1a037,clickhouse-l3=true,hostname=klktest-ch-1,paas-l1=true,stand_slug=****-unix-inside-0300s2,type=dataops,unix-admin=true \nРезультаты поиска можно фильтровать:\n./tsh ls --proxy teleport.***.ru:443 --query=&#039;labels[&quot;type&quot;] == &quot;dataops&quot;&#039;\nВнутри одинарных кавычек фильтра допускаются следующие операторы ==, !=, &amp;&amp; и ||.\nssh\nПозволяет подключиться к хосту за телепортом. Например так:\n./tsh ssh user@&lt;some_host_from_tsh_ls&gt;.ru\nconfig\nПокажет кусочек конфига ~/.ssh/config который если туда добавить по идее позволит исползьзовать для телепорт хостов обычный ssh вместо ./tsh ssh. Но у меня не завелось. Похоже надо добавлять эти записи в DNS для начала.\nFootnotes\n\n\nauth=local актуально для внутренней инсталляции. ↩\n\n\n"},"notes/Development/Teleport.-Golang":{"title":"Teleport. Golang","links":["notes/Development/Teleport.-Golang"],"tags":[],"content":"Teleport. Golang"},"notes/Development/Thrift-Client.-Golang":{"title":"Thrift Client. Golang","links":["notes/Development/Thrift-Client.-Golang"],"tags":["reference/golang"],"content":"Thrift Client. Golang\nПример создания клиента для Thrift сервера.\nПоследняя строка это вызов метода.\nfunc main() {\n\ttransportFactory := thrift.NewTFramedTransportFactoryConf(thrift.NewTTransportFactory(), nil)\n\tprotocolFactoryBinary := thrift.NewTBinaryProtocolFactoryConf(nil)\n \n\t// protocolFactoryCompact := thrift.NewTCompactProtocolFactoryConf(nil)\n\tprotocolFactoryDebug := thrift.NewTDebugProtocolFactoryWithLogger(protocolFactoryBinary, &quot;&quot;, thrift.StdLogger(log.Default()))\n \n\ttransport := thrift.NewTSocketConf(net.JoinHostPort(HOST, PORT), nil)\n \n\tuseTransport, err := transportFactory.GetTransport(transport)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n \n\tclient := trino.NewTrinoThriftServiceClientFactory(useTransport, protocolFactoryDebug)\n\tif err := transport.Open(); err != nil {\n\t\tfmt.Fprintln(os.Stderr, &quot;Error opening socket to &quot;+HOST+&quot;:&quot;+PORT, &quot; &quot;, err)\n\t\tos.Exit(1)\n\t}\n\tdefer transport.Close()\n \n\tfmt.Println(client.TrinoListSchemaNames(context.Background()))\n}"},"notes/Development/Thrift-Client.-Java":{"title":"Thrift Client. Java","links":["notes/Development/Thrift-Client.-Java","notes/Development/Thrift-Client.-Golang"],"tags":[],"content":"Thrift Client. Java\npackage com.mts.dataops.virtualization;\n \nimport com.mts.dataops.datavirtualization.TrinoThriftService;\nimport org.apache.thrift.TException;\nimport org.apache.thrift.protocol.TBinaryProtocol;\nimport org.apache.thrift.protocol.TProtocol;\nimport org.apache.thrift.transport.TSocket;\nimport org.apache.thrift.transport.layered.TFramedTransport;\n \nimport java.util.List;\n \npublic class Client {\n    public void start() throws TException {\n        TSocket transport = new TSocket(&quot;localhost&quot;, 9998);\n        transport.open();\n        \n        TFramedTransport tFramedTransport = new TFramedTransport(transport);\n        TProtocol protocol = new TBinaryProtocol(tFramedTransport);\n        TrinoThriftService.Client client = new TrinoThriftService.Client(protocol);\n \n        List&lt;String&gt; schemas = client.trinoListSchemaNames();\n        System.out.println(schemas);\n    }\n}\n \nParent::\nChildren::\nFriend:: Thrift Client. Golang"},"notes/Development/Thrift-Codegen.-Golang":{"title":"Thrift Codegen. Golang","links":["notes/Development/Thrift-Codegen.-Golang","notes/Development/Thrift-Codegen.-Java"],"tags":[],"content":"Thrift Codegen. Golang\nthrift -r --gen go:skip_remote trino.thrift\nГде флаг skip_remote это:\n\nSkip the generating of -remote folders for the client binaries for services\n\nParent::\nChildren::\nFriend:: Thrift Codegen. Java"},"notes/Development/Thrift-Codegen.-Java":{"title":"Thrift Codegen. Java","links":["notes/Development/Thrift-Codegen.-Java"],"tags":[],"content":"Thrift Codegen. Java\nGradle\nplugins {\n    id &#039;java&#039;\n    id &quot;org.jruyi.thrift&quot; version &quot;0.4.2&quot;\n}\n \ngroup &#039;com.mts.dataops.virtualization&#039;\nversion &#039;1.0-SNAPSHOT&#039;\n \nrepositories {\n    mavenCentral()\n}\n \ndependencies {\n    implementation &#039;org.apache.thrift:libthrift:0.18.1&#039;\n    implementation &#039;javax.annotation:javax.annotation-api:1.3.2&#039;\n    implementation &#039;org.slf4j:slf4j-api:2.0.7&#039;\n    implementation &#039;org.slf4j:slf4j-simple:2.0.7&#039;\n \n    testImplementation &#039;org.junit.jupiter:junit-jupiter-api:5.8.1&#039;\n    testRuntimeOnly &#039;org.junit.jupiter:junit-jupiter-engine:5.8.1&#039;\n}\n \ntest {\n    useJUnitPlatform()\n}\n\nПодключить плагин org.jruyi.thrift.\nДобавить зависимости:\n\norg.apache.thrift:libthrift\njavax.annotation:javax.annotation-api\norg.slf4j:slf4j-api\n\n\nСпецификации thrift сложить в src/main/thrift\n\nТак же важно прописать в spec файле thrift’а namespace для Java:\nnamespace java com.mts.dataops.datavirtualization\n\nПосле этого в gradle станет доступна команда сборки исходников:\n./gradlew compileThrift"},"notes/Development/Thrift-Server.-Golang":{"title":"Thrift Server. Golang","links":["notes/Development/Thrift-Server.-Golang"],"tags":[],"content":"Thrift Server. Golang\nСоздание сервера\ntransportFactory := thrift.NewTFramedTransportFactoryConf(thrift.NewTTransportFactory(), nil)\nprotocolFactory := thrift.NewTBinaryProtocolFactoryConf(nil)\n\nDebug\nfunc main() {\n\tvar ts TrinoService\n \n\ttransportFactory := thrift.NewTFramedTransportFactoryConf(thrift.NewTTransportFactory(), nil)\n\tprotocolFactoryBinary := thrift.NewTBinaryProtocolFactoryConf(nil)\n \n\tprotocolFactoryDebug := thrift.NewTDebugProtocolFactoryWithLogger(protocolFactoryBinary, &quot;log&quot;, thrift.StdLogger(log.Default()))\n \n\ttransport, err := thrift.NewTServerSocket(&quot;:9998&quot;)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n \n\tprocessor := trino.NewTrinoThriftServiceProcessor(&amp;ts)\n\tserver := thrift.NewTSimpleServer4(processor, transport, transportFactory, protocolFactoryDebug)\n\tlog.Fatal(server.Serve())\n}\nКлиент"},"notes/Development/Thrift-Server.-Java":{"title":"Thrift Server. Java","links":["notes/Development/Thrift-Server.-Java"],"tags":[],"content":"Thrift Server. Java\npackage com.mts.dataops.virtualization;\n \nimport com.mts.dataops.datavirtualization.TrinoThriftService;\nimport org.apache.thrift.protocol.TBinaryProtocol;\nimport org.apache.thrift.server.TServer;\nimport org.apache.thrift.server.TThreadPoolServer;\nimport org.apache.thrift.transport.TServerSocket;\nimport org.apache.thrift.transport.TServerTransport;\nimport org.apache.thrift.transport.TTransportException;\nimport org.apache.thrift.transport.layered.TFramedTransport;\n \npublic class Main {\n    public static void main(String[] args) throws TTransportException {\n        Server trino = new Server();\n        TrinoThriftService.Processor&lt;Server&gt; processor = new TrinoThriftService.Processor&lt;&gt;(trino);\n \n        TServerTransport serverTransport = new TServerSocket(9998);\n        TFramedTransport.Factory transportFactory = new TFramedTransport.Factory();\n        TBinaryProtocol.Factory protocolFactory = new TBinaryProtocol.Factory();\n \n        TThreadPoolServer.Args thriftArgs = new TThreadPoolServer.Args(serverTransport)\n                .processor(processor).\n                inputProtocolFactory(protocolFactory).\n                inputTransportFactory(transportFactory).\n                outputTransportFactory(transportFactory);\n        TServer server = new TThreadPoolServer(thriftArgs);\n \n        Thread thread = new Thread(server::serve);\n        thread.start();\n    }\n}\n\n\n                  \n                  Debug \n                  \n                \n\nДля Java нет Debug реализации протоколов.\n\n"},"notes/Development/Thrift.-Golang":{"title":"Thrift. Golang","links":["notes/Development/Thrift.-Golang","notes/Development/Thrift-Server.-Golang","notes/Development/Thrift-Client.-Golang","notes/Development/Thrift-Codegen.-Golang"],"tags":[],"content":"Thrift. Golang\n\nChildren:: Thrift Server. Golang\nChildren:: Thrift Client. Golang\nChildren:: Thrift Codegen. Golang\n"},"notes/Development/Thrift.-Java":{"title":"Thrift. Java","links":["notes/Development/Thrift.-Java","notes/Development/Thrift-Client.-Java","notes/Development/Thrift-Codegen.-Java","notes/Development/Thrift-Server.-Java"],"tags":[],"content":"Thrift. Java\n\nChildren:: Thrift Client. Java\nChildren:: Thrift Codegen. Java\nChildren:: Thrift Server. Java\n"},"notes/Development/Thrift":{"title":"Thrift","links":["notes/Development/Thrift","notes/Development/Thrift.-Golang","notes/Development/Thrift.-Java","Trino-thrift-connector"],"tags":[],"content":"Thrift\n\nChildren:: Thrift. Golang\nChildren:: Thrift. Java\n\nРаботу с Thrift можно разделить на следующие слои:\n\nСервер\nПротокол\nТранспорт\n\nПротокол\n\nTBinaryProtocol — простой двоичный формат, кодирующий числовые значения как двоичные, а не преобразующий их в текст.\nTCompactProtocol — очень эффективное плотное кодирование данных (подробнее см. ниже).\nTDenseProtocol — похож на TCompactProtocol, но удаляет метаинформацию из передаваемых данных и добавляет её обратно на стороне получателя. TDenseProtocol всё ещё экспериментальный и пока недоступен в реализации на Java.\nTJSONProtocol — использует JSON для кодирования данных.\nTSimpleJSONProtocol — протокол только для записи с использованием JSON. Подходит для разбора скриптовыми языками.\nTDebugProtocol — использует читаемый человеком текстовый формат для помощи в отладке.\n\nТранспорт\n\nTSocket — использует блокирующий ввод-вывод через сокет для передачи данных.\nTFramedTransport — отправляет данные в кадрах, где каждый кадр предваряется указанием его длины. Этот транспорт необходим при использовании неблокирующего сервера.\nTFileTransport — этот транспорт осуществляет запись в файл. Хотя этот транспорт не входит в реализацию на Java, его должно быть достаточно просто реализовать.\nTMemoryTransport — для ввода-вывода использует память. Реализация на Java внутренне использует простой ByteArrayOutputStream.\nTZlibTransport — выполняет сжатие с помощью zlib. Используется вместе с другим транспортом. В реализации на Java недоступен.\n\nFriend:: Trino thrift connector"},"notes/Development/Topic":{"title":"Topic","links":["notes/Development/Topic","notes/Development/min.insync.replicas","notes/Development/segment.bytes","notes/Development/retention.bytes"],"tags":[],"content":"Topic\nПри создании Kafka топика необходимо учитывать несколько основных параметров:\n\nmin.insync.replicas\nsegment.bytes\nretention.bytes - любое удаление возможно только в рамках сегмента, а он по умолчанию кажется один гигабайт!\n"},"notes/Development/WebDAV":{"title":"WebDAV","links":["notes/Development/WebDAV","notes/Development/Создание-htpasswd-файла"],"tags":["reference/unix"],"content":"WebDAV\nОказывается WebDAV это не какой-то сервер, а просто расширение спецификации HTTP позволяющее манипулировать файлами на сервере. Соответственно его серверной частью является фактически любой http-сервер.\nNginx\nВот пример конфигурационного файла для nginx:\nserver {\n    server_name webdav.mak-sim.ru;\n    listen 443 ssl;\n    index index.html;\n \ncreate_full_put_path  on;\n    access_log /var/log/nginx/webdav.log;\n    error_log /var/log/nginx/webdav_error.log;\n \n    location / {\n#        try_files $uri $uri/ =404;\n        root /opt/webdav;\n        dav_methods PUT DELETE MKCOL COPY MOVE;\n        dav_ext_methods PROPFIND OPTIONS;\n        client_max_body_size 100m;\n        create_full_put_path on;\n        auth_basic &quot;Restricted&quot;;\n        auth_basic_user_file /etc/nginx/.webdav_htpasswd;\n}\n    ssl_certificate /etc/letsencrypt/live/ssch.ru/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/ssch.ru/privkey.pem; # managed by Certbot\n}\nВ Ubuntu необходимо так же установить пакет libnginx-mod-http-dav-ext.\nChild:: Создание htpasswd файла"},"notes/Development/YandexGPT-в-Obsidian-TextGenerator":{"title":"YandexGPT в Obsidian TextGenerator","links":["notes/Development/YandexGPT-в-Obsidian-TextGenerator","notes/Development/Получение-IAM_TOKEN-в-YC","notes/Development/Получение-API-ключа-в-YC","notes/Development/Получение-ID-каталога-в-Yandex-Cloud","notes/Development/Температура-запроса-LLM","notes/Development/Роль-модели"],"tags":[],"content":"YandexGPT в Obsidian TextGenerator\nДля того чтобы работать с API YandexGPT необходимо быть зарегистрированным в Yandex Cloud и иметь действующий платежный аккаунт.\nДля авторизации в API потребуется либо IAM токен либо API ключ.\n\nПолучение IAM_TOKEN в YC\nПолучение API ключа в YC\n\nObsidian\n\nУстановить плагин TextGenerator\nВыбрать Provider Profile - Custom или клонировать его нажав +\n\nВ поле Endpoint указать llm.api.cloud.yandex.net/foundationModels/v1/completion\nВ поле API Key указать либо IAM_TOKEN либо API ключ полученный ранее\n\nAdvanced mode\nДальнейшие пункты настраиваются после включения переключателя Advanced mode.\n\nВ секции Headers указываем следующее при использовании ключа API.\n\n{\n    &quot;Content-Type&quot;: &quot;application/json&quot;,\n    &quot;Authorization&quot;: &quot;Api-Key {{api_key}}&quot;, \n    &quot;x-folder-id&quot;: &quot;b1gjpq05r3ppsou34c7d&quot;\n}\nИли вот так при при использовании IAM токена:\n{\n    &quot;Content-Type&quot;: &quot;application/json&quot;,\n    &quot;Authorization&quot;: &quot;Bearer {{api_key}}&quot;, \n    &quot;x-folder-id&quot;: &quot;b1gjpq05r3ppsou34c7d&quot;\n}\nВ x-folder-id необходимо подставить идентификатор того каталога для которого создавался ключ/токен.\n\nВ секции Body пропишем тело запроса.\n\n{\n  &quot;modelUri&quot;: &quot;gpt://b1gjpq05r3ppsou34c7d/yandexgpt/latest&quot;,\n  &quot;completionOptions&quot;: {\n    &quot;stream&quot;: false,\n    &quot;temperature&quot;: {{temperature}},\n    &quot;maxTokens&quot;: {{max_tokens}}\n  },\n  &quot;messages&quot;:  [{&quot;text&quot;:  {{stringify tg_selection}}, &quot;role&quot;:&quot;user&quot;}] \n}\nГде\n\nmodelUri это адрес модели выключающий в себя идентификатор каталога из шагов выше. Список существующих моделей можно посмотреть тут.\ntemperature - температура запроса.\nВ списке messages возможно стоит определить роль модели. Что-то типа:\n\n\nТы AI асистент встроенный в Obsidian. Твоё назначение помогать создавать и редактировать статьи внутри PKM.\n\n\nВ секции Response Sanatization прописываем обработчик ответов API:\n\nif (res.status &gt;= 300) {\n  const err = data?.error?.message || JSON.stringify(data);\n  throw err;\n}\n \nconst choices = data.result.alternatives.map(c =&gt; ({ content: c.message.text }));\n \nreturn choices;\n\nОбязательно устанавливаем галочку CORS Bypass\n\nЭкспортированный профиль\nTextGenerator поддерживает импорт-экспорт профилей. Ниже приведен сохраненный результат описывающий действия выше.\n{\n  id: &#039;Default (Custom) 2&#039;,\n  profile: {\n    extends: &#039;Default (Custom)&#039;,\n    name: &#039;YandexGPT&#039;,\n  },\n  config: {\n    endpoint: &#039;llm.api.cloud.yandex.net/foundationModels/v1/completion&#039;,\n    custom_header: &#039;{\\n    &quot;Content-Type&quot;: &quot;application/json&quot;,\\n    &quot;Authorization&quot;: &quot;Api-Key {{api_key}}&quot;, \\n&quot;x-folder-id&quot;: &quot;b1gjpq05r3ppsou34c7d&quot;\\n}&#039;,\n    custom_body: &#039;{\\n  &quot;modelUri&quot;: &quot;gpt://b1gjpq05r3ppsou34c7d/yandexgpt/latest&quot;,\\n  &quot;completionOptions&quot;: {\\n    &quot;stream&quot;: false,\\n    &quot;temperature&quot;: {{temperature}},\\n    &quot;maxTokens&quot;: {{max_tokens}}\\n  },\\n  &quot;messages&quot;:  [{&quot;text&quot;:  {{stringify tg_selection}}, &quot;role&quot;:&quot;user&quot;}] \\n}\\n&#039;,\n    model: &#039;gpt-3.5-turbo-16k&#039;,\n    sanatization_streaming: &#039;// catch error\\nif (res.status &gt;= 300) {\\n  const err = data?.error?.message || JSON.stringify(data);\\n  throw err;\\n}\\nlet resultText = &quot;&quot;;\\nconst lines = chunk.split(&quot;\\ndata: &quot;);\\n\\nconst parsedLines = lines\\n    .map((line) =&gt; line.replace(/^data: /, &quot;&quot;).trim()) // Remove the &quot;data: &quot; prefix\\n    .filter((line) =&gt; line !== &quot;&quot; &amp;&amp; line !== &quot;[DONE]&quot;) // Remove empty lines and &quot;[DONE]&quot;\\n    .map((line) =&gt; {\\n        try {\\n            return JSON.parse(line)\\n        } catch { }\\n    }) // Parse the JSON string\\n    .filter(Boolean);\\n\\nfor (const parsedLine of parsedLines) {\\n    const { choices } = parsedLine;\\n    const { delta } = choices[0];\\n    const { content } = delta;\\n    // Update the UI with the new content\\n    if (content) {\\n        resultText += content;\\n    }\\n}\\nreturn resultText;&#039;,\n    sanatization_response: &#039;if (res.status &gt;= 300) {\\n  const err = data?.error?.message || JSON.stringify(data);\\n  throw err;\\n}\\n\\nconst choices = data.result.alternatives.map(c =&gt; ({ content: c.message.text }));\\n\\nreturn choices;&#039;,\n    frequency_penalty: 0,\n    presence_penalty: 0.5,\n    top_p: 1,\n    CORSBypass: true,\n    streamable: false,\n    api_key: &#039;&#039;,\n  },\n}"},"notes/Development/ZNode":{"title":"ZNode","links":["notes/Development/ZNode","notes/Development/ZooKeeper"],"tags":[],"content":"ZNode\nZNode — это базовая единица хранения данных в системе координации Apache ZooKeeper.\nОсновные характеристики ZNode:\nИерархическая структура:\nZNode организованы в виде иерархической структуры, похожей на файловую систему. Каждый ZNode может содержать данные и иметь дочерние ZNode.\nДанные и метаданные:\nКаждый ZNode может хранить данные и метаданные. Метаданные включают информацию о версии данных, времени создания и модификации, а также ACL (список контроля доступа).\nТипы ZNode:\n\nPersistent ZNode: Создаются с помощью команды create, и они остаются в системе до тех пор, пока не будут удалены явно.\nEphemeral ZNode: Создаются с помощью команды create -e, и они автоматически удаляются, когда клиент, создавший их, отключается от ZooKeeper.\nSequential ZNode: Создаются с помощью команды create -s, и им автоматически присваивается уникальный порядковый номер.\n\nНаблюдение (Watch):\nКлиенты могут установить наблюдение (watch) на ZNode. Если происходит изменение данных или структуры ZNode, клиенты, установившие наблюдение, получают уведомление.\nТранзакции\nВсе операции с ZNode являются атомарными. Это означает, что либо вся операция выполняется успешно, либо ничего не происходит."},"notes/Development/ZooKeeper-GUI":{"title":"ZooKeeper GUI","links":["notes/Development/ZooKeeper-GUI","notes/Development/ZooKeeper","tags/reference/ubuntu","tags/reference/macos"],"tags":["reference/ubuntu","reference/macos"],"content":"ZooKeeper GUI\nСписок GUI клиентов, что я использовал для работы с ZooKeeper.\nPrettyZoo\nSource:: github.com/vran-dev/PrettyZoo\n\n\n                  \n                  Project archived \n                  \n                \n\nВ июне 2024-ого проект заархивировн.\n\n\nВubuntu устанавливается как deb пакет.\nВmacos есть dmg образ.\nПриятный GUI, работающий достаточно быстро\nZoonavigator\nSource:: github.com/elkozmon/zoonavigator\nЖивой проект по состоянию на ноябрь 2024-ого.\nЗапускается как веб-сервис, доступ через браузер. В Ubuntu это snap или docker образ."},"notes/Development/ZooKeeper":{"title":"ZooKeeper","links":["notes/Development/ZooKeeper","notes/Development/ZNode","notes/Development/Apache-Kafka","notes/Development/ZooKeeper-GUI"],"tags":[],"content":"ZooKeeper\nsource:: zookeeper.apache.org/\nApache Zookeeper — это централизованная служба для управления конфигурацией, синхронизации и предоставления групповых услуг в распределенных системах.\nОсновные характеристики\n\nЦентрализованное управление: Позволяет управлять конфигурацией и состоянием распределенных приложений.\nСинхронизация: Обеспечивает механизмы для синхронизации процессов в распределенной среде.\nВысокая доступность: Поддерживает репликацию данных для обеспечения отказоустойчивости.\n\nАрхитектура\n\nСерверы Zookeeper: Состоят из набора серверов, которые хранят данные и обрабатывают запросы.\n\nОсновная единица хранения информации в Zookeeper - ZNode\n\n\nКлиенты: Приложения, которые взаимодействуют с Zookeeper для получения конфигурации и состояния.\n\nПрименение\n\nКоординация распределенных приложений: Используется для управления состоянием и конфигурацией в таких системах, как Hadoop и Kafka.\nСинхронизация: Позволяет синхронизировать доступ к ресурсам между различными узлами.\n\nFriend:: Apache Kafka, ZooKeeper GUI"},"notes/Development/franz-go":{"title":"franz-go","links":["notes/Development/franz-go"],"tags":[],"content":"franz-go\nsource:: github.com/twmb/franz-go\nseeds := []string{&quot;localhost:9092&quot;}\n// One client can both produce and consume!\n// Consuming can either be direct (no consumer group), or through a group. Below, we use a group.\ncl, err := kgo.NewClient(\n\tkgo.SeedBrokers(seeds...),\n\tkgo.ConsumerGroup(&quot;my-group-identifier&quot;),\n\tkgo.ConsumeTopics(&quot;foo&quot;),\n)\nif err != nil {\n\tpanic(err)\n}\ndefer cl.Close()\n \nctx := context.Background()\n \n// 1.) Producing a message\n// All record production goes through Produce, and the callback can be used\n// to allow for synchronous or asynchronous production.\nvar wg sync.WaitGroup\nwg.Add(1)\nrecord := &amp;kgo.Record{Topic: &quot;foo&quot;, Value: []byte(&quot;bar&quot;)}\ncl.Produce(ctx, record, func(_ *kgo.Record, err error) {\n\tdefer wg.Done()\n\tif err != nil {\n\t\tfmt.Printf(&quot;record had a produce error: %v\\n&quot;, err)\n\t}\n \n})\nwg.Wait()\n \n// Alternatively, ProduceSync exists to synchronously produce a batch of records.\nif err := cl.ProduceSync(ctx, record).FirstErr(); err != nil {\n\tfmt.Printf(&quot;record had a produce error while synchronously producing: %v\\n&quot;, err)\n}\n \n// 2.) Consuming messages from a topic\nfor {\n\tfetches := cl.PollFetches(ctx)\n\tif errs := fetches.Errors(); len(errs) &gt; 0 {\n\t\t// All errors are retried internally when fetching, but non-retriable errors are\n\t\t// returned from polls so that users can notice and take action.\n\t\tpanic(fmt.Sprint(errs))\n\t}\n \n\t// We can iterate through a record iterator...\n\titer := fetches.RecordIter()\n\tfor !iter.Done() {\n\t\trecord := iter.Next()\n\t\tfmt.Println(string(record.Value), &quot;from an iterator!&quot;)\n\t}\n \n\t// or a callback function.\n\tfetches.EachPartition(func(p kgo.FetchTopicPartition) {\n\t\tfor _, record := range p.Records {\n\t\t\tfmt.Println(string(record.Value), &quot;from range inside a callback!&quot;)\n\t\t}\n \n\t\t// We can even use a second callback!\n\t\tp.EachRecord(func(record *kgo.Record) {\n\t\t\tfmt.Println(string(record.Value), &quot;from a second callback!&quot;)\n\t\t})\n\t})\n}"},"notes/Development/ingres":{"title":"ingres","links":["notes/Development/ingres","notes/Development/Настройка-ssl-microk8s"],"tags":["reference/kubernetes"],"content":"ingres\n\nВключение аддона microk8s enable ingress\nПосле этого можно создавать ингресы примерно вот так:\n\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  annotations:\n    cert-manager.io/cluster-issuer: lets-encrypt\n    meta.helm.sh/release-name: grafana\n    meta.helm.sh/release-namespace: monitoring\n  creationTimestamp: &quot;2024-08-23T10:19:10Z&quot;\n  generation: 3\n  labels:\n    app.kubernetes.io/instance: grafana\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: grafana\n    app.kubernetes.io/version: 11.1.4\n    helm.sh/chart: grafana-8.4.7\n  name: grafana\n  namespace: monitoring\n  resourceVersion: &quot;4379574&quot;\n  uid: e2fe91d3-bcad-4476-b523-7ddea8f279be\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: grafana.mak-sim.ru\n    http:\n      paths:\n      - backend:\n          service:\n            name: grafana\n            port:\n              number: 80\n        path: /\n        pathType: Prefix\n  tls:\n  - hosts:\n    - grafana.mak-sim.ru\n    secretName: grafana-tls\nstatus:\n  loadBalancer:\n    ingress:\n    - ip: 127.0.0.1\n \n\nНастройка ssl microk8s\n"},"notes/Development/kafka-go":{"title":"kafka-go","links":["notes/Development/kafka-go","notes/Development/min.insync.replicas","notes/Development/segment.bytes","notes/Development/retention.bytes"],"tags":[],"content":"kafka-go\nSource:: github.com/segmentio/kafka-go\nСоздание топика\nТак как топик можно создать лишь при обращении к контроллеру (во всяком случае в kafka-go) сначала необходимо найти контроллер и подключиться к нему:\nconn, err := kafka.DialContext(ctx, &quot;tcp&quot;, *brokers)\nif err != nil {\n        log.Fatal(err)\n}\ndefer conn.Close()\n \ncontroller, err := conn.Controller()\nif err != nil {\n        panic(err.Error())\n}\nvar controllerConn *kafka.Conn\ncontrollerConn, err = kafka.Dial(&quot;tcp&quot;, net.JoinHostPort(controller.Host, strconv.Itoa(controller.Port)))\nif err != nil {\n        panic(err.Error())\n}\ndefer controllerConn.Close()\nДалее вызывается метод создания топика в который можно передать все параметры указанные в документации Kafka через поле ConfigEntries (min.insync.replicas, segment.bytes, retention.bytes и дургие)\ncontrollerConn.CreateTopics(kafka.TopicConfig{\n        Topic:             *name,\n        NumPartitions:     *partitions,\n        ReplicationFactor: *replicas,\n        ConfigEntries: []kafka.ConfigEntry{\n                // {ConfigName: &quot;min.insync.replicas&quot;, ConfigValue: &quot;2&quot;},\n                {ConfigName: &quot;segment.bytes&quot;, ConfigValue: &quot;2097152&quot;},\n                // {ConfigName: &quot;retention.bytes&quot;, ConfigValue: &quot;3145728&quot;},\n        },\n})"},"notes/Development/kerberos":{"title":"kerberos","links":[],"tags":[],"content":"kerberos\nСоздание keytab-файла\n\nktutil\naddent -password -p login@DOMAIN.RU -k 1 -e aes256-cts-hmac-sha1-96\nУказываем пароль\nwkt sa0000techdq.keytab\n\nПросмотр файла\n[root@host keytabs]# klist -kt login.keytab -e\nKeytab name: FILE:login.keytab\nKVNO Timestamp         Principal\n---- ----------------- --------------------------------------------------------\n1 03/30/23 15:24:47 login@DOMAIN.RU (aes256-cts-hmac-sha1-96)\n\nkinit\nkinit -kt login.keytab login@DOMAIN.RU  "},"notes/Development/konfig":{"title":"konfig","links":["[](https:/github.com/corneliusweig/konfig)","notes/Development/Krew"],"tags":["reference/kubernetes"],"content":"Konfig\nУтилита позволяющая управлять файлами конфигурации kubeconfig. Склеивать их, вытаскивать какой-то один контекст и многое другое.\nGitHub\nУстановка\nЧерез Krew\nkubectl krew install konfig\nВручную\ncurl -Lo konfig github.com/corneliusweig/konfig/raw/v0.2.6/konfig \\\n  &amp;&amp; chmod +x konfig \\\n  &amp;&amp; sudo mv -i konfig /usr/local/bin\nИспользование\nИмпорт Kubeconfig\nСледующая команда добавит новый файл new-cfg в стандартный конфиг.\nkonfig import --save new-cfg\nОна же без ключа save покажет как будет изменён файл конфига, но не запишет изменений.\nОбъединение двух файлов\nСледующая команда объединить два конфигурационных файла.\nkonfig merge config1 config2 &gt; merged-config\nИзвлечение минимального Kubeconfig для определённого контекста\nkonfig export minikube &gt; minikube.config\nFriend:: Krew"},"notes/Development/microk8s":{"title":"microk8s","links":["notes/Development/microk8s","notes/Development/ingres","notes/Development/Добавление-IP-и-DNS-в-сертификат-microk8s"],"tags":["reference/kubernetes"],"content":"microk8s\n\ningres\nДобавление IP и DNS в сертификат microk8s\n"},"notes/Development/min.insync.replicas":{"title":"min.insync.replicas","links":["notes/Development/min.insync.replicas"],"tags":[],"content":"min.insync.replicas\nПараметр min.insync.replicas в Apache Kafka определяет минимальное количество реплик, которые должны быть в синхронизированном состоянии для того, чтобы запись в тему считалась успешной. Этот параметр важен для обеспечения надежности и доступности данных в распределенной системе.\nКогда producer отправляет сообщение в Kafka, он может настроить уровень подтверждений (acknowledgments) через параметр acks. Если установлен режим acks=all, то запись будет считаться успешной только в том случае, если как минимум min.insync.replicas реплик подтвердят получение сообщения. Это помогает избежать потери данных в случае сбоя одной или нескольких реплик.\nНапример, если у нас есть топик с тремя репликами и мы установили min.insync.replicas=2, это значит, что для успешной записи сообщения как минимум две из трех реплик должны быть в синхронизированном состоянии. Если количество синхронизированных реплик падает ниже этого порога, producer будет получать ошибки при попытке записать сообщения, что позволяет предотвратить потерю данных."},"notes/Development/neo4j-в-Golang":{"title":"neo4j в Golang","links":["notes/Development/neo4j-в-Golang","notes/Development/Инструментирование-OTEL-neo4j"],"tags":[],"content":"neo4j в Golang\nChildren:: Инструментирование OTEL neo4j\nЗапись данных\n\t// Создаем сессию\n\tsession := driver.NewSession(ctx, neo4j.SessionConfig{AccessMode: neo4j.AccessModeWrite})\n\tdefer func() {\n\t\t_ = session.Close(ctx)\n\t}()\n \n\t// Запись данных\n\t_, err = session.ExecuteWrite(ctx, func(tx neo4j.ManagedTransaction) (any, error) {\n\t\t// Создание пользователей\n\t\tqueries := []struct {\n\t\t\tquery  string\n\t\t\tparams map[string]interface{}\n\t\t}{\n\t\t\t{query: &quot;MERGE (a:Person {name: $name, age: $age})&quot;, params: map[string]interface{}{&quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 30}},\n\t\t\t{query: &quot;MERGE (b:Person {name: $name, age: $age})&quot;, params: map[string]interface{}{&quot;name&quot;: &quot;Bob&quot;, &quot;age&quot;: 25}},\n\t\t\t{query: &quot;MERGE (c:Person {name: $name, age: $age})&quot;, params: map[string]interface{}{&quot;name&quot;: &quot;Charlie&quot;, &quot;age&quot;: 35}},\n\t\t}\n\t\tfor _, q := range queries {\n\t\t\t_, err := tx.Run(ctx, q.query, q.params)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\nЧтение данных\n\t// Чтение данных: находим друзей для Alice\n\t_, err = session.ExecuteRead(ctx, func(tx neo4j.ManagedTransaction) (any, error) {\n\t\tresult, err := tx.Run(ctx,\n\t\t\t&quot;MATCH (a:Person {name: $name})-[:FRIENDS]-&gt;(friend) &quot;+\n\t\t\t\t&quot;RETURN friend.name AS name, friend.age AS age&quot;,\n\t\t\tmap[string]interface{}{&quot;name&quot;: &quot;Alice&quot;})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n \n\t\t// Обработка результата\n\t\tfmt.Println(&quot;Друзья Alice:&quot;)\n\t\tfor result.Next(ctx) {\n\t\t\trecord := result.Record()\n\t\t\tname, _ := record.Get(&quot;name&quot;)\n\t\t\tage, _ := record.Get(&quot;age&quot;)\n\t\t\tfmt.Printf(&quot;- %s (Возраст: %d)\\n&quot;, name, age)\n\t\t}\n \n\t\treturn nil, result.Err()\n\t})\n\tif err != nil {\n\t\tlog.Fatalf(&quot;Ошибка выполнения чтения: %v&quot;, err)\n\t}"},"notes/Development/retention.bytes":{"title":"retention.bytes","links":["notes/Development/retention.bytes"],"tags":[],"content":"retention.bytes\nПараметр retention.bytes в Apache Kafka определяет максимальный размер данных, который может храниться в топике. Если размер данных в топике превышает указанное значение retention.bytes, Kafka начнет удалять самые старые сообщения, чтобы освободить место для новых.\nЭтот параметр позволяет управлять объемом хранимых данных и может быть полезен для контроля за использованием дискового пространства. Если вы хотите сохранить только определенное количество байтов данных в топике, вы можете установить это значение. Если параметр не установлен, по умолчанию используется значение -1, что означает отсутствие ограничения по размеру."},"notes/Development/segment.bytes":{"title":"segment.bytes","links":["notes/Development/segment.bytes"],"tags":[],"content":"segment.bytes\nПараметр segment.bytes в конфигурации темы (topic) Kafka определяет максимальный размер сегмента, который может быть создан в логах конкретной темы. Сегменты — это файлы, в которые Kafka записывает данные, и они хранятся на диске.\nКогда размер сегмента достигает указанного значения segment.bytes, Kafka создает новый сегмент для записи новых сообщений. Это помогает управлять объемом данных, которые находятся в одном сегменте, и облегчает операции, такие как очистка или удаление старых данных.\nПо умолчанию значение segment.bytes обычно составляет 1 ГБ, но его можно настроить в зависимости от потребностей вашего приложения и доступной вычислительной мощности. Установка более низкого значения может привести к более частым операциям записи, но может улучшить управление данными, в то время как более высокое значение может снизить количество файлов на диске и повысить производительность чтения, но усложнить удаление старых данных."},"notes/Development/Автоматическое-инструментирование-http.Handler-OTEL":{"title":"Автоматическое инструментирование http.Handler OTEL","links":["notes/Development/Автоматическое-инструментирование-http.Handler-OTEL"],"tags":["reference/golang"],"content":"Автоматическое инструментирование http.Handler OTEL\nДля того чтобы автоматически создавать span’ы для всех входящих HTTP запросов средствами OpenTelemetry можно следующим образом обернуть весь router Chi (или любой другой http.Handler):\nimport (\n&quot;github.com/go-chi/chi&quot;\n&quot;go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp&quot;\n)\n \nr := chi.NewRouter()\nwrappedHandler := otelhttp.NewHandler(r, &quot;hello-instrumented&quot;)\n \nhttp.ListenAndServe(&quot;:3000&quot;, wrappedHandler)"},"notes/Development/Базовая-настройка-OTEL-для-работы-с-Jaeger":{"title":"Базовая настройка OTEL для работы с Jaeger","links":["notes/Development/Базовая-настройка-OTEL-для-работы-с-Jaeger"],"tags":["reference/golang"],"content":"Базовая настройка OTEL для работы с Jaeger\n\n\n                  \n                  Устарело \n                  \n                \n\nНе вижу смысла использовать этот endpoint так как даже сам Jaeger умеет в OTLP\n\n\nНиже приведена функция которая обеспечивает базовую настройку tracer’а OpenTelemetry для работы с Jaeger коллектором.\nconst TRACER_NAME = &quot;demo_service&quot;\n \nvar tracer = otel.Tracer(TRACER_NAME)\n \nfunc initOtel() error {\n\texp, err := jaeger.New(jaeger.WithCollectorEndpoint(\n\t\tjaeger.WithEndpoint(&quot;http://127.0.0.1:14268/api/traces&quot;)),\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n \n\ttp := tracesdk.NewTracerProvider(\n\t\ttracesdk.WithBatcher(exp),\n\t\ttracesdk.WithResource(resource.NewWithAttributes(\n\t\t\tsemconv.SchemaURL,\n\t\t\tsemconv.ServiceNameKey.String(&quot;demo_service_name&quot;),\n\t\t)))\n \n\totel.SetTracerProvider(tp)\n\totel.SetTextMapPropagator(propagation.TraceContext{})\n\treturn nil\n}"},"notes/Development/Базовое-редактирование-видео":{"title":"Базовое редактирование видео","links":["notes/Development/Базовое-редактирование-видео"],"tags":[],"content":"Базовое редактирование видео\n\nНа вкладке Edit основные комбинации клавиш и возможности:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKeyDescAРежим курсора/выделенияBРежим лезвия (blade) - нужен для обрезки кусков клиповBackspaceУдаление клипа без авто-сдвига таймлайнаDeleteУдаление клипа с авто-сдвигом таймлайнаCmd-zОтмена последней операцииShit-Cmd-zRedo последней операции"},"notes/Development/Добавление-IP-и-DNS-в-сертификат-microk8s":{"title":"Добавление IP и DNS в сертификат microk8s","links":["notes/Development/Добавление-IP-и-DNS-в-сертификат-microk8s"],"tags":["reference/kubernetes"],"content":"Добавление IP и DNS в сертификат microk8s\n\nDNS запись или IP необходимо внести в файл /var/snap/microk8s/current/certs/csr.conf.template. Секция alt_names\n\n[ alt_names ]\nDNS.1 = kubernetes\nDNS.2 = kubernetes.default\nDNS.3 = kubernetes.default.svc\nDNS.4 = kubernetes.default.svc.cluster\nDNS.5 = kubernetes.default.svc.cluster.local\nDNS.6 = mydomain.com\n\n\nПосле изменения перегенерить сертификат командой\n\nsudo microk8s refresh-certs --cert server.crt"},"notes/Development/Добавление-фона-для-вертикального-видео":{"title":"Добавление фона для вертикального видео","links":["notes/Development/Добавление-фона-для-вертикального-видео"],"tags":[],"content":"Добавление фона для вертикального видео\n\nВытаскиваем видео на timeline\nС зажатым option перетаскиванием дублируем его на ещё одну дорожку.\nДля одной из двух дорожек (на вкладке Edit или Cut) настраиваем масштаб. Inspector → Video → Transform → Zoom X. Таким образом это видео будет занимать весь кадр.\nНа вкладке Edit ищем Gaussian Blur и применяем его к дорожке из третьего шага перетаскиванием.\n\nВ Inpsector → Effects настраиваем силу эффекта по горизонтали или вертикали (по умолчанию они равны друг другу).\n\n\n"},"notes/Development/Запуск-LogSeq-в-Ubuntu":{"title":"Запуск LogSeq в Ubuntu","links":["notes/Development/Запуск-LogSeq-в-Ubuntu"],"tags":["reference/ubuntu"],"content":"Запуск LogSeq в Ubuntu\nПри запуске некоторых AppImage в Ubuntu (например, LogSeq) может возникнуть следующая ошибка:\n❯ ./Logseq-linux-x64-0.10.9_dcf8b41b9db5c9fe9f84938688e17f23.AppImage\nQSocketNotifier: Can only be used with threads started with QThread\nAppImageLauncher error: appimage_shall_not_be_integrated() failed (returned -1)\nAppImageLauncher error: appimage_is_terminal_app() failed (returned -1)\n[15329:1028/094210.939162:FATAL:setuid_sandbox_host.cc(158)] The SUID sandbox helper binary was found, but is not configured correctly. Rather than run without sandboxing I&#039;m aborting now. You need to make sure that /tmp/.mount_LogseqWQcXdE/chrome-sandbox is owned by root and has mode 4755.\n\nЭта ошибка связана с неправильной конфигурацией SUID sandbox helper binary. В идеале, проблема должна решаться разработчиками пакета, однако для временного исправления ситуации можно выполнить следующую команду:\nsudo sysctl -w kernel.apparmor_restrict_unprivileged_userns=0\nДля того чтобы не выполнять данную команду каждый раз после перезагрузки системы, можно добавить строку kernel.apparmor_restrict_unprivileged_userns=0 в файл /etc/sysctl.conf."},"notes/Development/Инициализация-OTEL-в-go":{"title":"Инициализация OTEL в go","links":["notes/Development/Инициализация-OTEL-в-go"],"tags":["reference/golang"],"content":"Инициализация OTEL в go\nКак можно раньше в коде следует выполнить блок инициализации телеметрии.\nБазовая инициализация\npackage main\n \nimport (\n\t&quot;context&quot;\n\t&quot;fmt&quot;\n\t&quot;log&quot;\n\t&quot;time&quot;\n \n\t&quot;go.opentelemetry.io/otel&quot;\n\t&quot;go.opentelemetry.io/otel/exporters/otlp/otlptrace&quot;\n\t&quot;go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc&quot;\n\t&quot;go.opentelemetry.io/otel/sdk/resource&quot;\n\tsdktrace &quot;go.opentelemetry.io/otel/sdk/trace&quot;\n\tsemconv &quot;go.opentelemetry.io/otel/semconv/v1.4.0&quot;\n)\n \nconst (\n\tTRACER_NAME = &quot;demo_service&quot;\n)\n \nfunc InstallExportPipeline() (func(context.Context) error, error) {\n\ttraceClient := otlptracegrpc.NewClient(\n\t\totlptracegrpc.WithInsecure(),\n\t\totlptracegrpc.WithEndpoint(&quot;0.0.0.0:4317&quot;),\n\t)\n \n\tsctx, cancel := context.WithTimeout(context.Background(), time.Second*5)\n\tdefer cancel()\n \n\ttraceExp, err := otlptrace.New(sctx, traceClient)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n \n\tif err != nil {\n\t\treturn nil, fmt.Errorf(&quot;creating stdout exporter: %w&quot;, err)\n\t}\n \n\tres, err := resource.New(context.Background(),\n\t\tresource.WithFromEnv(),\n\t\tresource.WithProcess(),\n\t\tresource.WithTelemetrySDK(),\n\t\tresource.WithHost(),\n\t\tresource.WithAttributes(\n\t\t\tsemconv.ServiceNameKey.String(TRACER_NAME),\n\t\t),\n\t)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n \n\ttracerProvider := sdktrace.NewTracerProvider(\n\t\tsdktrace.WithBatcher(traceExp),\n\t\tsdktrace.WithResource(res),\n\t)\n\totel.SetTracerProvider(tracerProvider)\n \n\treturn tracerProvider.Shutdown, nil\n}\nИспользование в основном коде\nconst (\n        TRACER_NAME = &quot;demo_service&quot;\n)\n \nvar tracer = otel.Tracer(TRACER_NAME)\n \nfunc main() {\n\tctx := context.Background()\n\tshutdown, err := InstallExportPipeline()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\nНу а далее от этого глобального tracer’а уже можно создавать спаны и\nжонглировать ими через контекст:\nnewCtx, span := tracer.Start(r.Context(), &quot;/&quot;)\ndefer span.End()"},"notes/Development/Инструментирование-OTEL-MongoDB":{"title":"Инструментирование OTEL MongoDB","links":["notes/Development/Инструментирование-OTEL-MongoDB","notes/Development/Инициализация-OTEL-в-go"],"tags":[],"content":"Инструментирование OTEL MongoDB\nПриведенный ниже пример не избавит от необходимости выполнять Инициализация OTEL в go но все дальнейшие подключения к монге будут покрываться спанами автоматически!\npackage main\n \nimport (\n        &quot;context&quot;\n        &quot;log&quot;\n        &quot;time&quot;\n \n        &quot;go.mongodb.org/mongo-driver/mongo&quot;\n        &quot;go.mongodb.org/mongo-driver/mongo/options&quot;\n        &quot;go.opentelemetry.io/contrib/instrumentation/go.mongodb.org/mongo-driver/mongo/otelmongo&quot;\n        &quot;go.opentelemetry.io/otel&quot;\n)\n \nvar tracer = otel.Tracer(&quot;mongo_example&quot;)\n \nconst URI = &quot;mongodb://127.0.0.1:27017&quot;\n \nfunc getClient(ctx context.Context) (*mongo.Client, error) {\n        ctx, span := FollowSpan(ctx, &quot;getClient&quot;)\n        defer span.End()\n \n        opts := options.Client()\n        opts.ApplyURI(URI)\n        optsAuth := options.Credential{\n                Username:   &quot;root&quot;,\n                Password:   &quot;example&quot;,\n                AuthSource: &quot;admin&quot;,\n        }\n \n        opts.SetAuth(optsAuth)\n \n        opts.Monitor = otelmongo.NewMonitor()\n \n        client, err := mongo.Connect(ctx, opts)\n        if err != nil {\n                return nil, err\n        }\n        return client, nil"},"notes/Development/Инструментирование-OTEL-Redis-(KeyDB)":{"title":"Инструментирование OTEL Redis (KeyDB)","links":["notes/Development/Инструментирование-OTEL-Redis-(KeyDB)"],"tags":[],"content":"Инструментирование OTEL Redis (KeyDB)\nДля покрытия трейсами Redis в Golang можно воспользоваться библиотекой github.com/XSAM/otelsql.\nСамо подключение очень простое и осуществляется примерно вот так:\nfunc initRedis() {\n\trdb = redis.NewClient(&amp;redis.Options{\n\t\tAddr: &quot;localhost:6379&quot;,\n\t})\n\tif err := redisotel.InstrumentTracing(rdb); err != nil {\n\t\tpanic(err)\n\t}\n}"},"notes/Development/Инструментирование-OTEL-neo4j":{"title":"Инструментирование OTEL neo4j","links":["notes/Development/Инструментирование-OTEL-neo4j","notes/Development/Neo4j"],"tags":[],"content":"Инструментирование OTEL neo4j\nВместо стандартного создания драйвера Neo4j:\ndriver, err := neo4j.NewDriverWithContext(uri, neo4j.BasicAuth(username, password, &quot;&quot;))\n\tif err != nil {\n\t\tlog.Fatalf(&quot;Ошибка подключения к Neo4j: %v&quot;, err)\n\t}\nМожно воспользоваться библиотекой neo4j_tracing\n\tdriverFactory := neo4j_tracing.NewNeo4jTracer()\n\tdriver, err := driverFactory.NewDriverWithContext(uri, neo4j.BasicAuth(username, password, &quot;&quot;))\n\tif err != nil {\n\t\tpanic(err)\n\t}"},"notes/Development/Как-переименовать-камеры-в-Multicam":{"title":"Как переименовать камеры в Multicam","links":["notes/Development/Как-переименовать-камеры-в-Multicam"],"tags":[],"content":"Как переименовать камеры в Multicam\n\nВ контекстном меню Multicam ролика можно выбрать опцию “Open in timeline”. В этом режиме откроется работа с ним как с отдельными треками.\nТут можно переименовать и поиграть например со звуком. Работая с громкостью отдельных каналов.\n"},"notes/Development/Как-посчитать-количество-планок-памяти-в-Linux":{"title":"Как посчитать количество планок памяти в Linux","links":["notes/Development/Как-посчитать-количество-планок-памяти-в-Linux"],"tags":["reference/unix"],"content":"Как посчитать количество планок памяти в Linux\nsudo dmidecode -t memory | grep -i size\nДля этого можно использовать команду “sudo dmidecode -t memory | grep -i size”. Она выведет информацию о размере каждой установленной планки памяти, а также общее количество физических планок."},"notes/Development/Картинка-в-картинке-в-круге-Open-FX":{"title":"Картинка в картинке в круге Open FX","links":["notes/Development/Картинка-в-картинке-в-круге-Open-FX"],"tags":[],"content":"Картинка в картинке в круге Open FX\n\nНа вкладке Effects находим Open FX эффект “Transform” и применяем его (перетаскивая на таймлайн) к дорожке которую хотим сделать маленькой.\nВ Inspector на вкладке Effects для эффекта Transform в разделе Image Adjustment ставим в единицу параметр Edge Rounding.\nНа вкладке Inspector’а Video изменяя параметры Zoom и Position двигаем картинку внутри полученного круга.\nВ Inspector на вкладке Effects для эффекта Transform параметры Position и Zoom определяют местоположение и масштаб самого круга.\n"},"notes/Development/Картинка-в-картинке.-Трансформация":{"title":"Картинка в картинке. Трансформация","links":["notes/Development/Картинка-в-картинке.-Трансформация"],"tags":[],"content":"Картинка в картинке. Трансформация\n\nВ окне Edit открываем inspector\n\nВ секции Cropping подрезаем видео убирая лишнее (оставляем голову)\nВ секции Transform изменяем\n\nМасштаб чтобы картинка стала маленькой\nПоложение по осям X и Y для размещения в нужной части экрана\n\n\n\n\n"},"notes/Development/Картинка-в-картинке":{"title":"Картинка в картинке","links":["notes/Development/Картинка-в-картинке","notes/Development/Картинка-в-картинке.-Трансформация","notes/Development/Картинка-в-картинке-в-круге-Open-FX"],"tags":[],"content":"Картинка в картинке\nЯ нашел два способа разместить картинку в картинке. Это удобно например для небольшой говорящей головы в рамках скринкаста.\n\nКартинка в картинке. Трансформация\nКартинка в картинке в круге Open FX\n"},"notes/Development/Ключевые-точки":{"title":"Ключевые точки","links":["notes/Development/Ключевые-точки"],"tags":[],"content":"Ключевые точки\n\nПри выставлении какого либо параметра, например силу гаусова размытия, можно определить точку начала и точку конца этого эффекта.\nНапример в точке начала может быть выставлена сила эффекта в ноль, а в конечной в единицу. DaVinci осуществит плавный переход от нуля до единицы. То есть сила (в данном примере, а вообще величина параметра) будет плавно меняться от первой точки до конечной.\nЕсли это применить например к координатам то объект будет двигаться или менять свои размеры.\nРомбики на фото ниже задают ключевые точки.\n"},"notes/Development/Компиляция-proto-файла-для-Golang":{"title":"Компиляция proto файла для Golang","links":["notes/Development/Компиляция-proto-файла-для-Golang"],"tags":["reference/golang"],"content":"Компиляция proto файла для Golang\nsyntax = &quot;proto3&quot;;\npackage ecommerce;\n \nservice ProductInfo {\n    rpc addProduct(Product) returns (ProductID);\n    rpc getProduct(ProductID) returns(Product);\n};\n \nmessage Product {\n    string id = 1;\n    string name = 2;\n    string description = 3;\n};\n \nmessage ProductID {\n    string value = 1;\n};\nprotoc --go-grpc_out=. --go-grpc_opt=Mecommerce/product_info.proto=./ecommerce --go_out=. --go_opt=Mecommerce/product_info.proto=./ecommerce  ecommerce/product_info.proto\nАльтернативой указания значений Mecommerce/product_info.proto=./ecommerce может стать определение значений go_package в proto:\noption go_package = &quot;./;investapi&quot;;\n"},"notes/Development/Компиляция-swagger-для-Golang":{"title":"Компиляция swagger для Golang","links":["notes/Development/Компиляция-swagger-для-Golang"],"tags":["reference/golang"],"content":"Компиляция swagger для Golang\nswagger-codegen generate --input-spec developers.strava.com/swagger/swagger.json --lang go --output api"},"notes/Development/Логическая-репликация-PostgreSQL":{"title":"Логическая репликация PostgreSQL","links":["notes/Development/Логическая-репликация-PostgreSQL"],"tags":[],"content":"Логическая репликация PostgreSQL\nЛогическая репликация в отличии от физической копирует не сами данные, а sql выражения эти данные изменяющие.\n\nНа мастере в postgresql.conf указать wal_level=&quot;logical&quot; после чего перезапустить сервер.\nНа реплике выполнить следующие команды:\n\npg_dumpall --database=postgres --host=db.mak-sim.ru --no-password --globals-only --no-privileges | psql\n \npg_dump --dbname db_name --host=db.mak-sim.ru --no-password --create --schema-only | psql\nПервая перенесет пользователей и прочие глобальные объекты. Вторая схему данных.\n\nПодключившись на мастере к нужной бд создадим публикацию:\n\nCREATE PUBLICATION db_pub FOR ALL TABLES;\n\nНа реплике создадим подписку\n\nCREATE SUBSCRIPTION health_sub CONNECTION &#039;host=db.mak-sim.ru dbname=health user=postgres password=**** sslmode=require&#039; PUBLICATION db_pub;\nПричём health_sub это имя слота на источнике репликации, а значит должно быть уникальным!\nРепликация новых таблиц\nЕсли после создания подписки на источнике появились новые таблицы то сначала необходимо создать на приемнике ту же таблицу (DDL), а затем выполнить команду:\nALTER SUBSCRIPTION sub_name REFRESH PUBLICATION;\nкоманду следует выполнить от лица пользователя владельца подписки. Узнать его можно так:\nselect\n\trolname\nfrom \n\tpg_authid\nwhere\n\toid =\n\t\t(select\n\t\t\tpubowner\n\t\tfrom\n\t\t\tpg_publication\n\t\twhere\n\t\t\tpubname=&#039;main&#039;);"},"notes/Development/Настройка-WireGuard":{"title":"Настройка WireGuard","links":["notes/Development/Настройка-WireGuard"],"tags":["reference/ubuntu","reference/unix"],"content":"Настройка WireGuard\nУстановка сервера\n\nУстановить wg-easy. Это упакованный в Docker wireguard + web интерфейс к нему\n\ndocker run -d \\\n  --name=wg-easy \\\n  -e LANG=en \\\n  -e WG_HOST=192.168.1.1 \\\n  -e PASSWORD=password \\\n  -v ~/.wg-easy:/etc/wireguard \\\n  -p 51820:51820/udp \\\n  -p 51821:51821/tcp \\\n  --cap-add=NET_ADMIN \\\n  --cap-add=SYS_MODULE \\\n  --sysctl=&quot;net.ipv4.conf.all.src_valid_mark=1&quot; \\\n  --sysctl=&quot;net.ipv4.ip_forward=1&quot; \\\n  --restart unless-stopped \\\n  ghcr.io/wg-easy/wg-easy\n \nНеобходимо заменить переменные WG_HOST и PASSWORD.\n2. По адресу http://192.168.1.1:51821 будет доступна простая панель управления где можно добавлять новых пользователей.\nНастройка клиентов\nAndroid\nПросто скачать приложение и отсканировать QR-код из web-интерфейса.\nUbuntu\n\nСкачать конфигурационный файл из веб интерфейса\nУстановить wireguard\n\nsudo apt install wireguard\n\n\nПочинить симлинк которого ждёт wireguard `ln -s /usr/bin/resolvectl /usr/local/bin/resolvconf\nС помощью утилиты wg-quick поднять интерфейс командой wg-quick up ./wg0.conf\n\nИмя интерфейса будет равно имени файла.\nФайл должен находиться по абсолютному или относительному пути. Если это не путь, а просто строка то тогда соответствующий конфиг будет искаться в папке /etc/wireguard.\n\nУдобнее сразу его туда скопировать.\n\n\n\n\n"},"notes/Development/Подключение-к-GRPC-server'у":{"title":"Подключение к GRPC server'у","links":["notes/Development/Подключение-к-GRPC-server'у"],"tags":["reference/golang"],"content":"Подключение к GRPC server’у\nSimple server\nСоздание сервера\ntype server struct {\n\tproductMap map[string]*pb.Product\n\tecommerce.UnimplementedProductInfoServer\n}\n \nconst (\n\tport = &quot;:50051&quot;\n)\n \nfunc main() {\n\tlis, err := net.Listen(&quot;tcp&quot;, port)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\ts := grpc.NewServer()\n\tecommerce.RegisterProductInfoServer(s, &amp;server{})\n\tlog.Printf(&quot;Starting gRPC listener on port %s&quot;, port)\n\tif err := s.Serve(lis); err != nil {\n\t\tlog.Fatalf(&quot;failed serve: %v&quot;, err)\n\t}\n}\nСоздание клиента\npackage main\n \nimport (\n\t&quot;context&quot;\n\t&quot;log&quot;\n\t&quot;time&quot;\n \n\t&quot;client/ecommerce&quot;\n \n\t&quot;google.golang.org/grpc&quot;\n\t&quot;google.golang.org/grpc/credentials/insecure&quot;\n)\n \nconst (\n\taddress = &quot;localhost:50051&quot;\n)\n \nfunc main() {\n\tconn, err := grpc.Dial(address, grpc.WithTransportCredentials(insecure.NewCredentials()))\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer conn.Close()\n \n\tc := ecommerce.NewProductInfoClient(conn)\n\tname := &quot;Apple iPhone 11&quot;\n\tdescription := &quot;Some phone&quot;\n \n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tr, err := c.AddProduct(ctx, &amp;ecommerce.Product{Name: name, Description: description})\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tlog.Printf(&quot;Product ID: %s added successfully&quot;, r.Value)\n \n\tproduct, err := c.GetProduct(ctx, &amp;ecommerce.ProductID{Value: r.Value})\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tlog.Printf(&quot;Product: %s&quot;, product.String())\n}\nTinkoff OpenAPI\nconn, err := grpc.Dial(&quot;invest-public-api.tinkoff.ru:443&quot;,\n\tgrpc.WithTransportCredentials(credentials.NewTLS(&amp;tls.Config{})),\n\tgrpc.WithPerRPCCredentials(oauth.TokenSource{\n\t\tTokenSource: oauth2.StaticTokenSource(&amp;oauth2.Token{\n\t\t\tAccessToken: &quot;token&quot;,\n\t\t\t}),\n\t\t}))\n\tif err != nil {\n\t\tlog.Fatalf(&quot;did not connect: %v&quot;, err)\n\t}\n\tdefer conn.Close()\nПосле чего объект conn можно передавать в функции создание новых сервисов."},"notes/Development/Получение-API-ключа-в-YC":{"title":"Получение API ключа в YC","links":["notes/Development/Получение-API-ключа-в-YC","notes/Development/Получение-списка-Service-Account-в-YC"],"tags":[],"content":"Получение API ключа в YC\nЭто инструкция по созданию API-ключа для сервисного аккаунта. API-ключ — секретный ключ, используемый для упрощенной авторизации в API Yandex Cloud.\nЕсли у вас еще нет сервисного аккаунта, создайте его и назначьте ему роли.\nЧтобы создать API-ключ:\n\nСоздайте API-ключ с помощью метода REST API create для ресурса ApiKey:\n\nexport SERVICEACCOUNT_ID=&lt;идентификатор_сервисного_аккаунта&gt;\nexport IAM_TOKEN=&lt;токен&gt;\ncurl -X POST \\\n  -H &quot;Content-Type: application/json&quot; \\\n  -H &quot;Authorization: Bearer $IAM_TOKEN&quot; \\\n  -d &quot;{\n      \\&quot;serviceAccountId\\&quot;: \\&quot;$SERVICEACCOUNT_ID\\&quot;,\n      \\&quot;scope\\&quot;: \\&quot;&lt;область_действия&gt;\\&quot;,\n      \\&quot;expiresAt\\&quot;: \\&quot;&lt;дата_и_время&gt;\\&quot;\n  }&quot; \\\n  iam.api.cloud.yandex.net/iam/v1/apiKeys\nГде:\n\nSERVICEACCOUNT_ID — идентификатор сервисного аккаунта. Обязательный параметр.\nIAM_TOKEN — IAM-токен. Обязательный параметр.\nscope — область действия для ключа с ограниченным доступом. Необязательный параметр.\nexpiresAt — дата и время истечения срока действия ключа с ограниченным доступом. Необязательный параметр.\n"},"notes/Development/Получение-IAM_TOKEN-в-YC":{"title":"Получение IAM_TOKEN в YC","links":["notes/Development/Получение-IAM_TOKEN-в-YC"],"tags":[],"content":"Получение IAM_TOKEN в YC\n\nВойдите- в ваш аккаунт на Яндексе.\nПолучите OAuth-токен в сервисе Яндекс.OAuth. Для этого перейдите по ссылке, нажмите Разрешить и скопируйте полученный OAuth-токен.\nОбменяйте OAuth-токен на IAM-токен:\n\ncurl -X POST \\\n  -d &#039;{&quot;yandexPassportOauthToken&quot;:&quot;&lt;OAuth-токен&gt;&quot;}&#039; \\\n  iam.api.cloud.yandex.net/iam/v1/tokens"},"notes/Development/Получение-ID-каталога-в-Yandex-Cloud":{"title":"Получение ID каталога в Yandex Cloud","links":["notes/Development/Получение-ID-каталога-в-Yandex-Cloud","notes/Development/Получение-ID-облака-в-Yandex-Cloud"],"tags":[],"content":"Получение ID каталога в Yandex Cloud\nДля использования многих методов API YC требуется знать идентификатор каталога в облаке.\nПолучение id облака\nИдентификатор самого облака в свою очередь можно получить вот так:\nTransclude of Получение-ID-облака-в-Yandex-Cloud\nПолучение id каталога(в)\nhttp GET resource-manager.api.cloud.yandex.net/resource-manager/v1/folders Authorization:&quot;Bearer $IAM_TOKEN&quot; cloud_id=b1gp230h62h8oavhctri\nОтвет:\n{\n    &quot;folders&quot;: [\n        {\n            &quot;cloudId&quot;: &quot;b1gp230h62h8oavhctri&quot;,\n            &quot;createdAt&quot;: &quot;2020-09-19T07:20:09Z&quot;,\n            &quot;id&quot;: &quot;b1gjpq05r3ppsou34c7d&quot;,\n            &quot;name&quot;: &quot;default&quot;,\n            &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n    ]\n}"},"notes/Development/Получение-ID-облака-в-Yandex-Cloud":{"title":"Получение ID облака в Yandex Cloud","links":["notes/Development/Получение-ID-облака-в-Yandex-Cloud","notes/Development/Получение-IAM_TOKEN-в-YC"],"tags":[],"content":"Получение ID облака в Yandex Cloud\nДля того чтобы узнать id облаков доступных в YC необходимо выполнить следующий запрос (необходим I AM токен):\nhttp GET resource-manager.api.cloud.yandex.net/resource-manager/v1/clouds  Authorization:&quot;Bearer $IAM_TOKEN&quot;\nОтвет:\n{\n    &quot;clouds&quot;: [\n        {\n            &quot;createdAt&quot;: &quot;2020-09-19T07:20:09Z&quot;,\n            &quot;id&quot;: &quot;b1gp230h62h8oavhctri&quot;,\n            &quot;name&quot;: &quot;maksim77&quot;,\n            &quot;organizationId&quot;: &quot;bpfulqitoarhlo1a29ln&quot;\n        }\n    ]\n}"},"notes/Development/Получение-списка-Service-Account-в-YC":{"title":"Получение списка Service Account в YC","links":["notes/Development/Получение-списка-Service-Account-в-YC","notes/Development/Получение-IAM_TOKEN-в-YC"],"tags":[],"content":"Получение списка Service Account в YC\nНеобходимо получить IAM_TOKEN и знать идентификатор каталога (FOLDER_ID).\nexport FOLDER_ID=b1gvmob95yys********\nexport IAM_TOKEN=CggaATEVAgA...\ncurl -H &quot;Authorization: Bearer ${IAM_TOKEN}&quot; \\\n  &quot;iam.api.cloud.yandex.net/iam/v1/serviceAccounts${FOLDER_ID}&quot;\n \n{\n &quot;serviceAccounts&quot;: [\n  {\n   &quot;id&quot;: &quot;ajebqtreob2d********&quot;,\n   &quot;folderId&quot;: &quot;b1gvmob95yys********&quot;,\n   &quot;createdAt&quot;: &quot;2018-10-18T13:42:40Z&quot;,\n   &quot;name&quot;: &quot;my-robot&quot;,\n   &quot;description&quot;: &quot;my description&quot;\n  }\n ]\n}"},"notes/Development/Проброс-span-Opentelemetry-через-текстовое-поле":{"title":"Проброс span Opentelemetry через текстовое поле","links":["notes/Development/Проброс-span-Opentelemetry-через-текстовое-поле"],"tags":["reference/golang"],"content":"Проброс span Opentelemetry через текстовое поле\nДля того чтобы пробросить span просто в текстовом виде можно выполнить следующее:\nm := make(map[string]string)\n \notel.GetTextMapPropagator().Inject(r.Context(), propagation.MapCarrier(m))\nпосле этого map’а m будет содержать id родительского span’а в ключе traceparent.\nТаким образом можно развернуть его обратно в контекст примерно вот так:\nm := make(map[string]string)\npm := propagation.MapCarrier(m)\npm.Set(&quot;traceparent&quot;, c[&quot;traceparent&quot;])\n \nctx := otel.GetTextMapPropagator().Extract(context.Background(), pm)\nПолученный контекст ctx можно будет использовать для создания дочернего span’а."},"notes/Development/Проброс-span-через-HTTP-в-Opentelemetry":{"title":"Проброс span через HTTP в Opentelemetry","links":["notes/Development/Проброс-span-через-HTTP-в-Opentelemetry","notes/Development/OpenTelemetry"],"tags":["reference/golang"],"content":"Проброс span через HTTP в Opentelemetry\nДля того чтобы пробросить span OpenTelemetry, а точнее конечно же его ID через http запрос можно использовать следующую схему.\n\nПри начальной настройке объекта otel необходимо указать:\n\notel.SetTextMapPropagator(propagation.TraceContext{})\n\nДалее существующий контекст который содержит span необходимо завернуть в Header запроса который мы будем выполнять:\n\notel.GetTextMapPropagator().Inject(newCtx, propagation.HeaderCarrier(req.Header))\nГде newCtx это контекст который вернулся при создании исходного span.\n\nНа стороне обработчика запроса принимающей стороны необходимо распаковать контекст из пришедшего request header.\n\nctx := otel.GetTextMapPropagator().Extract(r.Context(), propagation.HeaderCarrier(r.Header))\n_, span := tracer.Start(ctx, &quot;remoteservice&quot;)\ndefer span.End()"},"notes/Development/Работа-с-Kafka-в-Golang":{"title":"Работа с Kafka в Golang","links":["notes/Development/Работа-с-Kafka-в-Golang","notes/Development/kafka-go","notes/Development/franz-go"],"tags":[],"content":"Работа с Kafka в Golang\n\nkafka-go\nfranz-go\n"},"notes/Development/Работа-с-teleport":{"title":"Работа с teleport","links":["notes/Development/Работа-с-teleport","notes/Development/Teleport-CLI","notes/Development/Teleport.-Golang"],"tags":[],"content":"Работа с teleport\n&gt; Платформа доступа Teleport — это набор программного обеспечения и управляемых услуг, который предоставляет доступ к инфраструктуре по запросу с минимальными привилегиями на основе криптографической идентичности и модели Zero Trust, с встроенной безопасностью идентификации и управлением политиками.\n\nChildren:: Teleport CLI\nChildren:: Teleport. Golang\n\nSource:: goteleport.com/"},"notes/Development/Роль-модели":{"title":"Роль модели","links":["notes/Development/Роль-модели"],"tags":[],"content":"Роль модели\nПри использовании API для общения с языковыми моделями можно задавать роль модели. Это позволяет адаптировать её поведение под конкретные задачи или сценарии. Роль системы (system role) задаёт инструкции, которые влияют на последующее взаимодействие.\nОсновные роли\n\nsystem — определяет поведение модели и задаёт её стиль.\nuser — сообщение от пользователя с запросом или задачей.\nassistant — ответы от модели на запросы.\n\nПример использования API с указанием роли системы\n{\n  &quot;model&quot;: &quot;advanced-llm&quot;,\n  &quot;messages&quot;: [\n    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant that specializes in product management and databases.&quot;},\n    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What are the key benefits of using the latest database version for large-scale applications?&quot;}\n  ]\n}"},"notes/Development/Синхронизация-двух-камер":{"title":"Синхронизация двух камер","links":["notes/Development/Синхронизация-двух-камер","notes/Development/Как-переименовать-камеры-в-Multicam"],"tags":[],"content":"Синхронизация двух камер\nПохоже что существует два подхода. Один строится на простом выравнивании клипов друг относительно друга, а другой на создании специальной сущности для работы с множеством камер.\nПод мои нужды куда лучше подходит первый но попробую описать оба.\nВыравнивание клипов\n\nДобавить оба клипа на таймлайн.\nВыбрать оба.\nВ контекстном меню воспользоваться “Auto Align Clips&quot;→&quot;Based on waveform”\n\nMulticam timeline\n\nВыбрать все клипы (например на вкладке Media) и в контекстном меню использовать “Create new miulticam clip using selected clips”.\n\nИсходные клипы будут перенесены в папку “Original Clips”\n\n\nНа созданном клипе нужно в контекстном меню выбрать “Create New Timeline”.\nВ окне Edit при работе с timeline созданным на втором шаге следует включить отображение в двух панелях и в левом выбрать режим работы “Multicam”. Выбор мышью соответствующей камеры переключить фокус на неё.\n\nFriend:: Как переименовать камеры в Multicam"},"notes/Development/Создание-htpasswd-файла":{"title":"Создание htpasswd файла","links":["notes/Development/Создание-htpasswd-файла"],"tags":[],"content":"Создание htpasswd файла\n\napt-get install apache2-utils\nhtpasswd -c /etc/nginx/.webdav_htpasswd maksim77\n\nOnline генерация\nhostingcanada.org/htpasswd-generator/"},"notes/Development/Создание-перехватчика-GRPC":{"title":"Создание перехватчика GRPC","links":["notes/Development/Создание-перехватчика-GRPC","notes/Development/OpenTelemetry"],"tags":["reference/golang"],"content":"Создание перехватчика GRPC\nМожет быть полезно для OpenTelemetry.\nServer Unary Intercepter\nfunc MyInter(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface{}, error) {\n\tfmt.Println(ctx)\n\tfmt.Println(info.FullMethod)\n\treturn handler(ctx, req)\n}\n \nfunc main() {\n\tlis, err := net.Listen(&quot;tcp&quot;, port)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\ts := grpc.NewServer(grpc.UnaryInterceptor(MyInter))\n\tecommerce.RegisterProductInfoServer(s, &amp;server{})\n\tlog.Printf(&quot;Starting gRPC listener on port %s&quot;, port)\n\tif err := s.Serve(lis); err != nil {\n\t\tlog.Fatalf(&quot;failed serve: %v&quot;, err)\n\t}\n}"},"notes/Development/Структура-HTTP-Header-трэйсинга":{"title":"Структура HTTP Header трэйсинга","links":[],"tags":[],"content":"Trace Context\nЗаголовок HTTP отвечающий за передачу идентификатора span’а это traceparent.\nПример его содержимого:\ntraceparent: 00-0af7651916cd43dd8448eb211c80319c-b9c7c989f97918e1-01\n\nГде через дефис разделены следующие компоненты:\n\nversion - в настоящий момент всегда 00.\ntrace-id - основной идентификатор трэйса. Следует использовать именно его для поиска в системах типа Jaeger или Zipkin.\nparent-id - Идентификатор родительского Span’а.\ntrace-flags - служебные флаги\n\nSource:: www.w3.org/TR/trace-context/"},"notes/Development/Температура-запроса-LLM":{"title":"Температура запроса LLM","links":["notes/Development/Температура-запроса-LLM"],"tags":[],"content":"Температура запроса LLM\nОписание:\nПараметр temperature (температура) используется в моделях генерации текста, таких как LLM (Large Language Models), для управления степенью случайности в процессе генерации.\nФункция:\n\nНизкие значения temperature (например, 0.1) приводят к более детерминированным и предсказуемым результатам, где модель выбирает наиболее вероятные слова.\nВысокие значения temperature (например, 1.0 и выше) увеличивают разнообразие и креативность генерируемого текста, позволяя модели делать более рискованные и неожиданные выборы.\n\nПрименение:\n\nНастройка temperature позволяет пользователям контролировать баланс между креативностью и предсказуемостью в сгенерированном контенте, в зависимости от конкретных задач и целей.\n"},"notes/Development/Установка-GRPC-в-Golang":{"title":"Установка GRPC в Golang","links":["notes/Development/Установка-GRPC-в-Golang"],"tags":["reference/golang"],"content":"Установка GRPC в Golang\nLinux\n$ apt install -y protobuf-compiler\n$ protoc --version  # Ensure compiler version is 3+\nMac OS\n$ brew install protobuf\n$ protoc --version  # Ensure compiler version is 3+\nGolang\n$ go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.28\n$ go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.2"},"notes/Development/Цветокоррекция":{"title":"Цветокоррекция","links":["notes/Development/Цветокоррекция"],"tags":[],"content":"Цветокоррекция\n\nПо факту я особо не разобрался но:\n\nВсе действия происходят на вкладке Color.\n\nВот на этой карттинке символ A в круге означает автоматическую корректировку баланса.\nЕсли авто-корректировкой не пользоваться то задача выравнять графики справа примерно в один уровень с помощью ползунков левой части.\n"},"notes/Development/Частичный-коммит-изменений-файла-в-git":{"title":"Частичный коммит изменений файла в git","links":["notes/Development/Squash-commit-in-git"],"tags":["reference/git"],"content":"Для того чтобы в git добавить в следующий коммит только часть изменений осуществленных в файле необходимо добавить его с ключом patch или p в короткой записи:\ngit add -p &lt;filename&gt;\nпосле чего в консоли будет отображаться последовательно все изменения и задаваться вопрос для каждого из них:\nStage this hunk [y,n,q,a,d,/,j,J,g,s,e,?]?\n\nГде:\n\ny - записать изменение\nn - пропустить\na - записать это и все последующие\nd - пропустить это и все последующие\n? - справка по всем остальным клавишам\n\nFriend:: Squash commit in git"},"notes/Personal/Casio-AW-81":{"title":"Casio AW-81","links":["notes/Personal/Casio-AW-81"],"tags":[],"content":"Casio AW-81\n\nНастройка аналогового времени\n\nВ режиме Timekeeping нажать кнопку C шесть раз чтобы войти в Hand Setting Mode.\nУдерживать A пока цифровое время не начнёт мигать.\nНажать D для перемещения минутной стрелки.\n\nУдерживать D для быстрого перемещения стрелки.\nЕсли надо существенно изменить время то следует нажать D и B одновременно. Стрелка начнет движение на быстрой скорости сама до тех пор пока не будет нажата какая либо другая кнопка.\n\n\nНажать A для завершения настройки.\n\nНастройка digital времени\n\nВ режиме Timekeeping удерживать клавишу A пока не замигают секунду на цифровом дисплее.\nКнопкой C переключать активное поле в следующем порядке: Seconds → DST → Hour → Minutes → Day → Month → Year/\n\nПри настройке секунд кнопка Dсбрасывает их на ноль.\n\n\nНажать A для завершения настройки.\n"}}