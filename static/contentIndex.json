{"index":{"title":"index","links":["Index","notes/Gradle","notes/Flyway","notes/Переключение-между-различными-Java.-Linux","notes/DB-migrations-в-Golang","notes/Context--and--select","notes/Работа-с-oauth2-в-golang","notes/Task","notes/Учебник-по-awk","notes/Работа-с-restic","notes/Настройка-WebDAV-на-nginx","notes/Запуск-minio-в-docker","notes/Работа-с-JQ","notes/Инсталляция-Ansible-на-старых-серверах","notes/Настройка-OpenSearch-для-локальной-разработки","notes/Trino/Trino","notes/SSL-on-PostgreSQL","notes/Логическая-репликация-PostgreSQL","notes/PostgreSQL-upgrade","notes/Курс-Greenplum","notes/MongoDB-CRUD","notes/Neo4j","notes/Kafka/Apache-Kafka","notes/YandexGPT-в-Obsidian-TextGenerator","notes/OTEL/OpenTelemetry","notes/00_GRPC","notes/Thrift","notes/Swagger--and--OpenAPI","notes/SchemaCrawler","notes/Squash-commit-in-git","notes/Частичный-коммит-изменений-файла-в-git","notes/GitHub-issue-search","notes/microk8s","notes/Krew","notes/konfig","notes/Создание-ServiceAccount-и-токена-к-нему","notes/debug-container-k8s","notes/AST-дерево","notes/Добавление-нового-ядра-в-Jupyter-notebook","notes/Управление-зависимостями-C++.-Conan","notes/Управление-зависимостями-C++.-CMake","notes/Как-посчитать-количество-планок-памяти-в-Linux","notes/Установка-шрифтов-в-Ubuntu","notes/Смена-timezone-в-Ubuntu","notes/Tmux","notes/Vim","notes/NTLM-авторизация-в-httpie","notes/Смена-имен-папок-в-home-dir-на-английский","notes/tcpdump","notes/Kerberos","notes/Install-SNMP-on-asus-router","notes/Linux-cd-back-to-1-step","notes/Поиск-процесса-слушающего-порт","notes/Как-заблокировать-доступ-до-определенного-IP-в-Ubuntu","notes/Настройка-WireGuard","notes/MagicMouse-speed-settings","notes/Locate-в-MacOS","notes/Force-Sync-iCloud-Drive","notes/Video/00_DaVinci-Resolve","notes/VScode-hotkeys","notes/VirtualBox-with-UEFI-Secure-Boot","notes/Casio-AW-81","notes/Xiaomi-Mi-Cloud-from-python","notes/Bitcoin","notes/Запуск-LogSeq-в-Ubuntu","notes/Git-user-checks","notes/Draft-actions"],"tags":[],"content":"Index\nДобро пожаловать в ещё один цифровой садик.\nПо сути это небольшой кусочек моего Obsidian доступный всем. Большинство заметок здесь я специально не готовил к публикации и они видны “как есть”, что означает местами специфическое форматирование или хвост ы каких-то плагинов которые не видны в интерфейсе Quartz.\nТехнологии и Разработка\nЯзыки Программирования\nJava\n\nGradle\nFlyway\nПереключение между различными Java. Linux\n\nGolang\n\nDB migrations в Golang\nContext &amp; select\nРабота с oauth2 в golang\n\nTools &amp; Services\n\nTask - аналог Make в современном мире.\nУчебник по awk\nРабота с restic\nНастройка WebDAV на nginx\nЗапуск minio в docker\nРабота с JQ\nИнсталляция Ansible на старых серверах\nНастройка OpenSearch для локальной разработки\n\nБазы Данных\n\nTrino\n\nSQL\n\nPostgreSQL\n\nSSL on PostgreSQL\nЛогическая репликация PostgreSQL\nPostgreSQL upgrade\n\n\nGreenplum\n\nNoSQL\n\nMongoDB\n\nMongoDB CRUD\n\n\nNeo4j\nApache Kafka\n\nИнструменты и Плагины\n\nYandexGPT в Obsidian TextGenerator\nOpenTelemetry\ngRPC\nThrift\nSwagger &amp; OpenAPI\nSchemaCrawler\nGit\n\nSquash commit in git\nЧастичный коммит изменений файла в git\nGitHub issue search\n\n\nKubernetes\n\nmicrok8s\nKrew\nkonfig\nСоздание ServiceAccount и токена к нему\ndebug container k8s\n\n\n\nРазное\n\nAST дерево\nPython\n\nДобавление нового ядра в Jupyter notebook\n\n\nC++\n\nУправление зависимостями C++. Conan\nУправление зависимостями C++. CMake\n\n\n\nOS\nLinux\n\nКак посчитать количество планок памяти в Linux\nУстановка шрифтов в Ubuntu\nСмена timezone в Ubuntu\nTmux\nVim\nNTLM авторизация в httpie\nСмена имен папок в home dir на английский\ntcpdump\nРабота с Kerberos\nInstall SNMP on asus router\nLinux cd back to 1 step\nПоиск процесса слушающего порт\nКак заблокировать доступ до определенного IP в Ubuntu\nНастройка WireGuard\n\nMacOS\n\nMagicMouse speed settings\nLocate в MacOS\nForce Sync iCloud Drive\n\nПрочее\n\nDaVinci Resolve\nVScode hotkeys\nVirtualBox with UEFI Secure Boot\nНастройка времени на Casio AW-81\nXiaomi Mi Cloud from python\nBitcoin\nЗапуск LogSeq в Ubuntu\n\nPets\n\nGit user checks\nDraft actions\n"},"notes/00_GRPC":{"title":"00_GRPC","links":["notes/00_GRPC","notes/Установка-GRPC-в-Golang","notes/Компиляция-proto-файла-для-Golang","notes/Подключение-к-GRPC-server'у","notes/Создание-перехватчика-GRPC","notes/GRPC-Reflection","notes/Thrift"],"tags":["reference/golang"],"content":"00_GRPC\n\nУстановка GRPC в Golang\nКомпиляция proto файла для Golang\nПодключение к GRPC server’у\nСоздание перехватчика GRPC\nGRPC Reflection\n\nFriend:: Thrift"},"notes/AST-дерево":{"title":"AST дерево","links":["notes/AST-дерево"],"tags":[],"content":"AST дерево\nАбстрактное синтаксическое дерево (АСД, англ. abstract syntax tree, AST) — конечное помеченное ориентированное дерево, в котором внутренние вершины сопоставлены (помечены) с операторами языка программирования, а листья — с соответствующими операндами. Таким образом, листья являются пустыми операторами и представляют только переменные и константы.\n\nПриведенный на схеме AST соответствует примерно следующему коду:\nwhile b ≠ 0\n\tif a &gt; b\n\t\ta := a − b\n    else\n\t\tb := b − a\nreturn a   \n"},"notes/Ansible-become-pass":{"title":"Ansible become pass","links":["notes/Ansible-become-pass"],"tags":[],"content":"Ansible become pass\nBecome Pass определяется через переменную окружения ANSIBLE_BECOME_PASS."},"notes/Bitcoin":{"title":"Bitcoin","links":["notes/Bitcoin"],"tags":["reference/python"],"content":"Bitcoin\nДля того чтобы прочитать приватный мастер ключ из формата zpriv можно воспользоваться библиотекой pycoins на Python.\n  from pycoin.symbols.btc import network as BTC\n  zprv = BTC.parse(&quot;zprv......&quot;)\nИмпорт приватного ключа в Bitcoin Core\nwalletpassphrase &quot;password&quot; 600\nimportprivkey &quot;private_key&quot; &quot;label&quot; false\ngetblockchaininfo \nrescanblockchain 820742 821780\n\nГде цифры в последней команде это номера вершины и последнего доступного блока полученные из вывода getblockchaininfo."},"notes/Casio-AW-81":{"title":"Casio AW-81","links":["notes/Casio-AW-81"],"tags":[],"content":"Casio AW-81\n\nНастройка аналогового времени\n\nВ режиме Timekeeping нажать кнопку C шесть раз чтобы войти в Hand Setting Mode.\nУдерживать A пока цифровое время не начнёт мигать.\nНажать D для перемещения минутной стрелки.\n\nУдерживать D для быстрого перемещения стрелки.\nЕсли надо существенно изменить время то следует нажать D и B одновременно. Стрелка начнет движение на быстрой скорости сама до тех пор пока не будет нажата какая либо другая кнопка.\n\n\nНажать A для завершения настройки.\n\nНастройка digital времени\n\nВ режиме Timekeeping удерживать клавишу A пока не замигают секунду на цифровом дисплее.\nКнопкой C переключать активное поле в следующем порядке: Seconds → DST → Hour → Minutes → Day → Month → Year/\n\nПри настройке секунд кнопка Dсбрасывает их на ноль.\n\n\nНажать A для завершения настройки.\n"},"notes/Context--and--select":{"title":"Context & select","links":["notes/Context--and--select"],"tags":["reference/golang"],"content":"Context &amp; select\nБазовая работа с context и выбором select  в Golang.\npackage main\n \nimport (\n\t&quot;context&quot;\n\t&quot;time&quot;\n \n\t&quot;github.com/juju/zaputil/zapctx&quot;\n\t&quot;go.uber.org/zap&quot;\n)\n \ntype key struct{}\n \nfunc doWork(ctx context.Context) {\n\tlogger := zapctx.Logger(ctx)\n \n\tlogger.Info(ctx.Value(key{}).(string))\n\tfor {\n\t\tselect {\n\t\tcase &lt;-ctx.Done():\n\t\t\tlogger.Info(&quot;ctx canceled&quot;)\n\t\t\treturn\n\t\tdefault:\n\t\t\tlogger.Info(&quot;Working&quot;)\n\t\t\ttime.Sleep(time.Second)\n\t\t}\n\t}\n}\n \nfunc main() {\n\tctx := context.Background()\n \n\tlogger, _ := zap.NewProduction()\n\tlogger = logger.With(zap.String(&quot;env&quot;, &quot;prod&quot;))\n \n\tlogger.Info(&quot;Start app&quot;)\n \n\tlogCtx := zapctx.WithLogger(ctx, logger)\n\tctxLogWithValue := context.WithValue(logCtx, key{}, &quot;iddqd&quot;)\n \n\tctxTimeout, _ := context.WithTimeout(ctxLogWithValue, time.Second*5)\n\tdoWork(ctxTimeout)\n \n\tctxCancel, cancel := context.WithCancel(ctxLogWithValue)\n\tgo doWork(ctxCancel)\n\ttime.Sleep(time.Second * 6)\n\tcancel()\n}"},"notes/Cypher":{"title":"Cypher","links":["notes/Cypher","PublicMedia/openCypher9.pdf"],"tags":[],"content":"Cypher\n\nСоздание узлов с помощью MERGE\nЗапрос:\nMERGE (a:Person {name: $name, age: $age})\nОбъяснение:\n\nMERGE: Проверяет, существует ли узел с указанными свойствами. Если не существует, создаёт его. Если существует, повторного создания не будет.\n\nMERGE Reference\n\n\n(a:Person ...): Создаётся или ищется узел с меткой Person. Метка (label) описывает тип сущности (например, Person для человека).\n{name: $name, age: $age}: Свойства узла. name и age задаются через параметры (обозначены как $name и $age), значения которых передаются из кода.\n\nСоздание уникальных связей с помощью MERGE\nЗапрос:\nMATCH (a:Person {name: $name1}), (b:Person {name: $name2})\nMERGE (a)-[:FRIENDS]-&gt;(b)\nОбъяснение:\n\nMATCH (a:Person {name: $name1}): Ищет узел с меткой Person, у которого свойство name равно значению параметра $name1. Этот узел связывается с переменной a.\n\nMATCH Reference\n\n\nMATCH (b:Person {name: $name2}): Аналогично, ищет узел Person с именем $name2 и связывает его с переменной b.\nMERGE (a)-[:FRIENDS]-&gt;(b): Проверяет, существует ли связь FRIENDS от узла a к узлу b. Если такая связь существует, ничего не делает. Если не существует, создаёт её.\n[:FRIENDS]: Определяет тип связи. В данном случае это “дружба”.\n-&gt;: Направление связи. Стрелка указывает, что a дружит с b.\n\nПоиск друзей конкретного человека\nЗапрос:\nMATCH (a:Person {name: $name})-[:FRIENDS]-&gt;(friend)\nRETURN friend.name AS name, friend.age AS age\nОбъяснение:\n\nMATCH (a:Person {name: $name}): Ищет узел Person с именем, равным значению $name. Этот узел связывается с переменной a.\n-[:FRIENDS]-&gt;(friend): Находит все узлы, связанные с узлом a связью типа FRIENDS. Эти узлы связываются с переменной friend.\nRETURN friend.name AS name, friend.age AS age: Возвращает свойства найденных узлов:\n\nfriend.name — имя друга.\nfriend.age — возраст друга.\nRETURN Reference\n\n\nAS используется для задания алиасов, чтобы упростить доступ к возвращённым данным.\n\nПоиск кратчайшего пути между двумя людьми\nЗапрос:\nMATCH p = shortestPath((a:Person {name: $start})-[:FRIENDS*]-(b:Person {name: $end}))\nRETURN p\nОбъяснение:\n\nMATCH p = shortestPath(...): Начинает поиск пути, который будет присвоен переменной p. Функция shortestPath ищет наименьшее количество связей между узлами.\n(a:Person {name: $start}): Ищет узел с меткой Person, у которого свойство name равно значению параметра $start. Этот узел связывается с переменной a.\n-[:FRIENDS*]-: Находит любые связи типа FRIENDS (обозначенные *, что означает “любое количество связей”) между узлом a и узлом b. Направление связи не имеет значения благодаря использованию -.\n(b:Person {name: $end}): Ищет узел с меткой Person, у которого свойство name равно значению параметра $end. Этот узел связывается с переменной b.\nRETURN p: Возвращает найденный путь p, который представляет собой последовательность узлов и связей от a до b.\n\nПоиск самого длинного пути между двумя людьми\nЗапрос:\nMATCH p = (a:Person {name: $start})-[:FRIENDS*]-(b:Person {name: $end})\nRETURN p, length(p) AS pathLength\nORDER BY pathLength DESC\nLIMIT 1\nОбъяснение:\n\nMATCH p = (...): Начинает поиск пути, который будет присвоен переменной p.\n(a:Person {name: $start}): Ищет узел с меткой Person, у которого свойство name равно значению параметра $start. Этот узел связывается с переменной a.\n-[:FRIENDS*]-: Находит любые связи типа FRIENDS между узлом a и узлом b, независимо от их направления.\n(b:Person {name: $end}): Ищет узел с меткой Person, у которого свойство name равно значению параметра $end. Этот узел связывается с переменной b.\nRETURN p, length(p) AS pathLength: Возвращает найденный путь p и длину этого пути, которая определяется количеством связей (length(p)), присваивая результат алиасу pathLength.\nORDER BY pathLength DESC: Сортирует результаты по длине пути в порядке убывания, чтобы самые длинные пути шли первыми.\nLIMIT 1: Ограничивает результат одним самым длинным путем.\n"},"notes/DB-migrations-в-Golang":{"title":"DB migrations в Golang","links":["notes/DB-migrations-в-Golang"],"tags":["reference/golang"],"content":"DB migrations в Golang\ngithub.com/golang-migrate/migrate/v4. Работает как cli и как библиотека для Go.\nCLI\nСоздать новую миграцию:\nmigrate create -ext sql -seq -dir db/migrations create_token_table\nГде -seq нужен чтобы миграции создавались с номерами вместо дат.\nПрименить миграцию к БД:\nmigrate --database sqlite3://auth.db --path db/migrations up\nGolang\nimport (\n\t&quot;github.com/golang-migrate/migrate/v4&quot;\n\t_ &quot;github.com/golang-migrate/migrate/v4/database/sqlite3&quot;\n\t_ &quot;github.com/golang-migrate/migrate/v4/source/file&quot;\n)\n \ntype SQLiteStore struct{}\n \nfunc NewSQLiteStore() (*SQLiteStore, error) {\n\tm, err := migrate.New(&quot;file://db/migrations&quot;, &quot;sqlite3://auth.db&quot;)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n \n\terr = m.Up()\n\tif err != nil &amp;&amp; err.Error() != &quot;no change&quot; {\n\t\treturn nil, err\n\t}\n\tvar ss SQLiteStore\n\treturn &amp;ss, nil\n}\nСледует помнить, что метод Up возвращает “no change” как ошибку! Её надо обрабатывать в явном виде.\nПример с embed миграциями\nТак же в этом примере показано как использовать существующее соединение с БД, вместо формирования новой строки подключения.\n//go:embed migrations/pg/*\nvar migrations embed.FS\n \ntype PgStorage struct {\n\t*sqlx.DB\n}\n \nfunc NewPgStorage(conf config.Db) *PgStorage {\n\tdb, err := otelsqlx.Open(&quot;pgx&quot;, fmt.Sprintf(&quot;user=%s password=%s host=%s port=%d dbname=%s&quot;, conf.User, conf.Pass, conf.Host, conf.Port, conf.Name), otelsql.WithAttributes(semconv.DBSystemPostgreSQL))\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\td, err := iofs.New(migrations, &quot;migrations/pg&quot;)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n \n\tdriver, err := postgres.WithInstance(db.DB, &amp;postgres.Config{})\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tm, err := migrate.NewWithInstance(&quot;iofs&quot;, d, &quot;postgres&quot;, driver)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\terr = m.Up()\n\tif err != nil &amp;&amp; err.Error() != &quot;no change&quot; {\n\t\tlog.Fatal(err)\n\t}\n\treturn &amp;PgStorage{db}\n}"},"notes/Dependency-Injection":{"title":"Dependency Injection","links":["notes/Dependency-Injection"],"tags":[],"content":"Dependency Injection"},"notes/Deployment":{"title":"Deployment","links":["notes/Deployment","notes/Pod","notes/ReplicaSet"],"tags":["reference/kubernetes"],"content":"Deployment\nDeployment это ресурс Kubernetes представляющий собой абстракцию над Pod и ReplicaSet.\nUse Cases\n\nАвтоматическое декларативное создание ReplicaSet.\nОбновление спецификаций Pod и пересоздание RS\nОткат к предыдущему состоянию в случае не стабильной работы нового (хранится несколько последних версий развертывания).\nМасштабирование количества подов.\nВозможность поставить rollout update на паузу.\n\nСоздание Deployment\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-container\n        image: my-image:latest"},"notes/Draft-actions":{"title":"Draft actions","links":["notes/Draft-actions"],"tags":[],"content":"Draft actions\nI really like the Draft app, and I have written a number of actions for it. I wrote them for myself, but some of them seemed interesting enough for me to share with everyone.\n\nMastodon Reply - simple action that allows you to reply to Mastodon toot directly from within Draft.\nCalendar - this action takes all of today’s events from the calendar and creates a markdown for Obsidian Daily Notes.\n"},"notes/Flyway":{"title":"Flyway","links":["notes/Flyway"],"tags":[],"content":"Flyway\nСхема наименование файлов миграций:\nV1__name.sql\n\nV - типа миграции\n1 - её номер\n__ - разделитель.\nname - название миграции где вместо пробелов следует использовать знак _\n\nGradle\nbuildscript {\n    dependencies {\n        classpath &#039;org.postgresql:postgresql:42.6.0&#039;\n    }\n}\n \nplugins {\n    id &quot;org.flywaydb.flyway&quot; version &quot;9.19.0&quot;\n}\n \nflyway {\n    url = &#039;jdbc:postgresql://localhost:5432/trino&#039;\n    user = &#039;maksim&#039;\n    cleanDisabled = false\n}\nСами миграции должны лежать в папке src/main/resources/db/migration/.\nЗадачи gradle:\n\nflywayMigration - применить миграции\nflywayClean - очистка БД от текущей схемы. Работает только при настройке cleanDisabled = false.\n"},"notes/Force-Sync-iCloud-Drive":{"title":"Force Sync iCloud Drive","links":["notes/Force-Sync-iCloud-Drive","tags/obsidian"],"tags":["reference/macos","obsidian"],"content":"Force Sync iCloud Drive\nС активным использованиемobsidian на iOS/MacOS проблема с залипающей синхронизацией iCloud порой изрядно бесит.\nЕдинственный способ перезапуска синхронизации iCloud Drive который я нашёл это убить процесс bird. Который представляет из себя служебный демон синхронизации:\nkill `ps -ef | grep bird | grep -v grep | awk &#039;{print $2}&#039;`\nИли что примерно то же самое:\nkillall bird"},"notes/GRPC-Reflection":{"title":"GRPC Reflection","links":["notes/GRPC-Reflection"],"tags":["reference/golang"],"content":"GRPC Reflection\nСуществует возможность получать список методов, узнавать описания сообщений и даже вызывать методы с помощью утилиты командной строки grpc_cli.\nСборка утилиты\n\nКлонировать grpc репозиторий\ngit submodule update --init\nmkdir -p cmake/build\ncd cmake/build\ncmake -DgRPC_BUILD_TESTS=ON ../..\nmake grpc_cli\n\nНастройка севера для работы с reflection\nimport &quot;google.golang.org/grpc/reflection&quot;\n \ns := grpc.NewServer()\nreflection.Register(s)"},"notes/Git-user-checks":{"title":"Git user checks","links":["notes/Git-user-checks","notes/Gitcheck-dev-notes"],"tags":[],"content":"Git user checks\n\nVSCode Marketplace\nGitHub\n\nSometimes, after cloning a repository from a corporate git server and sending several commits to it, you realize that you forgot to change the user settings in git.\nThis extension was written to avoid that.\nYou only need to define three parameters. The first is the domain that the extension will look for in the origin section of the repository that you opened in VSCode.\nThe other two are user settings that need to be set for the repository cloned from the domain specified in the first paragraph.\n\nThat’s it! The extension will warn you that you are working with a repository for which user settings should be set (if they are not already set). Clicking the “Overwrite” button will automatically add the necessary parameters to the git settings of the current project.\n\nGitcheck dev notes"},"notes/GitHub-issue-search":{"title":"GitHub issue search","links":["notes/GitHub-issue-search"],"tags":["reference/git"],"content":"GitHub issue search\nДля того чтобы найти все комментарии к issue которые оставил пользователь можно использовать директиву поиска involves. Например так: is:issue involves:maksim77"},"notes/Gitcheck-dev-notes":{"title":"Gitcheck dev notes","links":["notes/Gitcheck-dev-notes"],"tags":[],"content":"Gitcheck dev notes\nAzure DevOps\nMarketplace console\n\nВот здесь расположена консоль управления экстеншенами.\n"},"notes/Gradle":{"title":"Gradle","links":["notes/Gradle"],"tags":[],"content":"Gradle\n\nСоздать пустой проект можно с помощью gradle init. Но он создает немного не стандартную структуру нежели я привык.\nДобавить wrapper - gradle wrapper.\n\nПростой рабочий конфиг build.gradle\nЗдесь:\n\nСекция application нужна для того чтобы работала команда run.\nСекция jar нужна для того чтобы в итоговом jar файле сформировался нормальный манифест с указанием на главный класс.\nПлагин com.github.johnrengelman.shadow обеспечивает сборку проекта в shadowJar.\n\nplugins {\n    id &#039;java&#039;\n    id &#039;application&#039;\n    id &#039;com.github.johnrengelman.shadow&#039; version &#039;8.1.1&#039;\n}\n \ngroup &#039;ru.mak_sim&#039;\nversion &#039;1.0-SNAPSHOT&#039;\n \nrepositories {\n    mavenCentral()\n}\n \napplication {\n    mainClass = &#039;ru.mak_sim.Hello&#039;\n}\n \njar {\n    manifest {\n        attributes(\n                &#039;Main-Class&#039;: &#039;ru.mak_sim.Hello&#039;\n        )\n    }\n}\n \ndependencies {\n  implementation &#039;org.apache.logging.log4j:log4j-api:2.20.0&#039;\n  implementation &#039;org.apache.logging.log4j:log4j-core:2.20.0&#039;\n}"},"notes/Guice":{"title":"Guice","links":["notes/Guice","notes/Dependency-Injection"],"tags":[],"content":"Guice\n\n\n                  \n                  Wikipedia \n                  \n                \n\nGoogle Guice — универсальный фреймворк с открытым исходным кодом для Java-платформы, разработанный компанией Google под лицензией Apache 2.0. Фреймворк обеспечивает поддержку внедрения зависимостей при помощи аннотаций для конфигурирования объектов Java[2].\nВнедрение зависимостей — паттерн проектирования, основная задача которого — отделить поведения объекта от управления его зависимостями. Guice позволяет классам реализаций программно привязываться к интерфейсу и затем иньектироваться в конструкторы, методы или поля, помеченные аннотацией @Inject. Когда необходимо обеспечить более одной реализации одного интерфейса, пользователь может создать собственную аннотацию, определяющую выбор нужной реализации, и затем использовать её для внедрения зависимостей.\n\n"},"notes/Install-SNMP-on-asus-router":{"title":"Install SNMP on asus router","links":[],"tags":["reference/unix"],"content":"Install SNMP package on Asus Router\nipkg list | grep snmp\nipkg install net-snmp\napp_set_enabled.sh net-snmp yes\nSource:: fatmin.com/2013/11/13/install-and-configure-snmp-on-the-asus-rt-ac66u-router/"},"notes/Install-swagger-on-Mac-OS":{"title":"Install swagger on Mac OS","links":["notes/Install-swagger-on-Mac-OS"],"tags":[],"content":"Install swagger on Mac OS\nbrew install swagger-codegen"},"notes/Kafka-Connect":{"title":"Kafka Connect","links":["notes/Kafka-Connect"],"tags":[],"content":"Kafka Connect\nЗапуск сервиса\nВ папке дистриубтива Kafka есть скрипт ./bin/connect-standalone.sh который надо запустить указав путь до файла конфига в формате properties:\nbootstrap.servers=127.0.0.1:29092,127.0.0.1:39092,127.0.0.1:49092\ngroup.id=myconnect\n \nkey.converter=org.apache.kafka.connect.json.JsonConverter\nvalue.converter=org.apache.kafka.connect.json.JsonConverter\n \noffset.storage.topic=connector_offset\noffset.storage.file.filename=offset\nconfig.storage.topic=connector_config\nstatus.storage.topic=connector_status\nДрайвер MongoDB Connect\nДокументация: www.mongodb.com/docs/kafka-connector/current/introduction/install/\nMaven: central.sonatype.com/artifact/org.mongodb.kafka/mongo-kafka-connect\nJar файл архива надо положить в паку libs дистрибутива Kafka.\nСоздать коннектор\nhttp POST http://localhost:8083/connectors @mongodb.json\nгде mongodb.json:\n{&quot;name&quot;: &quot;mongo-source&quot;,\n &quot;config&quot;: { &quot;connector.class&quot;:&quot;com.mongodb.kafka.connect.MongoSourceConnector&quot;,\n     &quot;connection.uri&quot;:&quot;mongodb://localhost:27017&quot;,\n     &quot;database&quot;:&quot;strava&quot;,\n     &quot;collection&quot;:&quot;workout&quot;,\n     &quot;copy.existing&quot;: true\n }\n}"},"notes/Kafka/Apache-Kafka":{"title":"Apache Kafka","links":["notes/Kafka/Apache-Kafka","notes/Kafka/Topic","notes/ZooKeeper","notes/Kafka/Работа-с-Kafka-в-Golang","notes/Kafka-Connect","notes/Kafka/RedPanda"],"tags":[],"content":"Apache Kafka\nApache Kafka — это распределенная платформа потоковой обработки, которая позволяет обрабатывать и передавать потоки данных в реальном времени с высокой пропускной способностью и низкой задержкой. Она используется для сбора, хранения и обработки сообщений, а также для обеспечения надежной передачи данных между различными системами и приложениями.\n\n\n                  \n                  Брокер (Broker) \n                  \n                \n\nБрокер — это отдельный сервер в кластере Kafka, который отвечает за хранение сообщений, их обработку и передачу. Брокеры работают совместно, образуя распределенную систему, которая обеспечивает высокую доступность и отказоустойчивость.\n\n\n\n\n                  \n                  Топик (Topic) \n                  \n                \n\nТопик Topic — это логический канал, по которому передаются сообщения в Kafka. Каждый топик имеет уникальное имя и может содержать множество сообщений. Топики используются для разделения потоков данных на логические категории, что упрощает их обработку и управление.\n\n\n\n\n                  \n                  Партиция (Partition) \n                  \n                \n\nПартиция — это часть топика, которая распределяется по брокерам. Каждый топик может состоять из одной или нескольких партиций, что позволяет распределить нагрузку и обеспечить параллельную обработку сообщений. Партиции обеспечивают горизонтальное масштабирование и улучшают производительность системы.\n\n\n\n\n                  \n                  Фактор репликации (Replication Factor) \n                  \n                \n\nФактор репликации — это количество копий партиции, которые создаются и хранятся в кластере. Например, если фактор репликации равен 3, то каждая партиция будет иметь три копии, распределенные по разным брокерам. Фактор репликации определяет уровень отказоустойчивости и надежности данных: чем выше фактор репликации, тем больше брокеров могут выйти из строя без потери данных, но при этом увеличивается нагрузка на кластер.\n\n\nZookeeper\nВ кластере Apache Kafka, ZooKeeper выполняет роль координатора, который управляет конфигурацией и состоянием кластера. Основные функции ZooKeeper включают:\n\nУправление конфигурацией: ZooKeeper хранит метаданные о брокерах, топиках и партициях, что позволяет Kafka динамически обновлять конфигурацию и перераспределять нагрузку.\nОбнаружение отказов: ZooKeeper отслеживает состояние брокеров и уведомляет остальные компоненты кластера о любых сбоях, что позволяет Kafka быстро реагировать на отказы и восстанавливать работу.\nВыбор лидера партиций: ZooKeeper помогает выбрать лидера для каждой партиции, что важно для обеспечения консистентности данных и отказоустойчивости.\n\nВ более новых версиях Kafka (начиная с версии 2.8) появилась возможность работы без ZooKeeper, используя собственный механизм управления состоянием кластера, называемый KRaft. Однако, в большинстве существующих установок Kafka по-прежнему используется ZooKeeper для управления кластером.\n\nРабота с Kafka в Golang\nKafka Connect\nRedPanda\n"},"notes/Kafka/RedPanda":{"title":"RedPanda","links":["notes/Kafka/RedPanda","notes/ZooKeeper","notes/RedPanda-docker-quick-start"],"tags":[],"content":"RedPanda\n\nRedPanda — это современная система управления потоками данных, разработанная для обеспечения высокой производительности и низкой задержки при обработке событий. Она совместима с клиентами Apache Kafka, что позволяет использовать существующие приложения и инструменты без значительных изменений.\nОсновные отличия RedPanda от Apache Kafka:\n\nПроизводительность: RedPanda оптимизирован для работы с SSD и использует более эффективные алгоритмы, что позволяет достигать большей пропускной способности и снижать задержки.\nАрхитектура: RedPanda построена на едином процессе, что упрощает развертывание и управление по сравнению с архитектурой Kafka, которая может требовать несколько компонентов (ZooKeeper) 1\nПростота использования: RedPanda предлагает более простую настройку и управление, что делает его более доступным для разработчиков.\nСовместимость: RedPanda полностью совместим с API Kafka, что позволяет пользователям легко мигрировать или интегрировать его в существующие системы.\n\nChild:: RedPanda docker quick start\nFootnotes\n\n\nНе актуально для современных версий ↩\n\n\n"},"notes/Kafka/Topic":{"title":"Topic","links":["notes/Kafka/Topic","notes/Kafka/min.insync.replicas","notes/Kafka/segment.bytes","notes/Kafka/retention.bytes"],"tags":[],"content":"Topic\nПри создании Kafka топика необходимо учитывать несколько основных параметров:\n\nmin.insync.replicas\nsegment.bytes\nretention.bytes - любое удаление возможно только в рамках сегмента, а он по умолчанию кажется один гигабайт!\n"},"notes/Kafka/franz-go":{"title":"franz-go","links":["notes/Kafka/franz-go"],"tags":[],"content":"franz-go\nsource:: github.com/twmb/franz-go\nseeds := []string{&quot;localhost:9092&quot;}\n// One client can both produce and consume!\n// Consuming can either be direct (no consumer group), or through a group. Below, we use a group.\ncl, err := kgo.NewClient(\n\tkgo.SeedBrokers(seeds...),\n\tkgo.ConsumerGroup(&quot;my-group-identifier&quot;),\n\tkgo.ConsumeTopics(&quot;foo&quot;),\n)\nif err != nil {\n\tpanic(err)\n}\ndefer cl.Close()\n \nctx := context.Background()\n \n// 1.) Producing a message\n// All record production goes through Produce, and the callback can be used\n// to allow for synchronous or asynchronous production.\nvar wg sync.WaitGroup\nwg.Add(1)\nrecord := &amp;kgo.Record{Topic: &quot;foo&quot;, Value: []byte(&quot;bar&quot;)}\ncl.Produce(ctx, record, func(_ *kgo.Record, err error) {\n\tdefer wg.Done()\n\tif err != nil {\n\t\tfmt.Printf(&quot;record had a produce error: %v\\n&quot;, err)\n\t}\n \n})\nwg.Wait()\n \n// Alternatively, ProduceSync exists to synchronously produce a batch of records.\nif err := cl.ProduceSync(ctx, record).FirstErr(); err != nil {\n\tfmt.Printf(&quot;record had a produce error while synchronously producing: %v\\n&quot;, err)\n}\n \n// 2.) Consuming messages from a topic\nfor {\n\tfetches := cl.PollFetches(ctx)\n\tif errs := fetches.Errors(); len(errs) &gt; 0 {\n\t\t// All errors are retried internally when fetching, but non-retriable errors are\n\t\t// returned from polls so that users can notice and take action.\n\t\tpanic(fmt.Sprint(errs))\n\t}\n \n\t// We can iterate through a record iterator...\n\titer := fetches.RecordIter()\n\tfor !iter.Done() {\n\t\trecord := iter.Next()\n\t\tfmt.Println(string(record.Value), &quot;from an iterator!&quot;)\n\t}\n \n\t// or a callback function.\n\tfetches.EachPartition(func(p kgo.FetchTopicPartition) {\n\t\tfor _, record := range p.Records {\n\t\t\tfmt.Println(string(record.Value), &quot;from range inside a callback!&quot;)\n\t\t}\n \n\t\t// We can even use a second callback!\n\t\tp.EachRecord(func(record *kgo.Record) {\n\t\t\tfmt.Println(string(record.Value), &quot;from a second callback!&quot;)\n\t\t})\n\t})\n}"},"notes/Kafka/kafka-go":{"title":"kafka-go","links":["notes/Kafka/kafka-go","notes/Kafka/min.insync.replicas","notes/Kafka/segment.bytes","notes/Kafka/retention.bytes"],"tags":[],"content":"kafka-go\nSource:: github.com/segmentio/kafka-go\nСоздание топика\nТак как топик можно создать лишь при обращении к контроллеру (во всяком случае в kafka-go) сначала необходимо найти контроллер и подключиться к нему:\nconn, err := kafka.DialContext(ctx, &quot;tcp&quot;, *brokers)\nif err != nil {\n        log.Fatal(err)\n}\ndefer conn.Close()\n \ncontroller, err := conn.Controller()\nif err != nil {\n        panic(err.Error())\n}\nvar controllerConn *kafka.Conn\ncontrollerConn, err = kafka.Dial(&quot;tcp&quot;, net.JoinHostPort(controller.Host, strconv.Itoa(controller.Port)))\nif err != nil {\n        panic(err.Error())\n}\ndefer controllerConn.Close()\nДалее вызывается метод создания топика в который можно передать все параметры указанные в документации Kafka через поле ConfigEntries (min.insync.replicas, segment.bytes, retention.bytes и дургие)\ncontrollerConn.CreateTopics(kafka.TopicConfig{\n        Topic:             *name,\n        NumPartitions:     *partitions,\n        ReplicationFactor: *replicas,\n        ConfigEntries: []kafka.ConfigEntry{\n                // {ConfigName: &quot;min.insync.replicas&quot;, ConfigValue: &quot;2&quot;},\n                {ConfigName: &quot;segment.bytes&quot;, ConfigValue: &quot;2097152&quot;},\n                // {ConfigName: &quot;retention.bytes&quot;, ConfigValue: &quot;3145728&quot;},\n        },\n})"},"notes/Kafka/min.insync.replicas":{"title":"min.insync.replicas","links":["notes/Kafka/min.insync.replicas"],"tags":[],"content":"min.insync.replicas\nПараметр min.insync.replicas в Apache Kafka определяет минимальное количество реплик, которые должны быть в синхронизированном состоянии для того, чтобы запись в тему считалась успешной. Этот параметр важен для обеспечения надежности и доступности данных в распределенной системе.\nКогда producer отправляет сообщение в Kafka, он может настроить уровень подтверждений (acknowledgments) через параметр acks. Если установлен режим acks=all, то запись будет считаться успешной только в том случае, если как минимум min.insync.replicas реплик подтвердят получение сообщения. Это помогает избежать потери данных в случае сбоя одной или нескольких реплик.\nНапример, если у нас есть топик с тремя репликами и мы установили min.insync.replicas=2, это значит, что для успешной записи сообщения как минимум две из трех реплик должны быть в синхронизированном состоянии. Если количество синхронизированных реплик падает ниже этого порога, producer будет получать ошибки при попытке записать сообщения, что позволяет предотвратить потерю данных."},"notes/Kafka/retention.bytes":{"title":"retention.bytes","links":["notes/Kafka/retention.bytes"],"tags":[],"content":"retention.bytes\nПараметр retention.bytes в Apache Kafka определяет максимальный размер данных, который может храниться в топике. Если размер данных в топике превышает указанное значение retention.bytes, Kafka начнет удалять самые старые сообщения, чтобы освободить место для новых.\nЭтот параметр позволяет управлять объемом хранимых данных и может быть полезен для контроля за использованием дискового пространства. Если вы хотите сохранить только определенное количество байтов данных в топике, вы можете установить это значение. Если параметр не установлен, по умолчанию используется значение -1, что означает отсутствие ограничения по размеру."},"notes/Kafka/segment.bytes":{"title":"segment.bytes","links":["notes/Kafka/segment.bytes"],"tags":[],"content":"segment.bytes\nПараметр segment.bytes в конфигурации темы (topic) Kafka определяет максимальный размер сегмента, который может быть создан в логах конкретной темы. Сегменты — это файлы, в которые Kafka записывает данные, и они хранятся на диске.\nКогда размер сегмента достигает указанного значения segment.bytes, Kafka создает новый сегмент для записи новых сообщений. Это помогает управлять объемом данных, которые находятся в одном сегменте, и облегчает операции, такие как очистка или удаление старых данных.\nПо умолчанию значение segment.bytes обычно составляет 1 ГБ, но его можно настроить в зависимости от потребностей вашего приложения и доступной вычислительной мощности. Установка более низкого значения может привести к более частым операциям записи, но может улучшить управление данными, в то время как более высокое значение может снизить количество файлов на диске и повысить производительность чтения, но усложнить удаление старых данных."},"notes/Kafka/Работа-с-Kafka-в-Golang":{"title":"Работа с Kafka в Golang","links":["notes/Kafka/Работа-с-Kafka-в-Golang","notes/Kafka/kafka-go","notes/Kafka/franz-go"],"tags":[],"content":"Работа с Kafka в Golang\n\nkafka-go\nfranz-go\n"},"notes/Kerberos":{"title":"Kerberos","links":["notes/Kerberos"],"tags":[],"content":"Kerberos\nСоздание keytab-файла\n\nktutil\naddent -password -p login@DOMAIN.RU -k 1 -e aes256-cts-hmac-sha1-96\nУказываем пароль\nwkt sa0000techdq.keytab\n\nПросмотр файла\n[root@host keytabs]# klist -kt login.keytab -e\nKeytab name: FILE:login.keytab\nKVNO Timestamp         Principal\n---- ----------------- --------------------------------------------------------\n1 03/30/23 15:24:47 login@DOMAIN.RU (aes256-cts-hmac-sha1-96)\n\nkinit\nkinit -kt login.keytab login@DOMAIN.RU  "},"notes/Krew":{"title":"Krew","links":[],"tags":["reference/kubernetes"],"content":"Krew\nМенеджер плагинов для kubectl.\nGitHub\nДокументация\nУстановка\n\nДля установки необходим git\nВыполнить эту команду в консоли\n\n(\n  set -x; cd &quot;$(mktemp -d)&quot; &amp;&amp;\n  OS=&quot;$(uname | tr &#039;[:upper:]&#039; &#039;[:lower:]&#039;)&quot; &amp;&amp;\n  ARCH=&quot;$(uname -m | sed -e &#039;s/x86_64/amd64/&#039; -e &#039;s/\\(arm\\)\\(64\\)\\?.*/\\1\\2/&#039; -e &#039;s/aarch64$/arm64/&#039;)&quot; &amp;&amp;\n  KREW=&quot;krew-${OS}_${ARCH}&quot; &amp;&amp;\n  curl -fsSLO &quot;github.com/kubernetes-sigs/krew/releases/latest/download/${KREW}.tar.gz&quot; &amp;&amp;\n  tar zxvf &quot;${KREW}.tar.gz&quot; &amp;&amp;\n  ./&quot;${KREW}&quot; install krew\n)\n\nДобавить путь $HOME/.krew/bin в $PATH.\nЗапустить kubectl krew чтобы проверить, что всё нормально.\n"},"notes/Linux-cd-back-to-1-step":{"title":"Linux cd back to 1 step","links":[],"tags":["reference/unix"],"content":"Linux cd back to 1 step\nДля того чтобы вернуться в предыдущую директорию в shell Linux можно выполнить команду cd - она вернёт нас в предыдущую директорию."},"notes/Locate-в-MacOS":{"title":"Locate в MacOS","links":["notes/Locate-в-MacOS"],"tags":["reference/macos"],"content":"Locate в MacOS\nАналог линуксового updatedb: sudo /usr/libexec/locate.updatedb"},"notes/MPP":{"title":"MPP","links":["notes/MPP"],"tags":[],"content":"MPP\nMPP, также известная как массивно-параллельная архитектура, является типом распределенной параллельной вычислительной архитектуры, которая представляет собой систему, состоящую из нескольких серверов или узлов, каждый из которых выполняет свою собственную часть задачи. Задача делится на отдельные компоненты, которые выполняются на разных узлах параллельно, а результаты совмещаются для получения конечного решения. Этот подход может обеспечить более эффективное выполнение задач, требующих больших объемов данных или сложных вычислений, но он также может быть более сложен для настройки и управления, чем другие типы параллельных вычислений.\n"},"notes/MagicMouse-speed-settings":{"title":"MagicMouse speed settings","links":["notes/MagicMouse-speed-settings"],"tags":["reference/macos"],"content":"MagicMouse speed settings\nНастройка скорости движения magic mouse:\ndefaults write -g com.apple.mouse.scaling 15"},"notes/MongoDB-CRUD":{"title":"MongoDB CRUD","links":["notes/Презентации-Teta/mongodb_slides/MongoDB.-Презентация"],"tags":["reference/mongodb"],"content":"CRUD операции MongoDB\nСоздание документа\ndb.books.insertOne(\n  {\n    title: &quot;gRPC: запуск и эксплуатация облачных приложений. Go и Java для Docker и Kubernetes&quot;, \n    author: &quot;Касун Индрасири&quot;, \n    year: 2020\n  }\n)\n \n{\n  acknowledged: true,\n  insertedId: ObjectId(&quot;635988799c0531ba95d3586d&quot;)\n}\nСоздание нескольких документов\ndb.books.insertMany(\n  [\n    {title:&quot;Go: идиомы и паттерны проектирования&quot;,author:&quot;Боднер Джон&quot;,&quot;year&quot;:2022},\n    {title:&quot;Высоконагруженные приложения. Программирование, масштабирование, поддержка&quot;,author:&quot;Клеппман Мартин&quot;,year:2021}\n  ]\n)\nПоиск документов\nQuery\n// Найти все документы\ndb.books.find()\n// Найти документы по совпадению конкретного поля\ndb.books.find({year: 2021})\n// Найти документы по условию на кокретное поле\ndb.books.find({year: {$gte: 2021}})\n// Найти документы по условию на кокретное поле и вернуть первый\ndb.books.findOne({year: {$gte: 2021}})\n// Найти документа по одному ИЛИ по второму условию.\ndb.books.find({$or:[{year:{$gte: 2021}},{author: &quot;Касун Индрасири&quot;}]})\nProjection\ndb.books.findOne({year: {$gte: 2021}},{ title:1, _id: 0 })\ndb.books.findOne({year: {$gte: 2021}},{ title:0, _id: 0 })\nОбновление документов\ndb.collection.updateOne(&lt;filter&gt;, &lt;update&gt;, &lt;options&gt;)\ndb.collection.updateMany(&lt;filter&gt;, &lt;update&gt;, &lt;options&gt;)\ndb.collection.replaceOne(&lt;filter&gt;, &lt;update&gt;, &lt;options&gt;)\nupdateOne\ndb.books.updateOne(\n  {\n  title: &quot;Высоконагруженные приложения. Программирование, масштабирование, поддержка&quot;\n  },\n  {$set: {rating: 5}}\n)\n{\n  acknowledged: true,\n  insertedId: null,\n  matchedCount: 1,\n  modifiedCount: 1,\n  upsertedCount: 0\n}\n\nUpdate Operators reference\nТак же может быть передан документ содержащий дополнительные параметры обновления. Подробнее в документации.\n\nupdateMany\ndb.books.updateMany(\n  {rating: null},\n  {$set:\n    {rating: 3}\n  }\n)\n{\n  acknowledged: true,\n  insertedId: null,\n  matchedCount: 2,\n  modifiedCount: 2,\n  upsertedCount: 0\n}\n\nРазные операторы в MongoDB по разному обрабатывают значение null. Подробнее в документации.\n\nreplaceOne\ndb.books.replaceOne(\n  {author: &#039;Ньюмен Сэм&#039;},\n  {\n    title:&quot;Создание микросервисов&quot;,\n    author: &quot;Ньюмен Сэм&quot;,\n    year: 2016,\n    rating:3\n  },\n  {upsert:true}\n)\n\nПример притянут за уши и показывает в основном создание документа в рамках замены. Но можно так же и обновить или вставить.\n\nupsert - разрешает вставить если не найден результат.\n\n\n\nMongoDB. Презентация - презентация по MongoDB в рамках курса HSE."},"notes/NTLM-авторизация-в-httpie":{"title":"NTLM авторизация в httpie","links":["notes/NTLM-авторизация-в-httpie"],"tags":["reference/unix"],"content":"NTLM авторизация в httpie\npip install httpie-ntlm\n/usr/local/Cellar/httpie/3.2.2/libexec/bin/python3.11 -m pip install httpie-ntlm\nhttp newportal.site.ru --verify=false --auth-type=ntlm -a &quot;DOMAIN\\\\login:password&quot;"},"notes/Neo4j":{"title":"Neo4j","links":["notes/Neo4j","notes/Cypher","notes/neo4j-в-Golang"],"tags":[],"content":"Neo4j\nNeo4j — это графовая база данных, которая позволяет хранить и обрабатывать данные в виде графов. В отличие от традиционных реляционных баз данных, Neo4j использует узлы (nodes) и связи (relationships) для представления информации, что делает её особенно эффективной для работы с сложными взаимосвязями между данными.\nС помощью языка запросов Cypher пользователи могут легко выполнять операции по извлечению, обновлению и анализу данных. Neo4j находит широкое применение в различных областях, таких как анализ социальных сетей, управление логистикой, рекомендации и многие другие приложения, где важны связи между объектами.\nDocker\nКоманда запуска сервера в Docker для локальной разработки:\n \ndocker run -d --name neo4j -p7474:7474 -p7687:7687 -e NEO4J_AUTH=neo4j/password neo4j\n \n\nНа порту 7474 будет доступен веб интерфейс Neo4j: http://localhost:7474\nПорт 7687 используется для подключения к базе данных через Bolt-протокол.\nПро Bolt можно детальнее почитать тут.\n\nChildren:: neo4j в Golang"},"notes/OLTP-vs-OLAP":{"title":"OLTP vs OLAP","links":["notes/OLTP-vs-OLAP","notes/Высоконагруженные-приложения","notes/Olap-Cube"],"tags":[],"content":"OLTP vs OLAP\nОбработка транзакций или аналитика?\nДва основных паттерна запросов к БД:\n\n\n                  \n                  OLTP \n                  \n                \n\nOnline transaction processing. Обработка транзакций в реальном времени.\n\n\n\n\n                  \n                  OLAP \n                  \n                \n\nOnline analytical processing. Аналитическая обработка данных в реальном времени.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nСвойствоСистемы обработки транзакций (OLTP)Аналитические системы (OLAP)Основной паттерн чтенияНебольшое количество записей на один запрос, извлекаются по ключуАгрегирование по большому количеству записейОсновной паттерн записиПроизвольный доступ, операции записи с низким значением задержки на основе вводимых пользователем данныхГрупповой импорт (ETL) или поток событийВ основном применяетсяКонченными пользователям/заказчиками, через веб-приложенияШтатным аналитиком, для поддержки принятия решенияКакие данные отражаетАктуальное состояние данных (текущий момент времени)Историю событий, происходивших на протяжении отрезка времениРазмер набора данныхОт гигабайтов до терабайтовОт терабайтов до петабайтов\nParent:: Высоконагруженные приложения\nFriend:: Olap Cube"},"notes/OTEL/Exporter":{"title":"Exporter","links":["notes/OTEL/Exporter","notes/OTEL/OTLP","notes/00_GRPC"],"tags":[],"content":"Exporter\nExporter - это плагин который определяет формат и приемник данных для полученных от процессора данных.\nПо умолчанию используется экспортер OTLP (OpenTelemetry Protocol). OTLP реализован через три транспортных протокола:\nВариант по умолчанию: http/protobuf\nОсновные параметры OTLP\n\nПротокол. OTLP реализован через три транспортных протокола:\n\ngRPC\nhttp/protobuf\nhttp/json\n\n\nEndpoint. URL, к которому обращается экспортер для отправки интервалов или метрик. Значения по умолчанию - http://localhost:4318 для HTTP и http://localhost:4317 для gRPC.\nHeaders. Дополнительные заголовки HTTP\nСжатие. Используется для включения сжатия GZip.\nTimeout. Максимальное время ожидания экспортирования каждого пакета экспортером OTLP. Значение по умолчанию - 10 секунд.\nНастройки TLS\n"},"notes/OTEL/LogRecordExporter":{"title":"LogRecordExporter","links":["notes/OTEL/LogRecordExporter"],"tags":[],"content":"LogRecordExporter\nLogRecordExporters генерирует журнальные данные в разнообразных популярных форматах. Как и с другими сигналами, мы рекомендуем использовать экспортер OTLP."},"notes/OTEL/LogRecordProcessor":{"title":"LogRecordProcessor","links":["notes/OTEL/LogRecordProcessor","notes/OTEL/SpanProcessor","notes/OTEL/OTEL-Collector"],"tags":[],"content":"LogRecordProcessor\nLogRecordProcessor работает так же, как SpanProcessor.\nПо умолчанию используется пакетный обработчик, через который регистрируются экспортеры.\nКак и в случае с пакетным обработчиком интервалов, имеет смысл снизить параметр конфигурации scheduledDelayMillis при отправке данных локальному экземпляру Collector."},"notes/OTEL/LoggerProvider":{"title":"LoggerProvider","links":["notes/OTEL/LoggerProvider","notes/OTEL/LogRecordProcessor","notes/OTEL/LogRecordExporter"],"tags":[],"content":"LoggerProvider\nLoggerProvider реализует API ведения журнала в OpenTelemetry.\nОн состоит из LogRecordProcessor и LogRecordExporter."},"notes/OTEL/MeterProvider":{"title":"MeterProvider","links":["notes/OTEL/MeterProvider","notes/OTEL/MetricReader","notes/OTEL/MetricProducer","notes/OTEL/MetricExporter","notes/OTEL/Views"],"tags":[],"content":"MeterProvider\nMeterProvider реализует API метрик OpenTelemetry. Он состоит из представлений (view), MetricReader, MetricProducer и MetricExporter.\n\nMeterProvider объединяет в себе:\n\nMetricReader\nMetricProducer\nMetricExporter\nViews\n"},"notes/OTEL/MetricExporter":{"title":"MetricExporter","links":["notes/OTEL/MetricExporter","notes/OTEL/OTLP","notes/OTEL/OTEL-Collector"],"tags":[],"content":"MetricExporter\nMetricExporter отправляет пакеты метрик по сети. Как и в случае с трассировками, лучше всего использовать экспортер OTLP для отправки телеметрии Collector."},"notes/OTEL/MetricProducer":{"title":"MetricProducer","links":["notes/OTEL/MetricProducer","notes/OTEL/MetricReader"],"tags":[],"content":"MetricProducer\nMetricProducer в OTEL — это интерфейс, который отвечает за соединение SDK OpenTelemetry и сторонних средств инструментирования (например Prometheus).\nКаждая реализация MetricProducer регистрируется с MetricReader.\nНапример вот реализация MetricProducer для Prometheus в Golang - pkg.go.dev/go.opentelemetry.io/contrib/bridges/prometheus."},"notes/OTEL/MetricReader":{"title":"MetricReader","links":["notes/OTEL/MetricReader","notes/OTEL/SpanProcessor","notes/OTEL/MetricExporter"],"tags":[],"content":"MetricReader\nMetricReader это эквивалент SpanProcessor для метрик. Он их собирает и буфферизирует. Дефолтная реализация - PeriodicExportingMetricReader.\nPeriodicExportingMetricReader\nСобирает метрики в пакет, а затем отправляет их в MetricExporter.\nОсновные параметры:\n\nexportIntervalMillis - Интервал между двумя последовательными экспортированиями, в миллисекундах. Значение по умолчанию равно 60 000.\nexportTimeoutMillis - Продолжительность выполнения процедуры экспортирования до момента ее отмены, в миллисекундах. Значение по умолчанию равно 30 000.\n"},"notes/OTEL/OTEL-API":{"title":"OTEL API","links":["notes/OTEL/OTEL-API"],"tags":[],"content":"OTEL API"},"notes/OTEL/OTEL-Baggage.-Golang":{"title":"OTEL Baggage. Golang","links":["notes/OTEL/OTEL-Baggage.-Golang"],"tags":["reference/golang"],"content":"OTEL Baggage. Golang\nb, _ := baggage.NewMember(&quot;key&quot;, &quot;value&quot;)\nbag, _ := baggage.New(b)\nctx = baggage.ContextWithBaggage(ctx, bag)\nИсходный контекст в этом примере мог быть создан например при старте нового span’а. И если потом сделать его Inject то он передастся как http заголовок:\notel.GetTextMapPropagator().Inject(ctx, propagation.HeaderCarrier(w.Header()))\nИзвлечение пришедшей таким образом информации:\nctx := otel.GetTextMapPropagator().Extract(r.Context(), propagation.HeaderCarrier(r.Header))\n \nbag := baggage.FromContext(ctx)\n_, span := tracer.Start(ctx, &quot;second&quot;)\ndefer span.End() \nfmt.Println(bag.Member(&quot;key&quot;).Value())\n\n\n                  \n                  TextMapPropogator \n                  \n                \n\nВажно при объявлении TextMapPropogator использовать композитный “пропогатор” и добавить к стандартной TraceContext так же Baggage: otel.SetTextMapPropagator(propagation.NewCompositeTextMapPropagator(propagation.TraceContext{}, propagation.Baggage{}))\n\n"},"notes/OTEL/OTEL-Collector":{"title":"OTEL Collector","links":["notes/OTEL/OTEL-Collector"],"tags":[],"content":"OTEL Collector\n\n Описать настройку коллектор\n  Описать Collector builder\n"},"notes/OTEL/OTEL-Logs":{"title":"OTEL Logs","links":["notes/OTEL/OTEL-Logs","notes/OTEL/OTEL-Metrics","notes/OTEL/OTEL-Tracing","notes/OTEL/LoggerProvider"],"tags":[],"content":"OTEL Logs\nИсторически самый первый из сигналов наблюдаемости. Тем не менее имеет самую слабую корреляцию c OTEL Metrics и OTEL Tracing.\nВ целом легко заменяется на трасировку.\n“Ручка” для управления API логов в OTEL - LoggerProvider."},"notes/OTEL/OTEL-Metrics":{"title":"OTEL Metrics","links":["notes/OTEL/OTEL-Metrics","notes/OTEL/Контексты-наблюдаемости","notes/OTEL/Жесткий-контекст","notes/OTEL/MeterProvider"],"tags":[],"content":"OTEL Metrics\nГлавной проблемой метрик в общем случае является отсутствие контекста. Не всегда можно однозначно и просто соотнести измеренные цифры и события в системе.\nДля решения этой проблемы существует сущность в Otel Exemplars - особая разновидность жесткого контекста.\nТакие метрики в OpenTelemetry позволяют связывать агрегированные метрики с конкретными событиями или контекстом, что помогает глубже понять причины изменения этих метрик.\n“Ручка” для управления API метрик в OTEL - MeterProvider."},"notes/OTEL/OTEL-Resource":{"title":"OTEL Resource","links":["notes/OTEL/OTEL-Resource","notes/OTEL/OTEL-SDK","Resources-в-Golang","Resources-в-Java","Resources-в-Collector"],"tags":[],"content":"OTEL Resource\nРесурсы — это набор атрибутов, которые описывают сущность, создающую телеметрию, в контексте API OpenTelemetry. Они предоставляют контекст для данных телеметрии, таких как метрики, логи и трейсы, и помогают идентифицировать источник этих данных.\nАтрибуты — это пары ключ-значение, которые описывают характеристики ресурса в OpenTelemetry, такие как имя хоста, версия программного обеспечения или среда выполнения, и предоставляют дополнительный контекст для данных телеметрии.\nАтрибуты определяются на уровне SDK и являются одним из компонентов всех трёх сущностей провайдеров.\n\n\n                  \n                  Semantic Conventions \n                  \n                \n\nПроект OpenTelemetry представляет стандартные названия для большого количества типовых атрибутов. Следует использовать их, а не изобретать свои.\n\n\nРесурсы сервиса\nСуществует набор ресурсов которые должны быть определены так как не могут быть получены другими методами. Они представляют собой по сути набор атрибутов описывающих сам сервис, что важно многим (почти всем) инструментам хранения и анализа.\n\nservice.name - логическое имя сервиса. Должно быть единым на всех инстансах если сервис горизонтально масштабирован.\nservice.namespace - Имя сервиса не всегда уникально и их можно группировать с неймспейсы.\nservice.instance.id - уникальный идентификатор сервиса. Должно быть уникально при горизонтальном мастшабировани у каждого экземпляра сервиса.\nservice.version - версия та же что в системе контроля версий.\n\nДетекторы ресурсов\nБольшинство SDK для конкретных языков предоставляют набор детекторов ресурсов, которые можно использовать для автоматического обнаружения информации о ресурсах из окружения\n\nResources в Golang\nResources в Java\nResources в Collector\n"},"notes/OTEL/OTEL-SDK":{"title":"OTEL SDK","links":["notes/OTEL/OTEL-SDK","notes/OTEL/Сигналы-Наблюдаемости","notes/OTEL/TracerProvider","notes/OTEL/MeterProvider","notes/OTEL/LoggerProvider","notes/OTEL/Инициализация-OTEL-в-Golang"],"tags":[],"content":"OTEL SDK\nSDK представляет собой подключаемый фреймворк, состоящий из алгоритмов выборки, перехватчиков жизненного цикла и экспортеров, которые могут настраиваться при помощи переменных окружения или конфигурационных файлов YAML.\nОбъекты провайдеры в SDK необходимы для взаимодействия с API OpenTelemetry трёх основных сигналов наблюдаемости.\n\n\nTracerProvider\n\n\nMeterProvider\n\n\nLoggerProvider\n\n\n Описать варианты конфигурации SDK:\n\n Код\n Переменные\n Конфигурационный файл.\n\n\n\nПримеры работы с SDK\n\nИнициализация OTEL в Golang\n"},"notes/OTEL/OTEL-Tracing":{"title":"OTEL Tracing","links":["notes/OTEL/OTEL-Tracing","span","notes/OTEL/Контексты-наблюдаемости","notes/OTEL/Золотые-сигналы","notes/OTEL/TracerProvider"],"tags":[],"content":"OTEL Tracing\nIntro\nТрассировка (trace) представляет собой механизм моделирования работы распределенной системы.\nВся трасса (интервал, или трейс) состоит из отдельных спанов (span) связанных с друг другом через жёсткий контекст\nВ целом можно рассматривать трассировку как набор журналов связанных через общий идентификатор.\nТак как трассировка может быть преобразована в другие сигналы получается, что один trace может содержать в себе всю необходимую информацию для вычисления всех золотых сигналов.\n“Ручка” для управления API трейсов в OTEL - TracerProvider."},"notes/OTEL/OTEL.-Golang":{"title":"OTEL. Golang","links":["notes/OTEL/OTEL.-Golang","notes/OTEL/Инициализация-OTEL-в-Golang","notes/OTEL/Автоматическое-инструментирование-http.Handler-OTEL","notes/OTEL/Проброс-span-через-HTTP-в-Opentelemetry","notes/OTEL/Проброс-span-Opentelemetry-через-текстовое-поле","notes/OTEL/Инструментирование-OTEL-MongoDB","notes/OTEL/Инструментирование-OTEL-Redis-(KeyDB)","notes/OTEL/Инструментирование-OTEL-neo4j"],"tags":["reference/golang"],"content":"OTEL. Golang\n\nChildren:: Инициализация OTEL в Golang\nChildren:: Автоматическое инструментирование http.Handler OTEL\nChildren:: Проброс span через HTTP в Opentelemetry\nChildren:: Проброс span Opentelemetry через текстовое поле\n\nИнструментирование сервисов\n\nChildren:: Инструментирование OTEL MongoDB\nChildren:: Инструментирование OTEL Redis (KeyDB)\nChildren:: Инструментирование OTEL neo4j\n"},"notes/OTEL/OTEL.-Java":{"title":"OTEL. Java","links":["notes/OTEL/OTEL.-Java"],"tags":[],"content":"OTEL. Java\nSource:: github.com/open-telemetry/opentelemetry-java-examples/tree/main"},"notes/OTEL/OTLP":{"title":"OTLP","links":["notes/OTEL/OTLP","notes/OTEL/OTEL-Collector","notes/00_GRPC"],"tags":[],"content":"OTLP\nSource:: opentelemetry.io/docs/specs/otlp/\nOpenTelemetry Protocol (OTLP) - спецификация описывающая механизмы сбора и передачи данных между источниками, промежуточными узлами обработки (такими как Collector) и бекендами хранения для данных телеметрии.\nOTLP описывает сериализацию данных телеметрии и протокол для ее передачи между узлами.\nФорматом сериализации является gRPC.\nПротокол поддерживает следующие основные способы передачи данных:\n\nOTLP/gRPC\nOTLP/HTTP - HTTP вызовы передающие protobuf данные.\n\nСпецификация позволяет также передавать через HTTP данные в JSON формате.\n\n\n"},"notes/OTEL/OpenTelemetry-Baggage":{"title":"OpenTelemetry Baggage","links":["notes/OTEL/OpenTelemetry-Baggage","notes/OTEL/Мягкий-контекст","notes/OTEL/OTEL-Baggage.-Golang"],"tags":[],"content":"OpenTelemetry Baggage\nЕсли возникает ситуация при которой вместе с сигналом телеметрии (например trace’ом) необходимо передать так же и некую метаинформацию Open Telemetry предлагает использовать механизм Baggage.\nИными словами такая метаинформация называется мягким контекстом.\nПо сути baggage это способ передать key-value пары (возможно с некоторыми дополнительными свойствами) независимым от платформы способом. Точно так же как мы извлекаем информацию о span можно извлечь информацию о таких парах.\nПримеры использования\n\nGolang\n\nSource:: opentelemetry.io/docs/concepts/signals/baggage/"},"notes/OTEL/OpenTelemetry-в-K8S":{"title":"OpenTelemetry в K8S","links":["notes/OTEL/OpenTelemetry-в-K8S","notes/OTEL/OTEL-Collector","notes/OTEL/Инициализация-OTEL-в-Golang","notes/Deployment"],"tags":["reference/kubernetes"],"content":"OpenTelemetry в K8S\nОписание\nOpenTelemetry Operator позволяет:\n\nСоздавать инстансы Collector в различных режимах.\nСоздавать шаблон sidecar контейнера который будет запущен в тех подах на которые повесим нужную аннотацию.\nСоздавать объекты instrumentation которые (при соответствующей аннотации) автоматически настроят код сервиса на работу с OTEL.\n\nУстановка\ncert-manager\nkubectl apply -f github.com/cert-manager/cert-manager/releases/download/v1.13.2/cert-manager.yaml\nOpenTelemetry Operator\nkubectl apply -f github.com/open-telemetry/opentelemetry-operator/releases/latest/download/opentelemetry-operator.yaml \nJaeger\nЭто лишь бэкенд для хранения метрик. Можно настроить любую другую систему\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: opentelemetry\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: jaeger-all-in-one\n  namespace: opentelemetry\n  labels:\n    app: opentelemetry\n    component: otel-collector\nspec:\n  ports:\n    - port: 4317\n      protocol: TCP\n      targetPort: grpc\n  selector:\n    component: otel-collector\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: jaeger-all-in-one-ui\n  namespace: opentelemetry\n  labels:\n    app: opentelemetry\n    component: otel-collector\nspec:\n  ports:\n    - name: jaeger\n      port: 16686\n      protocol: TCP\n      targetPort: 16686\n  selector:\n    component: otel-collector\n  type: LoadBalancer\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger-all-in-one\n  namespace: opentelemetry\n  labels:\n    app: opentelemetry\n    component: otel-collector\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: opentelemetry\n      component: otel-collector\n  template:\n    metadata:\n      labels:\n        app: opentelemetry\n        component: otel-collector\n    spec:\n      containers:\n        - image: jaegertracing/all-in-one:1.52\n          name: jaeger\n          ports:\n            - containerPort: 16686\n            - containerPort: 14268\n            - containerPort: 14250\n            - containerPort: 4317\n              name: grpc\nOtelcoll\nЭтот коллектор otel в текущем примере будет являться общим шлюзом получающим данные от sidecar контейнеров. Таким образом достаточно поменять лишь его настройки, а основную систему не трогать.\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  name: otel-collector\n  namespace: opentelemetry\n  labels:\n    app: opentelemetry\n    component: otel-collector\nspec:\n  ports:\n    - port: 4318\n      name: &quot;grpc&quot;\n  config: |\n    receivers:\n      otlp:\n        protocols:\n          grpc:\n          http:\n    exporters:\n      otlp:\n        endpoint: jaeger-all-in-one.opentelemetry.svc.cluster.local:4317\n        tls:\n          insecure: true\n      logging:\n    processors:\n      batch:\n      resource:\n        attributes:\n          - key: test.key\n            value: &quot;test-value&quot;\n            action: insert\n    extensions:\n      health_check:\n      zpages:\n        endpoint: :55679\n    service:\n      telemetry:\n        logs:\n          level: &quot;debug&quot;\n      extensions: [zpages, health_check]\n      pipelines:\n        traces:\n          receivers: [otlp]\n          processors: [batch, resource]\n          exporters: [logging, otlp]\nSIdecar\nЭто в своём роде шаблон контейнера который будет запускаться внутри каждого пода имеющего соответствующую аннотацию.\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  name: sidecar\nspec:\n  mode: sidecar\n  config: |\n    receivers:\n      otlp:\n        protocols:\n          grpc:\n          http:\n    processors:\n      batch:\n    exporters:\n      logging:\n      otlp:\n        endpoint: &quot;otel-collector-collector.opentelemetry.svc.cluster.local:4317&quot;\n        tls:\n          insecure: true\n    service:\n      telemetry:\n        logs:\n          level: &quot;debug&quot;\n      pipelines:\n        traces:\n          receivers: [otlp]\n          processors: []\n          exporters: [logging, otlp]\nInstrumentation\nРесурс k8s, что определяет настройки otel которые будут вставлены в запущенный сервис. Иными словами например Инициализация OTEL в Golang не требуется. Достаточно создать такой объект и повесить нужные аннотации.\napiVersion: opentelemetry.io/v1alpha1\nkind: Instrumentation\nmetadata:\n  name: demo-instrumentation\nspec:\n  propagators:\n    - tracecontext\n    - baggage\n  sampler:\n    type: parentbased_traceidratio\n    argument: &quot;1&quot;\nАннотации сервиса\n\nsidecar.opentelemetry.io/inject: &quot;sidecar&quot; - подключит в pod sidecar.\ninstrumentation.opentelemetry.io/inject-java: &quot;true&quot; - подключит код внутрь запущенного сервиса. На Golang у меня не завелось.\n\nDeployment целиком\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rules-generator\n  labels:\n    app: rules-generator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rules-generator\n  template:\n    metadata:\n      labels:\n        app: rules-generator\n      annotations:\n        sidecar.opentelemetry.io/inject: &quot;sidecar&quot;\n        instrumentation.opentelemetry.io/inject-java: &quot;true&quot;\n    spec:\n      containers:\n        - name: rules-generator\n          image: maksim77/rules:0.0.1\n          ports:\n            - containerPort: 12346\n            - containerPort: 9999\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: rules-generator-service\n  labels:\n    app: rules-generator\nspec:\n  selector:\n    app: rules-generator\n  type: NodePort\n  ports:\n    - protocol: TCP\n      port: 9999\n      targetPort: 9999"},"notes/OTEL/OpenTelemetry":{"title":"OpenTelemetry","links":["notes/OTEL/OpenTelemetry","notes/OTEL/Тед-Янг,-Остин-Паркер-Изучаем-OpenTelemetry","notes/OTEL/OTEL-API","notes/OTEL/OTEL-SDK","notes/OTEL/OTEL-Collector","notes/OTEL/Сигналы-Наблюдаемости","notes/OTEL/Локальный-стенд-OpenTelemetry","notes/OTEL/OTEL.-Golang","notes/OTEL/OTEL.-Java","notes/OTEL/OpenTelemetry-в-K8S"],"tags":[],"content":"OpenTelemetry\n\nOpenTelemetry — это открытая платформа для наблюдаемости, которая предоставляет инструменты, API и SDK для сбора, обработки и экспорта телеметрических данных, таких как трассировки, метрики и логи.\n\n\n                  \n                   Изучаем OpenTelmetry\n                  \n                \n\n\nКнига O’Reily которая знатно помогла мне разобраться в платформе. Обязательна к прочтению.\n\n\nКомпоненты\nОсновные составляющие проекта OpenTelemetry включают:\n\nAPI: Набор интерфейсов, которые разработчики могут использовать для интеграции OpenTelemetry в свои приложения. API предоставляет стандартизированные методы для создания и управления телеметрическими данными.\nSDK: Набор инструментов и библиотек, которые реализуют API и предоставляют дополнительные возможности, такие как автоматический сбор данных, обработка и экспорт. SDK обычно включает в себя компоненты для работы с трассировками, метриками и логами. \nКоллектор (Collector): Самостоятельный сервис, который собирает, обрабатывает и экспортирует телеметрические данные из различных источников. Коллектор может быть развернут отдельно и использоваться для централизованного сбора данных.\nСпецификации: Документация и стандарты, которые определяют, как должны быть реализованы различные компоненты OpenTelemetry. Спецификации обеспечивают совместимость и интероперабельность между различными реализациями и инструментами.\n\n\n\n                  \n                  В то же время в OTEL нет и никогда не будет хранилищ для метрик или например GUI.\n                  \n                \n\nВся работа OpenTelemetry по сути сводится к сбору, обработке и передаче на хранение трёх сигналов наблюдаемости.\nИнструкция как поднять локальный стенд для тестирования OpenTelemetry - Локальный стенд OpenTelemetry.\n\n\nOTEL. Golang\nOTEL. Java\nOpenTelemetry в K8S\n\nFriend:: OpenTelemetry Registry"},"notes/OTEL/Span":{"title":"Span","links":["notes/OTEL/Span","notes/OTEL/Жесткий-контекст","notes/OTEL/OTEL-Resource"],"tags":[],"content":"Span\nSpan представляет собой основную единицу трассировки. Span — это отдельная операция в распределенной системе, которая содержит информацию о выполнении этой операции. Каждый Span включает в себя следующие ключевые элементы:\n\nИмя (Name): Описание операции, например, “GET /api/users”.\nКонтекст (Context): Уникальный идентификатор Span, который позволяет различать его среди других. Включает в себя идентификатор трейса (Trace ID) и идентификатор самого Span (Span ID).\nВременные метки (Timestamps): Время начала и окончания операции, что позволяет измерять её продолжительность.\nАтрибуты (Attributes): Набор ключ-значение, который содержит дополнительную информацию о Span, например, параметры запроса или метаданные.\nСобытия (Events): Хронологический список событий, которые произошли в течение выполнения Span.\nСтатус (Status): Информация о результате выполнения операции, например, успешное завершение или ошибка.\nСвязи (Links): Связи с другими Span’ами, которые могут быть полезны для представления сложных зависимостей между операциями.\n\nSpan’ы могут быть вложенными, образуя иерархию, которая отражает структуру выполнения операций в распределенной системе. Это позволяет разработчикам и администраторам отслеживать и анализировать поведение приложений, выявлять узкие места и оптимизировать производительность."},"notes/OTEL/SpanProcessor":{"title":"SpanProcessor","links":["notes/OTEL/SpanProcessor","notes/OTEL/OTEL-Collector","notes/OTEL/Exporter"],"tags":[],"content":"SpanProcessor\nSpanProcessor - компонент который предназначен для сбора и изменения трейсов. Он перехватывает трейс дважды: в начале и в конце.\nТакие обработчики могут выстраиваться в pipeline в порядке регистрации и этот порядок важен! Обработчики изменяющие телеметрию должны быть включен в конвейер раньше, чем например группирующие её.\nВ целом практически любые операции над телеметрией могут быть сделаны как в процессоре так и потом уже в Collector’e.\nBatchProcessor\nДефолтная реализация SpanProcessor. Он буферизует данные трейсов и управляет плагинами экспортеров.\nВ общем случае BatchProcessor устанавливается как последний объект SpanProcessor в конвейере обработки.\nОсновные параметры:\n\nexporter - экспортер, которому передаются интервалы.\nmaxQueueSize - максимальное количество интервалов, содержащихся в буфере. Все дополнительные интервалы отбрасываются. Значение по умолчанию равно 2048.\nscheduledDelayMillis - интервал по умолчанию в миллисекундах между двумя последовательными экспортированиями. Значение по умолчанию равно 5000.\nexportTimeoutMillis - продолжительность выполнения процедуры экспортирования до момента ее отмены. Значение по умолчанию равно 30 000.\nmaxExportBatchSize - Максимальное количество спанов в экспортировании. Если очередь достигает размера maxExportBatchSize, пакет будет экспортирован, даже если срок scheduledDelayMillis еще не истек. Значение по умолчанию равно 512.\n\n\n\n                  \n                  Значения по умолчанию \n                  \n                \n\nЕсли Collector запущен на локально хосте то значение параметра scheduledDelayMillis можно и нужно существенно уменьшить.\n\n"},"notes/OTEL/TracerProvider":{"title":"TracerProvider","links":["notes/OTEL/TracerProvider","notes/OTEL/OpenTelemetry","notes/OTEL/SpanProcessor","notes/Sampler","notes/OTEL/Exporter"],"tags":[],"content":"TracerProvider\nКомпонент SDK отвечающий за создание Tracer, его фабрика.\n\nTracerProvider объединяет в себе:\n\nSpanProcessor\nSampler\nExporter\n"},"notes/OTEL/Views":{"title":"Views","links":["notes/OTEL/Views","notes/OTEL/OTEL-Collector"],"tags":[],"content":"Views\nПредставления (Views) - инструмент для настройки метрик, выдаваемых SDK. Позволяет определить какие инструменты игнорируются, как они должны агрегировать данные и о каких атрибутах сообщать.\nПредставления так же могут создаваться на уровне Collector"},"notes/OTEL/W3C-Trace-Context":{"title":"W3C Trace Context","links":["notes/OTEL/W3C-Trace-Context"],"tags":[],"content":"W3C Trace Context\nЗаголовок HTTP отвечающий за передачу идентификатора span’а это traceparent.\nПример его содержимого:\ntraceparent: 00-0af7651916cd43dd8448eb211c80319c-b9c7c989f97918e1-01\n\nГде через дефис разделены следующие компоненты:\n\nversion - в настоящий момент всегда 00.\ntrace-id - основной идентификатор трэйса. Следует использовать именно его для поиска в системах типа Jaeger или Zipkin.\nparent-id - Идентификатор родительского Span’а.\ntrace-flags - служебные флаги\n\nSource:: www.w3.org/TR/trace-context/"},"notes/OTEL/Автоматическое-инструментирование-http.Handler-OTEL":{"title":"Автоматическое инструментирование http.Handler OTEL","links":["notes/OTEL/Автоматическое-инструментирование-http.Handler-OTEL"],"tags":["reference/golang"],"content":"Автоматическое инструментирование http.Handler OTEL\nДля того чтобы автоматически создавать span’ы для всех входящих HTTP запросов средствами OpenTelemetry можно следующим образом обернуть весь router Chi (или любой другой http.Handler):\nimport (\n&quot;github.com/go-chi/chi&quot;\n&quot;go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp&quot;\n)\n \nr := chi.NewRouter()\nwrappedHandler := otelhttp.NewHandler(r, &quot;hello-instrumented&quot;)\n \nhttp.ListenAndServe(&quot;:3000&quot;, wrappedHandler)"},"notes/OTEL/Жесткий-контекст":{"title":"Жесткий контекст","links":["notes/OTEL/Жесткий-контекст","notes/OTEL/W3C-Trace-Context"],"tags":[],"content":"Жесткий контекст\nЖесткий контекст — уникальный идентификатор уровня запроса, который может распространяться сервисами в распределенном приложении к другим сервисам, участвующим в обработке того же запроса.\nРеализация по умолчанию выбранная в проекте OpenTelemetry это W3C Trace Context."},"notes/OTEL/Золотые-сигналы":{"title":"Золотые сигналы","links":["notes/OTEL/Золотые-сигналы"],"tags":[],"content":"Золотые сигналы\nЗолотые сигналы — четыре критические характеристики, которые должны сниматься для системы, как указано в книге Google SRE Handbook.\n\nЗадержка (latency) — время, необходимое для обслуживания запроса\nТрафик (traffic) — количество запросов\nОшибки (errors) относительная доля ошибочных запросов\nНасыщение (saturation) — степень загрузки системных ресурсов.\n"},"notes/OTEL/Инициализация-OTEL-в-Golang":{"title":"Инициализация OTEL в Golang","links":["notes/OTEL/Инициализация-OTEL-в-Golang"],"tags":["reference/golang"],"content":"Инициализация OTEL в Golang\nКак можно раньше в коде следует выполнить блок инициализации телеметрии.\nБазовая инициализация\npackage main\n \nimport (\n\t&quot;context&quot;\n\t&quot;fmt&quot;\n\t&quot;log&quot;\n\t&quot;time&quot;\n \n\t&quot;go.opentelemetry.io/otel&quot;\n\t&quot;go.opentelemetry.io/otel/exporters/otlp/otlptrace&quot;\n\t&quot;go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc&quot;\n\t&quot;go.opentelemetry.io/otel/sdk/resource&quot;\n\tsdktrace &quot;go.opentelemetry.io/otel/sdk/trace&quot;\n\tsemconv &quot;go.opentelemetry.io/otel/semconv/v1.4.0&quot;\n)\n \nconst (\n\tTRACER_NAME = &quot;demo_service&quot;\n)\n \nfunc InstallExportPipeline() (func(context.Context) error, error) {\n\ttraceClient := otlptracegrpc.NewClient(\n\t\totlptracegrpc.WithInsecure(),\n\t\totlptracegrpc.WithEndpoint(&quot;0.0.0.0:4317&quot;),\n\t)\n \n\tsctx, cancel := context.WithTimeout(context.Background(), time.Second*5)\n\tdefer cancel()\n \n\ttraceExp, err := otlptrace.New(sctx, traceClient)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n \n\tif err != nil {\n\t\treturn nil, fmt.Errorf(&quot;creating stdout exporter: %w&quot;, err)\n\t}\n \n\tres, err := resource.New(context.Background(),\n\t\tresource.WithFromEnv(),\n\t\tresource.WithProcess(),\n\t\tresource.WithTelemetrySDK(),\n\t\tresource.WithHost(),\n\t\tresource.WithAttributes(\n\t\t\tsemconv.ServiceNameKey.String(TRACER_NAME),\n\t\t),\n\t)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n \n\ttracerProvider := sdktrace.NewTracerProvider(\n\t\tsdktrace.WithBatcher(traceExp),\n\t\tsdktrace.WithResource(res),\n\t)\n\totel.SetTracerProvider(tracerProvider)\n \n\treturn tracerProvider.Shutdown, nil\n}\nИспользование в основном коде\nconst (\n        TRACER_NAME = &quot;demo_service&quot;\n)\n \nvar tracer = otel.Tracer(TRACER_NAME)\n \nfunc main() {\n\tctx := context.Background()\n\tshutdown, err := InstallExportPipeline()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\nНу а далее от этого глобального tracer’а уже можно создавать спаны и\nжонглировать ими через контекст:\nnewCtx, span := tracer.Start(r.Context(), &quot;/&quot;)\ndefer span.End()"},"notes/OTEL/Инструментирование-OTEL-MongoDB":{"title":"Инструментирование OTEL MongoDB","links":["notes/OTEL/Инструментирование-OTEL-MongoDB","notes/OTEL/Инициализация-OTEL-в-Golang"],"tags":[],"content":"Инструментирование OTEL MongoDB\nПриведенный ниже пример не избавит от необходимости выполнять Инициализация OTEL в Golang но все дальнейшие подключения к монге будут покрываться спанами автоматически!\npackage main\n \nimport (\n        &quot;context&quot;\n        &quot;log&quot;\n        &quot;time&quot;\n \n        &quot;go.mongodb.org/mongo-driver/mongo&quot;\n        &quot;go.mongodb.org/mongo-driver/mongo/options&quot;\n        &quot;go.opentelemetry.io/contrib/instrumentation/go.mongodb.org/mongo-driver/mongo/otelmongo&quot;\n        &quot;go.opentelemetry.io/otel&quot;\n)\n \nvar tracer = otel.Tracer(&quot;mongo_example&quot;)\n \nconst URI = &quot;mongodb://127.0.0.1:27017&quot;\n \nfunc getClient(ctx context.Context) (*mongo.Client, error) {\n        ctx, span := FollowSpan(ctx, &quot;getClient&quot;)\n        defer span.End()\n \n        opts := options.Client()\n        opts.ApplyURI(URI)\n        optsAuth := options.Credential{\n                Username:   &quot;root&quot;,\n                Password:   &quot;example&quot;,\n                AuthSource: &quot;admin&quot;,\n        }\n \n        opts.SetAuth(optsAuth)\n \n        opts.Monitor = otelmongo.NewMonitor()\n \n        client, err := mongo.Connect(ctx, opts)\n        if err != nil {\n                return nil, err\n        }\n        return client, nil"},"notes/OTEL/Инструментирование-OTEL-Redis-(KeyDB)":{"title":"Инструментирование OTEL Redis (KeyDB)","links":["notes/OTEL/Инструментирование-OTEL-Redis-(KeyDB)"],"tags":[],"content":"Инструментирование OTEL Redis (KeyDB)\nДля покрытия трейсами Redis в Golang можно воспользоваться библиотекой github.com/XSAM/otelsql.\nСамо подключение очень простое и осуществляется примерно вот так:\nfunc initRedis() {\n\trdb = redis.NewClient(&amp;redis.Options{\n\t\tAddr: &quot;localhost:6379&quot;,\n\t})\n\tif err := redisotel.InstrumentTracing(rdb); err != nil {\n\t\tpanic(err)\n\t}\n}"},"notes/OTEL/Инструментирование-OTEL-neo4j":{"title":"Инструментирование OTEL neo4j","links":["notes/OTEL/Инструментирование-OTEL-neo4j","notes/Neo4j"],"tags":[],"content":"Инструментирование OTEL neo4j\nВместо стандартного создания драйвера Neo4j:\ndriver, err := neo4j.NewDriverWithContext(uri, neo4j.BasicAuth(username, password, &quot;&quot;))\n\tif err != nil {\n\t\tlog.Fatalf(&quot;Ошибка подключения к Neo4j: %v&quot;, err)\n\t}\nМожно воспользоваться библиотекой neo4j_tracing\n\tdriverFactory := neo4j_tracing.NewNeo4jTracer()\n\tdriver, err := driverFactory.NewDriverWithContext(uri, neo4j.BasicAuth(username, password, &quot;&quot;))\n\tif err != nil {\n\t\tpanic(err)\n\t}"},"notes/OTEL/Контексты-наблюдаемости":{"title":"Контексты наблюдаемости","links":["notes/OTEL/Контексты-наблюдаемости","notes/OTEL/Жесткий-контекст","notes/OTEL/Мягкий-контекст"],"tags":[],"content":"Контексты наблюдаемости\n\nВ OpenTelemetry существуют три основных типа контекста: время, атрибуты и сам объект контекста.\nИначе говоря, контексты переносят информацию через разрывы: между двумя сервисами, работающими на одном компьютере, через канал между разными серверами, через RPC либо между разными потоками в одном процессе\nВиды контекстов\n\nЖесткий контекст\nМягкий контекст\n"},"notes/OTEL/Локальный-стенд-OpenTelemetry":{"title":"Локальный стенд OpenTelemetry","links":["notes/OTEL/Локальный-стенд-OpenTelemetry"],"tags":[],"content":"Локальный стенд OpenTelemetry\nSource:: github.com/maksim77/otel_dev_stand\n.\n├── compose.yaml\n├── grafana\n│   └── datasource.yml\n├── LICENSE.md\n├── otel\n│   └── otel-collector-config.yaml\n├── prometheus\n│   └── prometheus.yml\n├── README.md\n└── TODO.md\n\ncompose.yml\nservices:\n  prometheus:\n    image: prom/prometheus\n    container_name: prometheus\n    command:\n      - &#039;--config.file=/etc/prometheus/prometheus.yml&#039;\n    ports:\n      - 9090:9090\n    volumes:\n      - ./prometheus:/etc/prometheus\n \n  grafana:\n    image: grafana/grafana\n    container_name: grafana\n    ports:\n      - 3000:3000\n    environment:\n      - GF_SECURITY_ADMIN_USER=admin\n      - GF_SECURITY_ADMIN_PASSWORD=grafana\n    volumes:\n      - ./grafana:/etc/grafana/provisioning/datasources\n \n  otel-collector:\n    image: otel/opentelemetry-collector:latest\n    container_name: otel-collector\n    command: [&quot;--config=/etc/otel-collector-config.yaml&quot;]\n    volumes:\n      - ./otel/otel-collector-config.yaml:/etc/otel-collector-config.yaml\n    ports:\n      - &quot;4317:4317&quot;  # OTLP gRPC receiver\n      - &quot;8889:8889&quot;  # Prometheus exposed port\n    depends_on:\n      - jaeger\n \n  jaeger:\n    image: jaegertracing/all-in-one:latest\n    container_name: jaeger\n    environment:\n      - COLLECTOR_OTLP_ENABLED=true\n      - COLLECTOR_OTLP_GRPC_HOST_PORT=:4317\n    ports:\n      - &quot;16686:16686&quot;\nPrometheus\nВ папке prometheus находится файл prometheus.yml. Просто собирает метрики со следующих таргетов:\n\nСам Prometheus\nGrafana\n\nglobal:\n  scrape_interval: 15s\n  scrape_timeout: 10s\n  evaluation_interval: 15s\nalerting:\n  alertmanagers:\n  - static_configs:\n    - targets: []\n    scheme: http\n    timeout: 10s\n    api_version: v2\nscrape_configs:\n- job_name: prometheus\n  honor_timestamps: true\n  scrape_interval: 15s\n  scrape_timeout: 10s\n  metrics_path: /metrics\n  scheme: http\n  static_configs:\n  - targets:\n    - localhost:9090\n- job_name: grafana\n  honor_timestamps: true\n  scrape_interval: 15s\n  scrape_timeout: 10s\n  metrics_path: /metrics\n  scheme: http\n  static_configs:\n  - targets:\n    - grafana:3000\n- job_name: otel-collector\n  honor_timestamps: true\n  scrape_interval: 15s\n  scrape_timeout: 10s\n  metrics_path: /metrics\n  scheme: http\n  static_configs:\n  - targets:\n    - otel-collector:8889\nGrafana\nДля автоматического добавления соседнего Prometheus в папке grafana расположен файл datasource.yml:\napiVersion: 1\n \ndatasources:\n- name: Prometheus\n  type: prometheus\n  url: http://prometheus:9090 \n  isDefault: true\n  access: proxy\n  editable: true\n- name: Jaeger\n  type: jaeger\n  url: http://jaeger:16686\n  access: proxy\n  editable: true\nJaeger\nВ рамках стенда поднимается jaeger-all-in-one. Дополнительных настроек или файлов не требует.\nOTEL collector\nНастройки находятся в файле otel-collector-config.yaml:\nreceivers:\n  otlp:\n    protocols:\n      grpc:\n        endpoint: 0.0.0.0:4317\n      http:\n       endpoint: 0.0.0.0:4318\nprocessors:\nexporters:\n  otlp:\n    endpoint: &quot;http://jaeger:4317&quot;\n    tls:\n      insecure: true\n  debug:\n    verbosity: detailed\n  prometheus:\n    endpoint: 0.0.0.0:8889\nservice:\n  pipelines:\n    traces:\n      receivers: [otlp]\n      processors: []\n      exporters: [otlp, debug]\n    metrics:\n      receivers: [otlp]\n      processors: []\n      exporters: [prometheus, debug]\n "},"notes/OTEL/Мягкий-контекст":{"title":"Мягкий контекст","links":["notes/OTEL/Мягкий-контекст"],"tags":[],"content":"Мягкий контекст\nМягкий контекст формируется различными фрагментами метаданных, которые присоединяются каждым инструментом телеметрии к различным сервисам и инфраструктуре, обрабатывающим тот же запрос, — например, идентификатором клиента."},"notes/OTEL/Проброс-span-Opentelemetry-через-текстовое-поле":{"title":"Проброс span Opentelemetry через текстовое поле","links":["notes/OTEL/Проброс-span-Opentelemetry-через-текстовое-поле","span"],"tags":["reference/golang"],"content":"Проброс span Opentelemetry через текстовое поле\nДля того чтобы пробросить span просто в текстовом виде можно выполнить следующее:\nm := make(map[string]string)\n \notel.GetTextMapPropagator().Inject(r.Context(), propagation.MapCarrier(m))\nпосле этого map’а m будет содержать id родительского span’а в ключе traceparent.\nТаким образом можно развернуть его обратно в контекст примерно вот так:\nm := make(map[string]string)\npm := propagation.MapCarrier(m)\npm.Set(&quot;traceparent&quot;, c[&quot;traceparent&quot;])\n \nctx := otel.GetTextMapPropagator().Extract(context.Background(), pm)\nПолученный контекст ctx можно будет использовать для создания дочернего span’а."},"notes/OTEL/Проброс-span-через-HTTP-в-Opentelemetry":{"title":"Проброс span через HTTP в Opentelemetry","links":["notes/OTEL/Проброс-span-через-HTTP-в-Opentelemetry","notes/OTEL/Span","notes/OTEL/OpenTelemetry"],"tags":["reference/golang"],"content":"Проброс span через HTTP в Opentelemetry\nДля того чтобы пробросить Span OpenTelemetry, а точнее конечно же его ID через http запрос можно использовать следующую схему.\n\nПри начальной настройке объекта otel необходимо указать:\n\notel.SetTextMapPropagator(propagation.TraceContext{})\n\nДалее существующий контекст который содержит span необходимо завернуть в Header запроса который мы будем выполнять:\n\notel.GetTextMapPropagator().Inject(newCtx, propagation.HeaderCarrier(req.Header))\nГде newCtx это контекст который вернулся при создании исходного span.\n\nНа стороне обработчика запроса принимающей стороны необходимо распаковать контекст из пришедшего request header.\n\nctx := otel.GetTextMapPropagator().Extract(r.Context(), propagation.HeaderCarrier(r.Header))\n_, span := tracer.Start(ctx, &quot;remoteservice&quot;)\ndefer span.End()\n\n Проверить. Наверное можно не распаковывать если настроено инструментирование http\n"},"notes/OTEL/Сигналы-Наблюдаемости":{"title":"Сигналы Наблюдаемости","links":["notes/OTEL/Сигналы-Наблюдаемости","notes/OTEL/OTEL-Tracing","notes/OTEL/OTEL-Metrics","notes/OTEL/OTEL-Logs","notes/OTEL/Мягкий-контекст","notes/OTEL/OpenTelemetry-Baggage"],"tags":[],"content":"Сигналы Наблюдаемости\nСигнал - низкоуровневые данные описывающие происходящее в системе.\ngraph TD\n    A[Сигналы Наблюдаемости] --&gt; B[Трассировка]\n    A --&gt; C[Метрики]\n    A --&gt; D[Логи]\n\n    B --&gt;|Связывает сервисы| E[Сервисы]\n    C --&gt;|Измеряет производительность| E\n    D --&gt;|Записывает события| E\n\nС точки зрения Observability вообще и OpenTelemetry в частности можно выделить три основных сигнала наблюдаемости:\n\nТрассировка (tracing)\nМетрики (metrics)\nЛоги (logs)\n\nЭтот список отсортирован в порядке их важности исходя из значимости для Наблюдаемости в целом. Трассировка на первом месте как сигнал который связывает вместе все сервисы, а так же другие сигналы друг с другом.\nДля обмена мягким контекстом между сигналами, а так же проброса его между сервисами существует механизм OpenTelemetry Baggage.\nСигналы в разработке\nНа конец 2024 года в активной разработке есть ещё сигнал профилирования - Profiling12\nFootnotes\n\n\nopentelemetry.io/blog/2024/profiling/ ↩\n\n\nopentelemetry.io/blog/2024/state-profiling/ ↩\n\n\n"},"notes/OTEL/Тед-Янг,-Остин-Паркер-Изучаем-OpenTelemetry":{"title":"Тед Янг, Остин Паркер-Изучаем OpenTelemetry","links":[],"tags":[],"content":"Изучаем OpenTelemetry\n\n\n                  \n                  Metadata \n                  \n                \n\nAuthor: Тед Янг, Остин Паркер;\nPublisher: Спринт Бук\nPages: 240\n\n\n\n\n                  \n                  Zotero Link \n                  \n                \n\nPDF\n\n\n\n\n                  \n                  Abstract\n                  \n                \n\nПоявление OpenTelemetry произвело революцию в сфере наблюдаемости. Вместо того чтобы использовать несколько разрозненных систем, OpenTelemetry интегрирует трассировки, метрики и журналы в общий поток данных, предоставляя возможность оценить недоступные ранее взаимосвязи между ними. В этом  практическом руководстве показано, как настраивать, использовать и диагностировать систему наблюдаемости OpenTelemetry.\n\n\nАвторы Тед Янг и Остин Паркер, руководители, основатели и участники проекта OpenTelemetry, представляют все компоненты OpenTelemetry, а также лучшие практики наблюдаемости для многих популярных облачных сервисов, платформ и сервисов данных, таких как Kubernetes и AWS Lambda. Вы узнаете, как OpenTelemetry дает возможность сервисам и библиотекам OSS создавать собственное нативное инструментирование – впервые в отрасли.\nHighlights\n\n\n                  \n                  Quote\n                  \n                \n\n« Если когда-то задачу можно было сравнить с поиском иголки в стоге сена, то теперь она начинает напоминать поиски иголки в стоге иголок. » (Page 24)\n\n\n\n\n                  \n                  Quote\n                  \n                \n\n« Когда возникает проблема, есть только два аспекта, которые можно менять: разработчики могут изменить то, что делают транзакции, а операторы могут изменить состав доступных ресурсов. И это все. » (Page 33)\nНе думал об этом в таком ключе. Но звучит более чем разумно. других ручек по сути нет.\n\n\n\n\n                  \n                  Quote\n                  \n                \n\n« Жесткий контекст — уникальный идентификатор уровня запро- са, который может распространяться сервисами в распределенном приложении к другим сервисам, участвующим в обработке того же запроса » (Page 46)\n\n\n\n\n                  \n                  Quote\n                  \n                \n\n« Мягкий контекст формируется различными фрагментами ме- таданных, которые присоединяются каждым инструментом телеметрии к различным сервисам и инфраструктуре, обрабаты- вающим тот же запрос, — например, идентификатором клиента, » (Page 46)\n\n\n\n\n                  \n                  Quote\n                  \n                \n\n« Золотые сигналы — четыре критические характеристики, которые должны сниматься для системы, как указано которые должны сниматься для системы, как указано в кни- ге Google SRE Handbook (oreil.ly/aw2iQ). ге Google SRE Handbook (oreil.ly/aw2iQ). Задержка (latency) — время, необходимое для обслуживания (latency) — время, необходимое для обслуживания запроса, трафик (traffic) — количество запросов, ошибки (errors) — (latency) — время, необходимое для обслуживания запроса, трафик (traffic) — количество запросов, ошибки (errors) — относительная доля ошибочных запросов, насыщение относительная доля ошибочных запросов, насыщение (satu- ration) — степень загрузки системных ration) — степень загрузки системных ресурсов. » (Page 65)\n\n\n\n\n                  \n                  Quote\n                  \n                \n\n« Экземпляры  Метрики OpenTelemetry поддерживают особую разновидность жестких контекстов — экземпляры (exemplars), позволяющие связать событие с конкретным интервалом и трассировкой. В главе 5 вы узнаете, как создавать эти метрики и использовать их в своих приложениях. » (Page 68)\n\n\n\n\n                  \n                  Quote\n                  \n                \n\n« Средства долгосрочного хранения, анализа, GUI и другие фронтенд-компоненты не включены в OpenTelemetry и никогда не будут. » (Page 88)\n\n\n\n\n                  \n                  Quote\n                  \n                \n\n« коннектора OpenTelemetry Collector spanmetrics. Если отфиль- тровать дашборд, оставив только сервисы » (Page 95)\n\n\n\n\n                  \n                  Quote\n                  \n                \n\n« Сэмплеры отвечают за то, записывается ли интервал или игно- рируется. » (Page 115)\n\n\n\n\n                  \n                  Quote\n                  \n                \n\n« Но если телеметрия экспортируется в локальный коллектор, мы рекомен- дуем присвоить scheduledDelayMillis существенно меньшее зна- чение. Это гарантирует, что в случае внезапного сбоя чение. Это гарантирует, что в случае внезапного сбоя приложения будет потерян минимальный объем телеметрических данных. » (Page 117)\n\n\n\n\n                  \n                  Quote\n                  \n                \n\n« Недавно проект OpenTelemetry определил конфигурационный файл, работающий во всех языках. Этот подход рекомендуется использовать для настройки конфигурации. Конфигурационный файл обладает всеми преимуществами переменных окружения, но он намного проще проверяется » (Page 125)\n\n\n\n\n                  \n                  Quote\n                  \n                \n\n« Существует один критический набор ресурсов, которые невоз- можно получить из среды: ресурсы, описывающие ваш сервис. Эти ресурсы невероятно важны, поэтому вы должны просле- дить за тем, чтобы они были определены как часть настройки OpenTelemetry. » (Page 127)\n\n\n\n\n                  \n                  Quote\n                  \n                \n\n« Хотя вы можете легко загрузить контейнер Docker или заранее построенный двоичный образ Collector, в рабочих средах следует использовать Collector Builder (oreil.ly/UOy49). Эта использовать Collector Builder (oreil.ly/UOy49). Эта служеб- ная программа позволяет сгенерировать нестандартную ная программа позволяет сгенерировать нестандартную сборку со встроенными получателями, экспортерами и обработчиками » (Page 163)\n\n\n\n\n                  \n                  Quote\n                  \n                \n\n« Интервальные ссылки (oreil.ly/JcWS4) позволя- ют создать причинно-следственную связь между ют создать причинно-следственную связь между интервалами, не связанными прямыми отношениями «родитель/потомок». » (Page 175)\nИмеет смысл например при пробросе через сервис очередей так как мы не знаем сколько сообщение проведет в очереди.\n\n\n\n\n                  \n                  Quote\n                  \n                \n\n« Един- ственным изменяемым параметром конфигурации должно быть уменьшение размера пакета и тайм-аут экспорта, как упоминалось ранее. » (Page 182)\n\n\n\n\n                  \n                  Quote\n                  \n                \n\n« В настоящее время в проекте OpenTelemetry разрабаты- вается протокол для управления Collector через вается протокол для управления Collector через панель управления. Протокол OpAMP (Open Agent Management управления. Протокол OpAMP (Open Agent Management Protocol) Protocol) (github.com/open-telemetry/opamp-spec/blob/ main/speciication.md) заметно упростит развертывание main/speciication.md) заметно упростит развертывание изме- нений конфигурации и новых бинарных файлов нений конфигурации и новых бинарных файлов Collector по комплексу Collector независимо от управления по комплексу Collector независимо от управления при- ложениями. Это также позволяет Collector ложениями. Это также позволяет Collector сообщать метрики » (Page 185)\n\n\n\n\n                  \n                  Quote\n                  \n                \n\n« Первым шагом должно стать удаление всего, что вам не нужно. Вы можете воспользоваться фильтрами, чтобы полностью убрать из конвейера конкретные журнальные сообщения, интервалы или метрические инструменты. » (Page 191)\nследует отфильтровать  health check\n\n\n\n\n                  \n                  Quote\n                  \n                \n\n« выполнять это отображение на языке OTTL (OpenTelemetry Transformation Language) (oreil.ly/P2YZ8). Журналы могут обрабатываться в OpenTelemetry разными » (Page 199)\n\n\n\n\n                  \n                  Quote\n                  \n                \n\n« Надеемся, эта книга стала для вас полезным источником знаний! Если вы захотите связаться с авторами напрямую, вы не найдете их НИГДЕ, ПОТОМУ ЧТО TWITTER УМЕР. СОВСЕМ УМЕР. Если вы встретите авторов в дикой природе, не пытайтесь к ним приближаться. Медленно отойдите и не смотрите им в глаза. » (Page 233)\n\n"},"notes/Olap-Cube":{"title":"Olap Cube","links":["notes/Olap-Cube","notes/Высоконагруженные-приложения"],"tags":[],"content":"Olap Cube\n\nOLAP-куб или куб-данных это материализованное представление где некоторые агрегаты уже посчитаны заранее. Пример:\n\n\n\n\n\nParent:: Высоконагруженные приложения"},"notes/Pod":{"title":"Pod","links":["notes/Pod"],"tags":["reference/kubernetes"],"content":"Pod\nPod — это базовая единица вычислений в Kubernetes, представляющая собой группу одно или несколько контейнеров, которые запускаются на одном узле. Эти контейнеры разделяют ресурсы, такие как сеть и хранилище, и могут быть сконфигурированы для взаимодействия друг с другом в рамках одного окружения Pod. Каждый Pod имеет уникальный IP-адрес в рамках кластера, что позволяет контейнерам в его составе обмениваться данными через localhost.\nПример манифеста создания Pod\napiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\n  labels:\n    app: my-app\nspec:\n  containers:\n  - name: my-container\n    image: nginx:latest\n    ports:\n    - containerPort: 80\nВ этом манифесте создается Pod с именем my-pod, который имеет метку app: my-app. Внутри Pod запускается контейнер с именем my-container, использующий образ nginx:latest и слушающий порт 80."},"notes/PostgreSQL-on-HomeBrew":{"title":"PostgreSQL on HomeBrew","links":["notes/PostgreSQL-on-HomeBrew"],"tags":[],"content":"PostgreSQL on HomeBrew\nПуть по которому лежат конфигурационные файлы и сами данные: /usr/local/var/postgresql@16\nОбновление Postgres\n\nОстановить БД:\n\nbrew services stop postgresql@15\n\nПроверка перед переносом данных:\n\n/usr/local/opt/postgresql@16/bin/pg_upgrade --old-datadir=/usr/local/var/postgresql@15 --new-datadir=/usr/local/var/postgresql@16 --old-bindir=/usr/local/opt/postgresql@15/bin --new-bindir=/usr/local/opt/postgresql@16/bin --old-options=&#039;-c config_file=/usr/local/var/postgresql@15/postgresql.conf&#039; --new-options=&#039;-c config_file=/usr/local/var/postgresql@16/postgresql.conf&#039; --check\n \nПроведение проверок целостности\n-------------------------------\nChecking cluster versions                                     ок\nChecking database user is the install user                    ок\nChecking database connection settings                         ок\nChecking for prepared transactions                            ок\nChecking for system-defined composite types in user tables    ок\nChecking for reg* data types in user tables                   ок\nChecking for contrib/isn with bigint-passing mismatch         ок\nChecking for incompatible &quot;aclitem&quot; data type in user tables  ок\nChecking for presence of required libraries                   ок\nChecking database user is the install user                    ок\nChecking for prepared transactions                            ок\nChecking for new cluster tablespace directories               ок\n \n*Кластеры совместимы*\n\nТо же самое но без --check на конце мигрирует данные.\nbrew services start postgresql@16\n/usr/local/opt/postgresql@16/bin/vacuumdb --all --analyze-in-stages\nbrew uninstall postgresql@15\n\nSource:: www.kostolansky.sk/posts/upgrading-to-postgresql-15/"},"notes/PostgreSQL-upgrade":{"title":"PostgreSQL upgrade","links":["notes/PostgreSQL-upgrade","notes/PostgreSQL-on-HomeBrew"],"tags":[],"content":"PostgreSQL upgrade\n/usr/lib/postgresql/16/bin/pg_upgrade --old-datadir /var/lib/postgresql/13/main/ --new-datadir /var/lib/postgresql/16/main --old-bindir /usr/lib/postgresql/13/bin/ --new-bindir /usr/lib/postgresql/16/bin/ --old-options=&#039;-c config_file=/etc/postgresql/13/main/postgresql.conf&#039; --new-options=&#039;-c config_file=/etc/postgresql/16/main/postgresql.conf&#039;\n\nОба кластера должны быть остановлены.\nКлюч --check выполнить все проверки без миграции данных.\nПосле обновления в папке запуска будет лежать скрипт ./delete_old_cluster.sh который удалит старый кластер.\nРекомендуется на новом кластере выполнить - /usr/lib/postgresql/16/bin/vacuumdb --all --analyze-in-stages\n\nДетали по работе с HomeBrew версией: PostgreSQL on HomeBrew"},"notes/RedPanda-docker-quick-start":{"title":"RedPanda docker quick start","links":["notes/RedPanda-docker-quick-start"],"tags":[],"content":"RedPanda docker quick start\nname: redpanda-quickstart-one-broker\nnetworks:\n  redpanda_network:\n    driver: bridge\nvolumes:\n  redpanda-0: null\nservices:\n  redpanda-0:\n    command:\n      - redpanda\n      - start\n      - --kafka-addr internal://0.0.0.0:9092,external://0.0.0.0:19092\n      # Address the broker advertises to clients that connect to the Kafka API.\n      # Use the internal addresses to connect to the Redpanda brokers&#039;\n      # from inside the same Docker network.\n      # Use the external addresses to connect to the Redpanda brokers&#039;\n      # from outside the Docker network.\n      - --advertise-kafka-addr internal://redpanda-0:9092,external://localhost:19092\n      - --pandaproxy-addr internal://0.0.0.0:8082,external://0.0.0.0:18082\n      # Address the broker advertises to clients that connect to the HTTP Proxy.\n      - --advertise-pandaproxy-addr internal://redpanda-0:8082,external://localhost:18082\n      - --schema-registry-addr internal://0.0.0.0:8081,external://0.0.0.0:18081\n      # Redpanda brokers use the RPC API to communicate with each other internally.\n      - --rpc-addr redpanda-0:33145\n      - --advertise-rpc-addr redpanda-0:33145\n      # Mode dev-container uses well-known configuration properties for development in containers.\n      - --mode dev-container\n      # Tells Seastar (the framework Redpanda uses under the hood) to use 1 core on the system.\n      - --smp 1\n      - --default-log-level=info\n    image: docker.redpanda.com/redpandadata/redpanda:v24.2.8\n    container_name: redpanda-0\n    volumes:\n      - redpanda-0:/var/lib/redpanda/data\n    networks:\n      - redpanda_network\n    ports:\n      - 18081:18081\n      - 18082:18082\n      - 19092:19092\n      - 19644:9644\n  console:\n    container_name: redpanda-console\n    image: docker.redpanda.com/redpandadata/console:v2.7.2\n    networks:\n      - redpanda_network\n    entrypoint: /bin/sh\n    command: -c &#039;echo &quot;$$CONSOLE_CONFIG_FILE&quot; &gt; /tmp/config.yml; /app/console&#039;\n    environment:\n      CONFIG_FILEPATH: /tmp/config.yml\n      CONSOLE_CONFIG_FILE: |\n        kafka:\n          brokers: [&quot;redpanda-0:9092&quot;]\n          schemaRegistry:\n            enabled: true\n            urls: [&quot;http://redpanda-0:8081&quot;]\n        redpanda:\n          adminApi:\n            enabled: true\n            urls: [&quot;http://redpanda-0:9644&quot;]\n    ports:\n      - 8080:8080\n    depends_on:\n      - redpanda-0"},"notes/ReplicaSet":{"title":"ReplicaSet","links":["notes/ReplicaSet"],"tags":["reference/kubernetes"],"content":"ReplicaSet\nReplicaSet в Kubernetes — это контроллер, который обеспечивает высокую доступность и масштабируемость приложений. Он управляет множеством одинаковых Pod’ов, обеспечивая их поддержание в заданном количестве и автоматическое восстановление в случае сбоев.\nПример манифеста ReplicaSet\napiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: my-replicaset\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-app-container\n        image: my-app:latest\n        ports:\n        - containerPort: 8080\nВ этом примере создается ReplicaSet с именем my-replicaset, который управляет тремя Pod’ами с меткой app: my-app. Каждый Pod содержит контейнер с образом my-app:latest и открывает порт 8080."},"notes/SSL-on-PostgreSQL":{"title":"SSL on PostgreSQL","links":["notes/SSL-on-PostgreSQL"],"tags":[],"content":"SSL on PostgreSQL\nУстановка Certbot и сертификатов\n\nПроверяем работу snap\n\nsudo snap install core; sudo snap refresh core\n\nУдаляем на всякий случай certbot если он был.\n\nsudo apt-get remove certbot\n\nУстанавливаем snap\n\nsudo snap install --classic certbot\n\nСоздаем симлинк на бианрник (не уверен зачем)\n\nsudo ln -s /snap/bin/certbot /usr/bin/certbot\n\nПолучение сертификата\n\nsudo certbot certonly --standalone -d db.mak-sim.ru\nНастройка hook’а для PG\nСоздаём файл /etc/letsencrypt/renewal-hooks/deploy/postgresql.deploy:\n #!/bin/bash\n umask 0177\n DOMAIN=db.mak-sim.ru\n DATA_DIR=/var/lib/postgresql/12/main\n cp /etc/letsencrypt/live/$DOMAIN/fullchain.pem $DATA_DIR/server.crt\n cp /etc/letsencrypt/live/$DOMAIN/privkey.pem $DATA_DIR/server.key\n chown postgres:postgres $DATA_DIR/server.crt $DATA_DIR/server.key\nDATA_DIR можно узнать выполнив команду:\nsudo -u postgres psql -U postgres -c &#039;SHOW data_directory&#039;\n\nФайлу необходимо выдать права на исполнение.\nНастройки PostgreSQL\npostgresql.conf\nВ файле postgresql.conf необходимо поправить:\n ssl = on  \n ssl_cert_file = &#039;server.crt&#039;  \n ssl_key_file = &#039;server.key&#039;  \n ssl_prefer_server_ciphers = on\n\nМестоположение файла можно узнать выпонив:\nsudo -u postgres psql -U postgres -c &#039;SHOW config_file&#039;\npg_hba.conf\nДобавляем строку\n hostssl all all 0.0.0.0/0 md5\n"},"notes/Sampler":{"title":"Sampler","links":["notes/Sampler"],"tags":[],"content":"Sampler\nСэмплер - это процесс, который ограничивает количество трейсов, генерируемых системой. Каждая языковая реализация OpenTelemetry предлагает несколько головных сэмплеров.\nОчевидно, что использование сэмплеров требует понимания, какую именно проблему мы хотим решить так как это всегда означает потерю данных. Разумным решением на старте будет не использовать его!"},"notes/SchemaCrawler":{"title":"SchemaCrawler","links":["notes/SchemaCrawler"],"tags":[],"content":"SchemaCrawler\nSource:: www.schemacrawler.com\n\ncurl -s &quot;get.sdkman.io&quot; | bash\nsdk install schemacrawler\nschemacrawler.sh --server postgresql --database trino --host 127.0.0.1 --port 5432 --info-level standard --command script --script-language python --script ~/Downloads/mermaid.py\n\nmermaid.py\nfrom __future__ import print_function\nimport re\n \n \n# Mermaid only allows alphanumeric identifiers\ndef cleanname(name):\n    namepattern = r&#039;[^-\\d\\w]&#039;\n    cleanedname = re.sub(namepattern, &#039;&#039;, name)\n    if not cleanedname:\n        cleanedname = &quot;UNKNOWN&quot;\n    return cleanedname\n \n \nprint(&#039;erDiagram&#039;)\nprint(&#039;&#039;)\nfor table in catalog.tables:\n    print(&#039;  &#039; + cleanname(table.fullName) + &#039; {&#039;)\n    for column in table.columns:\n        print(&#039;    &#039; + cleanname(column.columnDataType.name) + &#039; &#039; + cleanname(column.name),\n              end=&#039;&#039;)\n        if column.isPartOfPrimaryKey():\n            print(&#039; PK&#039;, end=&#039;&#039;)\n        elif column.isPartOfForeignKey():\n            print(&#039; FK&#039;, end=&#039;&#039;)\n        elif column.isPartOfUniqueIndex():\n            print(&#039; UK&#039;, end=&#039;&#039;)\n        if column.hasRemarks():\n            print(&#039; &quot;&#039; + &#039; &#039;.join(column.remarks.splitlines()) + &#039;&quot;&#039;,\n                  end=&#039;&#039;)\n        print()\n    print(&#039;  }&#039;)\n    print(&#039;&#039;)\n \nfor table in catalog.tables:\n    for childTable in table.referencingTables:\n        print(&#039;  &#039; + cleanname(table.fullName) + &#039; ||--o{ &#039; +\n              cleanname(childTable.fullName) + &#039; : &quot;foreign key&quot;&#039;)"},"notes/Squash-commit-in-git":{"title":"Squash commit in git","links":["notes/Частичный-коммит-изменений-файла-в-git"],"tags":["reference/git"],"content":"Squash commit in git\nДля того чтобы схлопнуть к последнему коммиту следующие перед ним необходимо выполнить: git rebase -i HEAD~2  где 2 это количество коммитов которые будем схлопывать. Откроется редактор:\n\nВерхний коммит следует оставить как pick, тогда как все что требуется схлопнуть надо отметить как squash или просто s. После закрытия редактора он откроется снова для создания сообщения нового коммита.\nЕсли требуется обновить удаленный репозиторий то команду git push следует выполнять с ключом —force\nFriend:: Частичный коммит изменений файла в git"},"notes/Swagger--and--OpenAPI":{"title":"Swagger & OpenAPI","links":["notes/Swagger--and--OpenAPI","notes/Install-swagger-on-Mac-OS","notes/Компиляция-swagger-для-Golang"],"tags":[],"content":"Swagger &amp; OpenAPI\n\nInstall swagger on Mac OS\nКомпиляция swagger для Golang\n"},"notes/Teleport-CLI":{"title":"Teleport CLI","links":["notes/Teleport-CLI","notes/Teleport.-Golang"],"tags":[],"content":"Teleport CLI\nТелепорт можно установить различными способами в том числе и пакетами для OS, но так как мне требуется только авторизация для использования в коде и работа с командно строкой то проще всего скачать tar.gz файл и получить таким образом нужные бинарники.\n\n\n                  \n                  Важно \n                  \n                \n\nСначала следует узнать версию самого сервиса teleport запущенного в нашей инфре и скачать ровно ту же. Даже небольшие расхождения приводят к несовместимости API.\n\n\ntsh\nОсновная утилита для работы из CLI это tsh.\nАутентификация в teleport\n./tsh login --proxy=teleport.host --user=mylogin --skip-version-check --auth=local --ttl 5256000\n1\nЕсли добавить ключ -o &lt;имя_файла&gt; то будет сгенерирован текстовый файл содержащий в себе все необходимые сертификаты для работы с телепортом, что потребуется позже для Teleport. Golang.\nНастройка сохраняются в ~/.tsh/. Из интересного там находится файл current-profile который указывает на активный профиль если настроено подключение более чем к одному телепорту.\nОсновные команды\nenv\n./tsh env --proxy teleport.***:443\nвыведет список переменных которые надо задать для работы с этим proxy.\nls\nВыводит список доступных через этот proxy хостов.\n❯ ./tsh ls --proxy teleport.***.ru:443\n \nNode Name                                                     Address    Labels                                                                                                                                                                \n------------------------------------------------------------- ---------- --------------------------------------------------------------------------------------------------------------------------------------------------------------------- \nklktest-ch-1.******.******.mts.ru ⟵ Tunnel   bios=c4b72c42-29c3-d71d-0a16-954d87a1a037,clickhouse-l3=true,hostname=klktest-ch-1,paas-l1=true,stand_slug=****-unix-inside-0300s2,type=dataops,unix-admin=true \nРезультаты поиска можно фильтровать:\n./tsh ls --proxy teleport.***.ru:443 --query=&#039;labels[&quot;type&quot;] == &quot;dataops&quot;&#039;\nВнутри одинарных кавычек фильтра допускаются следующие операторы ==, !=, &amp;&amp; и ||.\nssh\nПозволяет подключиться к хосту за телепортом. Например так:\n./tsh ssh user@&lt;some_host_from_tsh_ls&gt;.ru\nconfig\nПокажет кусочек конфига ~/.ssh/config который если туда добавить по идее позволит исползьзовать для телепорт хостов обычный ssh вместо ./tsh ssh. Но у меня не завелось. Похоже надо добавлять эти записи в DNS для начала.\nFootnotes\n\n\nauth=local актуально для внутренней инсталляции. ↩\n\n\n"},"notes/Teleport.-Golang":{"title":"Teleport. Golang","links":["notes/Teleport.-Golang"],"tags":[],"content":"Teleport. Golang"},"notes/Thrift-Client.-Golang":{"title":"Thrift Client. Golang","links":["notes/Thrift-Client.-Golang"],"tags":["reference/golang"],"content":"Thrift Client. Golang\nПример создания клиента для Thrift сервера.\nПоследняя строка это вызов метода.\nfunc main() {\n\ttransportFactory := thrift.NewTFramedTransportFactoryConf(thrift.NewTTransportFactory(), nil)\n\tprotocolFactoryBinary := thrift.NewTBinaryProtocolFactoryConf(nil)\n \n\t// protocolFactoryCompact := thrift.NewTCompactProtocolFactoryConf(nil)\n\tprotocolFactoryDebug := thrift.NewTDebugProtocolFactoryWithLogger(protocolFactoryBinary, &quot;&quot;, thrift.StdLogger(log.Default()))\n \n\ttransport := thrift.NewTSocketConf(net.JoinHostPort(HOST, PORT), nil)\n \n\tuseTransport, err := transportFactory.GetTransport(transport)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n \n\tclient := trino.NewTrinoThriftServiceClientFactory(useTransport, protocolFactoryDebug)\n\tif err := transport.Open(); err != nil {\n\t\tfmt.Fprintln(os.Stderr, &quot;Error opening socket to &quot;+HOST+&quot;:&quot;+PORT, &quot; &quot;, err)\n\t\tos.Exit(1)\n\t}\n\tdefer transport.Close()\n \n\tfmt.Println(client.TrinoListSchemaNames(context.Background()))\n}"},"notes/Thrift-Client.-Java":{"title":"Thrift Client. Java","links":["notes/Thrift-Client.-Java","notes/Thrift-Client.-Golang"],"tags":[],"content":"Thrift Client. Java\npackage com.mts.dataops.virtualization;\n \nimport com.mts.dataops.datavirtualization.TrinoThriftService;\nimport org.apache.thrift.TException;\nimport org.apache.thrift.protocol.TBinaryProtocol;\nimport org.apache.thrift.protocol.TProtocol;\nimport org.apache.thrift.transport.TSocket;\nimport org.apache.thrift.transport.layered.TFramedTransport;\n \nimport java.util.List;\n \npublic class Client {\n    public void start() throws TException {\n        TSocket transport = new TSocket(&quot;localhost&quot;, 9998);\n        transport.open();\n        \n        TFramedTransport tFramedTransport = new TFramedTransport(transport);\n        TProtocol protocol = new TBinaryProtocol(tFramedTransport);\n        TrinoThriftService.Client client = new TrinoThriftService.Client(protocol);\n \n        List&lt;String&gt; schemas = client.trinoListSchemaNames();\n        System.out.println(schemas);\n    }\n}\n \nParent::\nChildren::\nFriend:: Thrift Client. Golang"},"notes/Thrift-Codegen.-Golang":{"title":"Thrift Codegen. Golang","links":["notes/Thrift-Codegen.-Golang","notes/Thrift-Codegen.-Java"],"tags":[],"content":"Thrift Codegen. Golang\nthrift -r --gen go:skip_remote trino.thrift\nГде флаг skip_remote это:\n\nSkip the generating of -remote folders for the client binaries for services\n\nParent::\nChildren::\nFriend:: Thrift Codegen. Java"},"notes/Thrift-Codegen.-Java":{"title":"Thrift Codegen. Java","links":["notes/Thrift-Codegen.-Java"],"tags":[],"content":"Thrift Codegen. Java\nGradle\nplugins {\n    id &#039;java&#039;\n    id &quot;org.jruyi.thrift&quot; version &quot;0.4.2&quot;\n}\n \ngroup &#039;com.mts.dataops.virtualization&#039;\nversion &#039;1.0-SNAPSHOT&#039;\n \nrepositories {\n    mavenCentral()\n}\n \ndependencies {\n    implementation &#039;org.apache.thrift:libthrift:0.18.1&#039;\n    implementation &#039;javax.annotation:javax.annotation-api:1.3.2&#039;\n    implementation &#039;org.slf4j:slf4j-api:2.0.7&#039;\n    implementation &#039;org.slf4j:slf4j-simple:2.0.7&#039;\n \n    testImplementation &#039;org.junit.jupiter:junit-jupiter-api:5.8.1&#039;\n    testRuntimeOnly &#039;org.junit.jupiter:junit-jupiter-engine:5.8.1&#039;\n}\n \ntest {\n    useJUnitPlatform()\n}\n\nПодключить плагин org.jruyi.thrift.\nДобавить зависимости:\n\norg.apache.thrift:libthrift\njavax.annotation:javax.annotation-api\norg.slf4j:slf4j-api\n\n\nСпецификации thrift сложить в src/main/thrift\n\nТак же важно прописать в spec файле thrift’а namespace для Java:\nnamespace java com.mts.dataops.datavirtualization\n\nПосле этого в gradle станет доступна команда сборки исходников:\n./gradlew compileThrift"},"notes/Thrift-Server.-Golang":{"title":"Thrift Server. Golang","links":["notes/Thrift-Server.-Golang"],"tags":[],"content":"Thrift Server. Golang\nСоздание сервера\ntransportFactory := thrift.NewTFramedTransportFactoryConf(thrift.NewTTransportFactory(), nil)\nprotocolFactory := thrift.NewTBinaryProtocolFactoryConf(nil)\n\nDebug\nfunc main() {\n\tvar ts TrinoService\n \n\ttransportFactory := thrift.NewTFramedTransportFactoryConf(thrift.NewTTransportFactory(), nil)\n\tprotocolFactoryBinary := thrift.NewTBinaryProtocolFactoryConf(nil)\n \n\tprotocolFactoryDebug := thrift.NewTDebugProtocolFactoryWithLogger(protocolFactoryBinary, &quot;log&quot;, thrift.StdLogger(log.Default()))\n \n\ttransport, err := thrift.NewTServerSocket(&quot;:9998&quot;)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n \n\tprocessor := trino.NewTrinoThriftServiceProcessor(&amp;ts)\n\tserver := thrift.NewTSimpleServer4(processor, transport, transportFactory, protocolFactoryDebug)\n\tlog.Fatal(server.Serve())\n}\nКлиент"},"notes/Thrift-Server.-Java":{"title":"Thrift Server. Java","links":["notes/Thrift-Server.-Java"],"tags":[],"content":"Thrift Server. Java\npackage com.mts.dataops.virtualization;\n \nimport com.mts.dataops.datavirtualization.TrinoThriftService;\nimport org.apache.thrift.protocol.TBinaryProtocol;\nimport org.apache.thrift.server.TServer;\nimport org.apache.thrift.server.TThreadPoolServer;\nimport org.apache.thrift.transport.TServerSocket;\nimport org.apache.thrift.transport.TServerTransport;\nimport org.apache.thrift.transport.TTransportException;\nimport org.apache.thrift.transport.layered.TFramedTransport;\n \npublic class Main {\n    public static void main(String[] args) throws TTransportException {\n        Server trino = new Server();\n        TrinoThriftService.Processor&lt;Server&gt; processor = new TrinoThriftService.Processor&lt;&gt;(trino);\n \n        TServerTransport serverTransport = new TServerSocket(9998);\n        TFramedTransport.Factory transportFactory = new TFramedTransport.Factory();\n        TBinaryProtocol.Factory protocolFactory = new TBinaryProtocol.Factory();\n \n        TThreadPoolServer.Args thriftArgs = new TThreadPoolServer.Args(serverTransport)\n                .processor(processor).\n                inputProtocolFactory(protocolFactory).\n                inputTransportFactory(transportFactory).\n                outputTransportFactory(transportFactory);\n        TServer server = new TThreadPoolServer(thriftArgs);\n \n        Thread thread = new Thread(server::serve);\n        thread.start();\n    }\n}\n\n\n                  \n                  Debug \n                  \n                \n\nДля Java нет Debug реализации протоколов.\n\n"},"notes/Thrift.-Golang":{"title":"Thrift. Golang","links":["notes/Thrift.-Golang","notes/Thrift-Server.-Golang","notes/Thrift-Client.-Golang","notes/Thrift-Codegen.-Golang"],"tags":[],"content":"Thrift. Golang\n\nChildren:: Thrift Server. Golang\nChildren:: Thrift Client. Golang\nChildren:: Thrift Codegen. Golang\n"},"notes/Thrift.-Java":{"title":"Thrift. Java","links":["notes/Thrift.-Java","notes/Thrift-Client.-Java","notes/Thrift-Codegen.-Java","notes/Thrift-Server.-Java"],"tags":[],"content":"Thrift. Java\n\nChildren:: Thrift Client. Java\nChildren:: Thrift Codegen. Java\nChildren:: Thrift Server. Java\n"},"notes/Thrift":{"title":"Thrift","links":["notes/Thrift","notes/Thrift.-Golang","notes/Thrift.-Java","notes/Trino/Trino-thrift-connector.-Golang"],"tags":[],"content":"Thrift\n\nChildren:: Thrift. Golang\nChildren:: Thrift. Java\n\nРаботу с Thrift можно разделить на следующие слои:\n\nСервер\nПротокол\nТранспорт\n\nПротокол\n\nTBinaryProtocol — простой двоичный формат, кодирующий числовые значения как двоичные, а не преобразующий их в текст. \nTCompactProtocol — очень эффективное плотное кодирование данных (подробнее см. ниже).\nTDenseProtocol — похож на TCompactProtocol, но удаляет метаинформацию из передаваемых данных и добавляет её обратно на стороне получателя. TDenseProtocol всё ещё экспериментальный и пока недоступен в реализации на Java.\nTJSONProtocol — использует JSON для кодирования данных.\nTSimpleJSONProtocol — протокол только для записи с использованием JSON. Подходит для разбора скриптовыми языками.\nTDebugProtocol — использует читаемый человеком текстовый формат для помощи в отладке.\n\nТранспорт\n\nTSocket — использует блокирующий ввод-вывод через сокет для передачи данных.\nTFramedTransport — отправляет данные в кадрах, где каждый кадр предваряется указанием его длины. Этот транспорт необходим при использовании неблокирующего сервера.   \nTFileTransport — этот транспорт осуществляет запись в файл. Хотя этот транспорт не входит в реализацию на Java, его должно быть достаточно просто реализовать.\nTMemoryTransport — для ввода-вывода использует память. Реализация на Java внутренне использует простой ByteArrayOutputStream.\nTZlibTransport — выполняет сжатие с помощью zlib. Используется вместе с другим транспортом. В реализации на Java недоступен.\n\nFriend:: Trino thrift connector. Golang"},"notes/Tmux":{"title":"Tmux","links":["notes/Tmux"],"tags":[],"content":"Tmux\nResize pane\n\nTo resize a pane, you always use the default prefix ‘Ctrl + b’ followed by the colon (:) key.\nWhen you invoke these key combinations, it will prompt at the bottom of your screen. To resize the pane, you will need to use the prompt to resize the desired pane.\nFor example, to resize a pane, you must type in the ‘resize-pane’ command followed by a hyphen (-) and either one of these options (D, U, R, L). These options are down, up, right, and left, respectively. Its work is to resize the pane in the direction provided.\n\n :resize-pane -D 10\n\nС помощью мыши\n\nThis is one of the easiest alternatives to resize panes on Tmux. Using the mouse is much more convenient as it does not require any commands. This method is usually preferred since it provides more control over the pane size than the first method, which involves using the resize-pane command. Open the tmux.conf file and append the following line of code:\n\nset -g mouse on\n\n\nOnce you are done, reload the tmux.conf file by executing the following line of code:\n\ntmux source-file ~/.tmux.conf\n\nSource:: www.fosslinux.com/80813/how-to-adjust-the-tmux-pane-size.htm"},"notes/Trino/Configuration-class":{"title":"Configuration class","links":["notes/Trino/Configuration-class","notes/Guice"],"tags":[],"content":"Configuration class\nimport io.airlift.configuration.Config;\nimport io.airlift.configuration.ConfigDescription;\nimport io.airlift.configuration.ConfigSecuritySensitive;\nimport io.airlift.units.Duration;\nimport io.airlift.units.MaxDuration;\nimport io.airlift.units.MinDuration;\n \nimport javax.validation.constraints.NotNull;\n \npublic class ExampleConfig\n{\n    private String secret;\n    private Duration timeout = Duration.succinctDuration(10, TimeUnit.SECONDS);\n \n    public String getSecret()\n    {\n        return secret;\n    }\n \n    @Config(&quot;secret&quot;)\n    @ConfigDescription(&quot;Secret required to access the data source&quot;)\n    @ConfigSecuritySensitive\n    public ExampleConfig setSecret(String secret)\n    {\n        this.secret = secret;\n        return this;\n    }\n \n    @NotNull\n    @MaxDuration(&quot;10m&quot;)\n    @MinDuration(&quot;1ms&quot;)\n    public Duration getTimeout()\n    {\n        return timeout;\n    }\n \n    @Config(&quot;timeout&quot;)\n    public ExampleConfig setTimeout(Duration timeout)\n    {\n        this.timeout = timeout;\n        return this;\n    }\n}\nЭтот класс должен быть связан (bound) с модулем Guice:\nimport com.google.inject.Binder;\nimport com.google.inject.Module;\n \nimport static io.airlift.configuration.ConfigBinder.configBinder;\n \npublic class ExampleModule\n        implements Module\n{\n    public ExampleModule()\n    {\n    }\n \n    @Override\n    public void configure(Binder binder)\n    {\n        configBinder(binder).bindConfig(ExampleConfig.class);\n    }\n}\nПосле этого модуль надо надо инициализировать в connector factory при создании нового экземпляра коннектора:\n@Override\npublic Connector create(String connectorName, Map&lt;String, String&gt; config, ConnectorContext context)\n{\n    requireNonNull(config, &quot;config is null&quot;);\n    Bootstrap app = new Bootstrap(new ExampleModule());\n    Injector injector = app\n            .doNotInitializeLogging()\n            .setRequiredConfigurationProperties(config)\n            .initialize();\n \n    return injector.getInstance(ExampleConnector.class);\n}"},"notes/Trino/Connectors-SPI":{"title":"Connectors SPI","links":["notes/Trino/Connectors-SPI","notes/Trino/Configuration-class"],"tags":[],"content":"Connectors SPI\nИнстанс коннектор создается в ConnectorFactory когда Trino вызывает метод getConnectorFactory() для нашего плагина. ConnectorFactory это просто интерфейс отвечающий за предоставление имени коннектора и его экземпляра.\nПростейший коннектор поддерживающий только чтение но не запись в источнике должен вернуть экземпляры следующих сервисов:\n\nConnectorMetadata\nConnectorSplitManager\nИ один из двух:\n\nConnectorRecordSetProvider\nConnectorPageSourceProvider\n\n\n\nКонфигурация\nМетод create() класса ConnectorFactory получает мапу конфигурации:\nConnector create(String catalogName,\n Map&lt;String,String&gt; config,\n ConnectorContext context)\nпроблема в том, что все значения будут строками, а значит потребуют валидации и преобразования в нужные типы. Чтобы избежать этих сложностей (и огрести новые) авторы Trino советуют создать отдельный:\nchild:: Configuration class\nConnectorMetadata\nЭтот интерфейс позволяет Trino получать списки схем, таблиц, и другие метаданные о конкретном источнике данных.\nПростейший коннектор (read-only) должен реализовывать следующие методы:\n\nlistSchemaNames\nlistTables\nstreamTableColumns\ngetTableHandle\ngetTableMetadata\ngetColumnHandles\ngetColumnMetadata\nОчевидно, что если источник поддерживает схемы, таблицы и колонки то реализация этого интерфейса довольно очевидна. Если же нет придётся изобретать.\n\nДополнительно интерфейс позволяет реализовать следующие возможности:\n\nSchema management, which is creating, altering and dropping schemas, tables, table columns, views, and materialized views.\nSupport for table and column comments, and properties.\nSchema, table and view authorization.\nExecuting Table functions.\nProviding table statistics used by the Cost Based Optimizer (CBO) and collecting statistics during writes and when analyzing selected tables.\nData modification, which is:\n\ninserting, updating, and deleting rows in tables,\nrefreshing materialized views,\ntruncating whole tables,\nand creating tables from query results.\n\n\nRole and grant management.\nPushing down:\n\nLimit and Top N - limit with sort items\nPredicates\nProjections\nSampling\nAggregations\nJoins\nTable function invocation\n\n\n"},"notes/Trino/MySQL-connector":{"title":"MySQL connector","links":["notes/Trino/MySQL-connector","notes/Trino/Trino"],"tags":[],"content":"MySQL connector\n\nВ новых версиях Trino есть проблема с настройками временных зон. Точнее с отсутствием таких настроек на стороне БД.\n\nРешили в итоге следующим параметром в jvm.config - Duser.timezone=Etc/GMT+3\n\n\n"},"notes/Trino/Patterns-in-Prometheus-JMX-exporter":{"title":"Patterns in Prometheus JMX exporter","links":["notes/Trino/Patterns-in-Prometheus-JMX-exporter"],"tags":[],"content":"Patterns in Prometheus JMX exporter\n\nВ выводе настроенного по умолчанию jmx_exporter можно увидеть строки вида:\n\n# HELP trino_execution_resourcegroups_InternalResourceGroup_MaxQueuedQueries  trino.execution.resourcegroups:name=admin,type=InternalResourceGroup,attribute=MaxQueuedQueries\n# TYPE trino_execution_resourcegroups_InternalResourceGroup_MaxQueuedQueries untyped\n\n\nВот эта trino.execution.resourcegroups:name=admin,type=InternalResourceGroup,attribute=MaxQueuedQueries часть должна быть настроена в конфигах pattern примерно вот так:\n\n  - pattern: &#039;trino.execution.resourcegroups&lt;type=InternalResourceGroup, name=global\\.adhoc&gt;&lt;&gt;(\\w+): (\\d+)&#039;\n    name: trino_resourcegroups_adhoc\n    labels:\n      name: &quot;root_group&quot;\n      type: $1\n    value: $2\n  - pattern: &#039;trino.execution.resourcegroups&lt;type=InternalResourceGroup, name=global\\.adhoc\\.(\\w+)&gt;&lt;&gt;(\\w+): (\\d+)&#039;\n    name: trino_resourcegroups_adhoc\n    labels:\n      name: $1\n      type: $2\n    value: $3\n  - pattern: &#039;trino.execution.resourcegroups&lt;type=InternalResourceGroup, name=global\\.bi&gt;&lt;&gt;(\\w+): (\\d+)&#039;\n    name: trino_resourcegroups_bi\n    labels:\n      name: &quot;root_group&quot;\n      type: $1\n    value: $2\n  - pattern: &#039;trino.execution.resourcegroups&lt;type=InternalResourceGroup, name=global\\.bi\\.(\\w+)&gt;&lt;&gt;(\\w+): (\\d+)&#039;\n    name: trino_resourcegroups_bi\n    labels:\n      name: $1\n      type: $2\n    value: $3\n  - pattern: &quot;.*&quot;\n"},"notes/Trino/TPCDS":{"title":"TPCDS","links":["notes/Trino/TPCDS"],"tags":[],"content":"TPCDS\nИнструкция по созданию набора данных TPCDS на MacOS и Linux\nУстановка\n\nКлонировать репозиторий с GitHub,\nУстановить зависимости для сборки.\n\nMacOS: xcode-select --install\nLinux:\n\nsudo apt-get install gcc make flex bison byacc git\n`sudo yum install gcc make flex bison byacc git\n\n\n\n\ncd tpcds-kit/tools\nСборка\n\nmake OS=MACOS\nmake OS=LINUX\n\n\n\nВерсия gcc в Linux\nДля того чтобы сборка прошла в Ubuntu 24.04 мне потребовалось установить более старую версию gcc и её собрать с дополнительными ключами.\nsudo apt install gcc-9\nmake CC=gcc-9 OS=LINUX\nГенерация\n./dsdgen -DIR /Users/maksim/tmp/data -SCALE 2 -VERBOSE Y\nГде:\n\nдиректория уже должна быть создана\n\nПараллельная генерация данных\nSince dsdgen generates 200-300GB/hour serially on a 2-3GHz x86 processor, it is useful to run multiple parallel streams when generating large amounts of data.\nExample:generating 1 GB with 4 parallel streams simultaneously\nSCALE=1\nTPCDS_DIR=/tmp/dsdgen/${SCALE}\nmkdir -p ${TPCDS_DIR}\ndsdgen -scale ${SCALE} -f -dir ${TPCDS_DIR} -parallel 4 -child 1 &amp;\ndsdgen -scale ${SCALE} -f -dir ${TPCDS_DIR} -parallel 4 -child 2 &amp;\ndsdgen -scale ${SCALE} -f -dir ${TPCDS_DIR} -parallel 4 -child 3 &amp;\ndsdgen -scale ${SCALE} -f -dir ${TPCDS_DIR} -parallel 4 -child 4 &amp;\nЗагрузка данных\n\nСоздать таблицы скриптом, что лежит в папке tools: psql -h 10.73.152.23 -U tpcds -d tpcds -f tpcds.sql\nВыполнить скрипт ниже для загрузки данных:\n\nfor i in `ls *.dat`; do\n  table=${i/.dat/}\n  echo &quot;Loading $table...&quot;\n  sed &#039;s/|$//&#039; $i &gt; /tmp/$i\n  psql -U tpcds -h 10.73.152.23 tpcds -q -c &quot;TRUNCATE $table&quot;\n  psql -U tpcds -h 10.73.152.23 tpcds -c &quot;\\\\copy $table FROM &#039;/tmp/$i&#039; CSV DELIMITER &#039;|&#039;&quot;\ndone\nГенерация запросов\ndsqgen \\\n-DIRECTORY ../query_templates \\\n-INPUT ../query_templates/templates.lst \\\n-VERBOSE Y \\\n-QUALIFY Y \\\n-SCALE 10000 \\\n-DIALECT netezza \\\n-OUTPUT_DIR /tmp"},"notes/Trino/Trino-API":{"title":"Trino API","links":["notes/Trino/Trino-API"],"tags":[],"content":"Trino API\nОказывается, документация Trino не совсем полна. В частности я нашел как минимум два недокументированных endpoint’а.\n\n/metrics - endpoint для Prometheus отдающий все JMX метрики.\nv1/jmx JMX сам по себе\n\nv1/jmx/mbean - json содержащий все Mbean\n\n\n"},"notes/Trino/Trino-thrift-connector.-Golang":{"title":"Trino thrift connector. Golang","links":["notes/Trino/Trino-thrift-connector.-Golang","PublicMedia/trino.thrift","notes/Thrift","notes/Thrift-Server.-Golang"],"tags":["reference/golang"],"content":"Trino thrift connector. Golang\nTrino thrift specs\nTrino ожидает TBinaryProtocol и TFramedTransport как протокол и транспорт соответственно.\nTransclude of Thrift-Server.-Golang#^ba761a\nMethods\nTrinoListSchemaNames\nfunc (ts *TrinoService) TrinoListSchemaNames(ctx context.Context) (_r []string, _err error) {\n \n}\nTrinoListTables\nfunc (ts *TrinoService) TrinoListTables(ctx context.Context, schemaNameOrNull *trino.TrinoThriftNullableSchemaName) (_r []*trino.TrinoThriftSchemaTableName, _err error) {\n \n}\nTrinoGetTableMetadata\nfunc (ts *TrinoService) TrinoGetTableMetadata(ctx context.Context, schemaTableName *trino.TrinoThriftSchemaTableName) (_r *trino.TrinoThriftNullableTableMetadata, _err error) {\n \n}\nTrinoGetSplits\nfunc (ts *TrinoService) TrinoGetSplits(ctx context.Context, schemaTableName *trino.TrinoThriftSchemaTableName, desiredColumns *trino.TrinoThriftNullableColumnSet, outputConstraint *trino.TrinoThriftTupleDomain, maxSplitCount int32, nextToken *trino.TrinoThriftNullableToken) (_r *trino.TrinoThriftSplitBatch, _err error) {\n \n}\nTrinoGetIndexSplits\nfunc (ts *TrinoService) TrinoGetIndexSplits(ctx context.Context, schemaTableName *trino.TrinoThriftSchemaTableName, indexColumnNames []string, outputColumnNames []string, keys *trino.TrinoThriftPageResult_, outputConstraint *trino.TrinoThriftTupleDomain, maxSplitCount int32, nextToken *trino.TrinoThriftNullableToken) (_r *trino.TrinoThriftSplitBatch, _err error) {\n \n}\nTrinoGetRows\nfunc (ts *TrinoService) TrinoGetRows(ctx context.Context, splitId *trino.TrinoThriftId, columns []string, maxBytes int64, nextToken *trino.TrinoThriftNullableToken) (_r *trino.TrinoThriftPageResult_, _err error) {\n \n}"},"notes/Trino/Trino":{"title":"Trino","links":["notes/Trino/Trino","notes/Trino/Запрос-к-полю-типа-map-в-SQL-Trino","notes/Trino/Поля-типа-NUMBER-в-Oracle-коннекторе","notes/Trino/Выполнение-запросов-напрямую-к-источнику-в-Trino","notes/Trino/Работа-с-view-в-Hive","notes/Trino/MySQL-connector","notes/Trino/Trino-API","notes/Trino/Trino-thrift-connector.-Golang","notes/Trino/Patterns-in-Prometheus-JMX-exporter","notes/Trino/TPCDS","notes/Trino/Извлечение-каталогов-из-SQL-в-Trino-parser","notes/Trino/Connectors-SPI","notes/Trino/Сохранение-federated-query-как-view","notes/Trino/Создание-Hive-Metastore"],"tags":[],"content":"Trino\n\nЗапрос к полю типа map в SQL Trino\nПоля типа NUMBER в Oracle коннекторе\nВыполнение запросов напрямую к источнику в Trino\nРабота с view в Hive\nMySQL connector\nTrino API\nTrino thrift connector. Golang\nPatterns in Prometheus JMX exporter - настройка jmx exporter для Trino.\nTPCDS - инструкция по генерации TPCDS.\nИзвлечение каталогов из SQL в Trino parser\nConnectors SPI\nСохранение federated query как view\nСоздание Hive Metastore\n"},"notes/Trino/Выполнение-запросов-напрямую-к-источнику-в-Trino":{"title":"Выполнение запросов напрямую к источнику в Trino","links":["notes/Trino/Выполнение-запросов-напрямую-к-источнику-в-Trino","notes/Trino/Trino"],"tags":[],"content":"Выполнение запросов напрямую к источнику в Trino\nДля ряда коннекторов, например postgresql и mysql можно выполнять запросы которые будут переданы в соответствующую БД как есть, а не обработаны движком Trino:\nSELECT\n      X,Y\n    FROM\n      TABLE(\n        mariadb.system.query(\n          query =&gt; &#039;SELECT\n            ST_X(loacation) as X,\n            ST_Y/location) As Y\n          FROM\n            mytable&#039;\n        )\n      );\n "},"notes/Trino/Запрос-к-полю-типа-map-в-SQL-Trino":{"title":"Запрос к полю типа map в SQL Trino","links":["notes/Trino/Запрос-к-полю-типа-map-в-SQL-Trino"],"tags":[],"content":"Запрос к полю типа map в SQL Trino\nДля того чтобы использовать в секции where SQL выражения Trino поле с типом map следует воспользоваться функцией\n\nelement_at(map(K, V), key) → V\nReturns value for given key, or NULL if the key is not contained in the map.\n\nПопытка использовать простой запрос может привести к тому, что если такого ключа не будет то произойдет ошибка. Дело в том, что если ключ не встречается в мапе то запрос свалится."},"notes/Trino/Извлечение-каталогов-из-SQL-в-Trino-parser":{"title":"Извлечение каталогов из SQL в Trino parser","links":["notes/Trino/Извлечение-каталогов-из-SQL-в-Trino-parser"],"tags":[],"content":"Извлечение каталогов из SQL в Trino parser\npackage org.example;\n \n \nimport io.trino.sql.parser.ParsingOptions;\nimport io.trino.sql.parser.SqlParser;\nimport io.trino.sql.tree.*;\n \nimport java.util.ArrayList;\nimport java.util.HashSet;\nimport java.util.Optional;\nimport java.util.Set;\n \npublic class Main {\n    public static void main(String[] args) {\n        String sql1 = &quot;&quot;&quot;\n                select distinct\n                        l1.userid,\n                        r33.msisdn\n                from\n                        catalog1.schema1.table1 as l1\n                left join (select distinct msisdn,\n                       websso_guid\n                from (\n                    select  msisdn,\n                            websso_guid,\n                            row_number() over (partition by websso_guid order by business_dttm desc) as win\n                    from catalog1.schema2.table2) as sso\n                where sso.win = 1) as r33\n                on from_utf8(l1.userid)=r33.websso_guid\n                where    2+2=4\n                        and from_utf8(l1.app_package_name) = &#039;app_package_name&#039;\n                        and from_utf8(l1.eventcategory) = &#039;stories&#039;\n                        and from_utf8(l1.eventlabel) = &#039;strs_main_08_cvm_paytag_platite_smartphonom_beskontaktno&#039;\n                        and from_utf8(l1.eventaction) = &#039;button_tap&#039;\n                        and(l1.business_dt between date &#039;2023-08-01&#039; and date &#039;2023-08-31&#039;)\n                &quot;&quot;&quot;;\n \n        String sql2 = &quot;SELECT * FROM catalog1.schema1.table1 LEFT JOIN catalog1.schema1.table2 ON id&quot;;\n \n        String sql3 = &quot;SELECT * FROM catalog1.schema1.table1&quot;;\n \n        String sql4 = &quot;&quot;&quot;\n                select *\n                from catalog1.schema1.table3\n                where 1=1\n                --and raw_dt &gt; date &#039;2023-07-31&#039;\n                --and bundle_id like &#039;%music%&#039;\n                --and bundle_id in (&#039;mobile.music&#039;, &#039;music.android&#039;)\n                --and media_source = &#039;media_source&#039;\n                and campaign = &#039;stories_goroda&#039;\n                limit\n                20\n                &quot;&quot;&quot;;\n \n        String sql5 = &quot;&quot;&quot;\n                with conv as (\n                select msisdn\n                from catalog2.schema2.table1\n                where tbm = cast(&#039;2023-06-01&#039; as date) and abnt_category_ext_1m = &#039;Convergent&#039;\n                )\n                , prem as (\n                select msisdn\n                from catalog2.schema2.table1\n                where tbm = cast(&#039;2023-06-01&#039; as date) and abnt_category_ext_1m = &#039;Premium only&#039;\n                )\n                , prem_kion as (\n                select msisdn\n                from catalog2.schema2.table1\n                where tbm = cast(&#039;2023-06-01&#039; as date) and abnt_category_ext_1m = &#039;KION+Premium&#039;\n                )\n                , pre as\n                (select c.msisdn  --1058211\n                from conv c\n                join catalog1.schema1.table4 p on cast(c.msisdn as decimal) = p.mob_num and p.tbm = cast(&#039;2023-06-01&#039; as date)\n                and p.krem = 1 --and p.is_abnt_wtch_1m = 1\n                )\n                select count(distinct p.msisdn) --991  --57\n                from pre p\n                join prem_kion pp on p.msisdn = pp.msisdn\n                &quot;&quot;&quot;;\n \n        String sql6 = &quot;&quot;&quot;\n                select count(*) from catalog1.schema1.table5\n                where\n                    version_dt = to_date(&#039;2023-09-04&#039;,&#039;yyyy-mm-dd&#039;)&quot;&quot;&quot;;\n \n        String sql7 = &quot;&quot;&quot;\n                select\n                    business_dt,\n                    from_utf8(eventlabel) NazvanieStories,\n                    count(eventaction)filter (where from_utf8(eventaction) = &#039;cover_show&#039;) CoverShow,\n                    count(eventaction)filter (where from_utf8(eventaction) = &#039;cover_tap&#039;) CoverTap,\n                    count(eventaction)filter (where from_utf8(eventaction) = &#039;slide_show&#039; and from_utf8(eventcontent) = &#039;1&#039;) FirstSlideView,\n                    count(eventaction)filter (where from_utf8(eventaction) = &#039;button_tap&#039;) ButtonTap\n                                \n                from catalog1.schema1.table6\n                                \n                where 2+2=4\n                and from_utf8(app_package_name) = &#039;app_package_name&#039;\n                and from_utf8(eventcategory) = &#039;stories&#039;\n                and from_utf8(eventlabel) like &#039;strs_main%&#039;\n                                \n                group by 1,2\n                                \n                order by 1,ButtonTap desc&quot;&quot;&quot;;\n \n        String[] sqls = new String[]{sql1, sql2, sql3, sql4, sql5, sql6, sql7};\n \n        for (String sql : sqls) {\n            parse(sql);\n        }\n \n    }\n \n    private static void parse(String sql) {\n        ArrayList&lt;String&gt; results = new ArrayList&lt;&gt;();\n        ArrayList&lt;String&gt; withTableName = new ArrayList&lt;&gt;();\n \n        SqlParser sqlParser = new SqlParser();\n \n        Statement statement = sqlParser.createStatement(sql, new ParsingOptions());\n \n        for (Node n : statement.getChildren()) {\n            if (n instanceof QuerySpecification qs) {\n                Optional&lt;Relation&gt; from = qs.getFrom();\n                if (from.isPresent()) {\n                    Relation relation = from.get();\n                    recursive(relation, results);\n                }\n            } else if (n instanceof With withNode) {\n                recursive(n, results);\n                withNode.getQueries().forEach(withQuery -&gt; withTableName.add(withQuery.getName().toString()));\n            }\n        }\n        results.removeAll(withTableName);\n        Set&lt;String&gt; final_result = new HashSet&lt;&gt;(results);\n \n        System.out.println(String.join(&quot;\\n&quot;, final_result));\n        System.out.println(&quot;======&quot;);\n    }\n \n    private static void recursive(Node node, ArrayList&lt;String&gt; result) {\n        if (node instanceof Table t) {\n            result.add(t.getName().toString());\n        }\n        for (Node child : node.getChildren()) {\n            if (child instanceof Table t) {\n                result.add(t.getName().toString());\n            } else {\n                recursive(child, result);\n            }\n        }\n    }\n}\n "},"notes/Trino/Поля-типа-NUMBER-в-Oracle-коннекторе":{"title":"Поля типа NUMBER в Oracle коннекторе","links":["notes/Trino/Поля-типа-NUMBER-в-Oracle-коннекторе"],"tags":[],"content":"Поля типа NUMBER в Oracle коннекторе\nПо умолчанию Trino отображает только поля NUMBER с фиксировано точностью. Если точность не указана колонка будет просто проигнорирована.\nСвойство сессии\nМожно задать свойство сессии указывающее значение точности для какого-то каталога по умоляанию в рамках сессии:\nSET SESSION ppms_oracle.number_default_scale = 10;\nПараметр коннектора\nЗначение по умолчанию можно определить через параметр oracle.number.default-scale в настройках каталога."},"notes/Trino/Работа-с-view-в-Hive":{"title":"Работа с view в Hive","links":["notes/Trino/Работа-с-view-в-Hive"],"tags":[],"content":"Работа с view в Hive\nПо умолчанию работа с вьюхами в Trino погашена. Если подумать то это логично учитывая, что из метастора мы можем забрать лишь структуру таблиц и их местоположение в HDFS. Но тут нет блоков которые можно было бы просто прочитать, их надо сформировать и найти согласно логике VIEW, а она может напрямую не поддерживаться в Trino.\nНо такую поддержку можно включить выставив параметр:\nhive.hive-views.enabled=true\nДетали тут."},"notes/Trino/Создание-Hive-Metastore":{"title":"Создание Hive Metastore","links":["notes/Trino/Создание-Hive-Metastore"],"tags":[],"content":"Создание Hive Metastore\nSource:: docs.cedrusdata.ru/latest/guide/data-lakes-hms-setup.html\nДанное руководство представляет инструкции по развертыванию Hive Metastore на локальном компьютере для тестирования работы CedrusData с озерами данных. Мы будем использовать локальную файловую систему для хранения данных и СУБД Postgres в Docker-контейнере для хранения метаданных.\nПроцесс развертывания занимает порядка 10-15 минут.\nВведение\nЧто такое Hive Metastore\nОзеро данных это совокупность файлов, хранящихся в файловой системе (например, HDFS или локальная файловая система) или облаке (например, S3). Для извлечения информации из файлов с помощью SQL необходимы метаданные, которые описывают, как представить информацию из файлов в виде реляционных таблиц. Примерами метаданных являются информация о путях к файлам, информация о колонках и типах данных, информация о partitioning. Hive Metastore представляет собой сервис управления метаданными.\nИсторически Hive Metastore был частью инсталляции Hive, распределенного SQL-движка, который позволяет выполнять SQL-запросы к большим данным с помощью map-reduce задач Hadoop. Со временем популярность Hadoop и Hive снизилась, уступив место таким продуктам, как Spark и Trino. Так как Hive Metastore по-прежнему достаточно хорошо справляется с задачами управления метаданным, его продолжают использовать в инсталляциях Spark, Trino и ряда других продуктов в качестве изолированного компонента. Hive Metastore не требует развертывания Hadoop или Hive, но зависит от некоторых библиотек Hadoop.\nАрхитектура Hive Metastore\nHive Metastore получает запросы на чтение или изменение метаданных от сторонних приложений через встроенный сервер, который работает по протоколу Thrift.\nHive Metastore хранит метаданные в сторонней базе данных для обеспечения сохранности информации в случае перезапуска сервиса. При получении запроса, Hive Metastore получает или обновляет необходимые метаданные в базе данных через интерфейс JDBC.\nНекоторые запросы к Hive Metastore требуют изменение данных непосредственно в файловой системе. Например, при получении запроса на создание схемы, необходимо директорию схемы в файловой системе, а при получении запроса на удаление таблицы, необходимо удалить соответствующие файлы.\nДля выполнения операций над файловой системой, Hive использует интерфейс Hadoop FileSystem. Файловая система может требовать специфичную конфигурацию. Так, для работы с данными в локальной файловой системе необходимо знать директорию, в которой хранятся данные, а для работы с данными в S3 необходимо предоставить URL и ключи доступа к object storage.\n\nРазвертывание Hive Metastore\nИнструкции ниже приведены для операционных систем Ubuntu/Debian с использованием сетевых портов по умолчанию. Адаптируйте инструкции, если вы используете другую операционную систему, или если у вас возникает конфликт портов.\n\nУбедитесь, что у вас установлена JDK 8 или выше. Мы рекомендуем использовать Eclipse Temurin JDK 21, которую можно установить с помощью следующих команд:\n\nwget -O - packages.adoptium.net/artifactory/api/gpg/key/public | sudo apt-key add - &amp;&amp; \\\necho &quot;deb packages.adoptium.net/artifactory/deb $(awk -F= &#039;/^VERSION_CODENAME/{print$2}&#039; /etc/os-release) main&quot; | sudo tee /etc/apt/sources.list.d/adoptium.list &amp;&amp; \\\nsudo apt update &amp;&amp; \\\nsudo apt install temurin-21-jdk\n\n\nУбедитесь, что у вас установлен Docker Engine, и что команда docker не требует sudo.\n\n\nЗапустите экземпляр Postgres в Docker-контейнере:\n\n\ndocker pull postgres\ndocker run --name postgres-hive -e &lt;span&gt;POSTGRES_USER&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;hive -e &lt;span&gt;POSTGRES_PASSWORD&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;hive -p 5432:5432 -d postgres\n\nСоздайте директорию в локальной файловой системе, в которой будут храниться данные. Владельцем директории должен быть пользователь, от имени которого будет запущен Hive Metastore. В данном примере мы создаем директорию /home/hive и меняем владельца на текущего пользователя:\n\nsudo mkdir /home/hive &amp;&amp; \\\nsudo chown $USER /home/hive\n\nСкачайте и распакуйте дистрибутив Hadoop:\n\nwget archive.apache.org/dist/hadoop/common/hadoop-3.3.4/hadoop-3.3.4.tar.gz &amp;&amp; \\\ntar -xf hadoop-3.3.4.tar.gz\n\nСкачайте и распакуйте дистрибутив Hive Metastore:\n\nwget archive.apache.org/dist/hive/hive-standalone-metastore-3.0.0/hive-standalone-metastore-3.0.0-bin.tar.gz &amp;&amp; \\\ntar -xf hive-standalone-metastore-3.0.0-bin.tar.gz\n\nСкачайте JDBC драйвер Postgres, и переместите его в поддиректорию lib/ в директории дистрибутива Hive Metastore:\n\nexport HIVE_HOME=&lt;директория дистрибутива Hive Metastore&gt; &amp;&amp; \\\nwget jdbc.postgresql.org/download/postgresql-42.5.0.jar -P $HIVE_HOME/lib\n\nВ директории дистрибутива Hive Metastore задайте следующее содержимое файлу conf/metastore-site.xml. Важными значениями являются порт сервера Thrift в параметрах hive.metastore.port и metastore.thrift.uris, порт Postgres в параметре javax.jdo.option.ConnectionURL и директория, в которой будут храниться файлы в параметре metastore.warehouse.dir. Измените соответствующие параметры, если вы используете другие порты или другую директорию.\n\n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;hive.metastore.port&lt;/name&gt;\n        &lt;value&gt;9083&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;metastore.thrift.uris&lt;/name&gt;\n        &lt;value&gt;thrift://localhost:9083&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;metastore.task.threads.always&lt;/name&gt;\n        &lt;value&gt;org.apache.hadoop.hive.metastore.events.EventCleanerTask&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;metastore.expression.proxy&lt;/name&gt;\n        &lt;value&gt;org.apache.hadoop.hive.metastore.DefaultPartitionExpressionProxy&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;\n        &lt;value&gt;org.postgresql.Driver&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;\n        &lt;value&gt;jdbc:postgresql://localhost:5432/hive&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;\n        &lt;value&gt;hive&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;\n        &lt;value&gt;hive&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;metastore.warehouse.dir&lt;/name&gt;\n        &lt;value&gt;/home/hive&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n\nЗадайте переменные окружения JAVA_HOME и HADOOP_HOME:\n\nexport JAVA_HOME=&lt;директория установки JDK&gt; &amp;&amp; \\\nexport HADOOP_HOME=&lt;директория дистрибутива Hadoop&gt;\nВо многих случаях директорию установки JDK можно узнать с помощью следующей команды:\necho $(dirname $(dirname $(readlink -f $(which java))))\n\nИз директории дистрибутива Hive Metastore инициализируйте схему Hive Metastore в Postgres:\n\nbin/schematool -initSchema -dbType postgres\n\nИз директории дистрибутива Hive Metastore запустите Hive Metastore:\n\nbin/start-metastore\nНа этом процесс развертывания Hive Metastore завершен.\nПроверка работы Hive Metastore с Trino\nconnector.name=hive\nhive.metastore.uri=thrift://localhost:9083\nhive.security=allow-all\nhive.max-partitions-per-writers=1000000\nbin/trino --execute &quot;create schema hive.my_tpcds&quot; &amp;&amp; \\\nbin/trino --execute &quot;create table hive.my_tpcds.call_center with (format = &#039;PARQUET&#039;) as select * from tpcds.sf1.call_center&quot;\n\n\n                  \n                  Docker \n                  \n                \n\nПри запуске Trino в Docker папка в которой создаются файлы должна быть доступна внутри контейнера Trino!\n\n"},"notes/Trino/Сохранение-federated-query-как-view":{"title":"Сохранение federated query как view","links":["notes/Trino/Сохранение-federated-query-как-view"],"tags":["project/dv/confluence"],"content":"Сохранение federated query как view\nСильной стороной Data Virtualization является возможность построения так называемых федеративных запросов (federated query), то есть запросов, которые объединяют в себе различные источники данных (каталоги в терминах системы).\nТакой запрос может быть весьма сложным и, наверное, может представлять ценность сам по себе. Например, для использования его как самостоятельной таблицы для дальнейшей работы.\nВ традиционных СУБД мы можем использовать для этих целей View, но View − это сущность в той или иной базе данных. Можно ли создать что-то похожее в Trino? Да, можно!\nСущность называется так же, то есть мы просто можем создать View, но есть один нюанс: сделать это можно лишь в каталоге, который использует Hive MetaStore.\nТо есть, если ваш запрос объединяет в себе данные, например, из кластеров GreenPlum и ClickHouse вы всё равно можете создать View, но лишь в перечисленных выше каталогах. Вот пример такого запроса:\ncreate view hive.dv_wrk.demo_view as (select\n\tfrom_utf8(bd_cat_name) as cat_name,\n\tsum(request_cnt) AS cnt\nfrom\n\thive.netscout_cdm.agg_host_d host_d \njoin\n\tch_demo.default.v_catalog_2gis_domains gis \n\ton host_d.host_name=from_utf8(gis.domain)\n\tAND host_d.business_dt=date(&#039;2023-03-01&#039;)\ngroup by\n\tbd_cat_name\norder by cnt desc);\n,где hive.dv_wrk − база данных в Hive MetaStore, к которой у пользователя есть доступ.\nБолее подробно о SQL синтаксисе и нюансах доступа при создании View в Trino вы можете прочитать здесь."},"notes/VScode-hotkeys":{"title":"VScode hotkeys","links":["notes/VScode-hotkeys"],"tags":[],"content":"VScode hotkeys\n\n⇧+⌥+I - создать курсор в конце каждой строки выделенного блока.\n⇧+⌘+L - создать курсор для всех слов что сейчас выделены.\n⇧+⌥+F - отформатировать документ.\n⌘+K   ⌘+X - удалить пробелы в конце строки\n"},"notes/Video/00_DaVinci-Resolve":{"title":"00_DaVinci Resolve","links":["notes/Video/00_DaVinci-Resolve","notes/Video/Базовое-редактирование-видео","notes/Video/Ключевые-точки","notes/Video/Цветокоррекция","notes/Video/Синхронизация-двух-камер","notes/Video/Картинка-в-картинке","notes/Video/Добавление-фона-для-вертикального-видео"],"tags":[],"content":"00_DaVinci Resolve\n\nБазовое редактирование видео\nКлючевые точки\nЦветокоррекция\nСинхронизация двух камер\nКартинка в картинке\nДобавление фона для вертикального видео\n"},"notes/Video/Базовое-редактирование-видео":{"title":"Базовое редактирование видео","links":["notes/Video/Базовое-редактирование-видео"],"tags":[],"content":"Базовое редактирование видео\n\nНа вкладке Edit основные комбинации клавиш и возможности:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKeyDescAРежим курсора/выделенияBРежим лезвия (blade) - нужен для обрезки кусков клиповBackspaceУдаление клипа без авто-сдвига таймлайнаDeleteУдаление клипа с авто-сдвигом таймлайнаCmd-zОтмена последней операцииShit-Cmd-zRedo последней операции"},"notes/Video/Добавление-фона-для-вертикального-видео":{"title":"Добавление фона для вертикального видео","links":["notes/Video/Добавление-фона-для-вертикального-видео"],"tags":[],"content":"Добавление фона для вертикального видео\n\nВытаскиваем видео на timeline\nС зажатым option перетаскиванием дублируем его на ещё одну дорожку.\nДля одной из двух дорожек (на вкладке Edit или Cut) настраиваем масштаб. Inspector → Video → Transform → Zoom X. Таким образом это видео будет занимать весь кадр.\nНа вкладке Edit ищем Gaussian Blur и применяем его к дорожке из третьего шага перетаскиванием.\n\nВ Inpsector → Effects настраиваем силу эффекта по горизонтали или вертикали (по умолчанию они равны друг другу).\n\n\n"},"notes/Video/Как-переименовать-камеры-в-Multicam":{"title":"Как переименовать камеры в Multicam","links":["notes/Video/Как-переименовать-камеры-в-Multicam"],"tags":[],"content":"Как переименовать камеры в Multicam\n\nВ контекстном меню Multicam ролика можно выбрать опцию “Open in timeline”. В этом режиме откроется работа с ним как с отдельными треками.\nТут можно переименовать и поиграть например со звуком. Работая с громкостью отдельных каналов.\n"},"notes/Video/Картинка-в-картинке-в-круге-Open-FX":{"title":"Картинка в картинке в круге Open FX","links":["notes/Video/Картинка-в-картинке-в-круге-Open-FX"],"tags":[],"content":"Картинка в картинке в круге Open FX\n\nНа вкладке Effects находим Open FX эффект “Transform” и применяем его (перетаскивая на таймлайн) к дорожке которую хотим сделать маленькой.\nВ Inspector на вкладке Effects для эффекта Transform в разделе Image Adjustment ставим в единицу параметр Edge Rounding.\nНа вкладке Inspector’а Video изменяя параметры Zoom и Position двигаем картинку внутри полученного круга.\nВ Inspector на вкладке Effects для эффекта Transform параметры Position и Zoom определяют местоположение и масштаб самого круга.\n"},"notes/Video/Картинка-в-картинке.-Трансформация":{"title":"Картинка в картинке. Трансформация","links":["notes/Video/Картинка-в-картинке.-Трансформация"],"tags":[],"content":"Картинка в картинке. Трансформация\n\nВ окне Edit открываем inspector\n\nВ секции Cropping подрезаем видео убирая лишнее (оставляем голову)\nВ секции Transform изменяем\n\nМасштаб чтобы картинка стала маленькой\nПоложение по осям X и Y для размещения в нужной части экрана\n\n\n\n\n"},"notes/Video/Картинка-в-картинке":{"title":"Картинка в картинке","links":["notes/Video/Картинка-в-картинке","notes/Video/Картинка-в-картинке.-Трансформация","notes/Video/Картинка-в-картинке-в-круге-Open-FX"],"tags":[],"content":"Картинка в картинке\nЯ нашел два способа разместить картинку в картинке. Это удобно например для небольшой говорящей головы в рамках скринкаста.\n\nКартинка в картинке. Трансформация\nКартинка в картинке в круге Open FX\n"},"notes/Video/Ключевые-точки":{"title":"Ключевые точки","links":["notes/Video/Ключевые-точки"],"tags":[],"content":"Ключевые точки\n\nПри выставлении какого либо параметра, например силу гаусова размытия, можно определить точку начала и точку конца этого эффекта.\nНапример в точке начала может быть выставлена сила эффекта в ноль, а в конечной в единицу. DaVinci осуществит плавный переход от нуля до единицы. То есть сила (в данном примере, а вообще величина параметра) будет плавно меняться от первой точки до конечной.\nЕсли это применить например к координатам то объект будет двигаться или менять свои размеры.\nРомбики на фото ниже задают ключевые точки.\n"},"notes/Video/Синхронизация-двух-камер":{"title":"Синхронизация двух камер","links":["notes/Video/Синхронизация-двух-камер","notes/Video/Как-переименовать-камеры-в-Multicam"],"tags":[],"content":"Синхронизация двух камер\nПохоже что существует два подхода. Один строится на простом выравнивании клипов друг относительно друга, а другой на создании специальной сущности для работы с множеством камер.\nПод мои нужды куда лучше подходит первый но попробую описать оба.\nВыравнивание клипов\n\nДобавить оба клипа на таймлайн.\nВыбрать оба.\nВ контекстном меню воспользоваться “Auto Align Clips&quot;→&quot;Based on waveform”\n\nMulticam timeline\n\nВыбрать все клипы (например на вкладке Media) и в контекстном меню использовать “Create new miulticam clip using selected clips”.\n\nИсходные клипы будут перенесены в папку “Original Clips”\n\n\nНа созданном клипе нужно в контекстном меню выбрать “Create New Timeline”.\nВ окне Edit при работе с timeline созданным на втором шаге следует включить отображение в двух панелях и в левом выбрать режим работы “Multicam”. Выбор мышью соответствующей камеры переключить фокус на неё.\n\nFriend:: Как переименовать камеры в Multicam"},"notes/Video/Цветокоррекция":{"title":"Цветокоррекция","links":["notes/Video/Цветокоррекция"],"tags":[],"content":"Цветокоррекция\n\nПо факту я особо не разобрался но:\n\nВсе действия происходят на вкладке Color.\n\nВот на этой карттинке символ A в круге означает автоматическую корректировку баланса.\nЕсли авто-корректировкой не пользоваться то задача выравнять графики справа примерно в один уровень с помощью ползунков левой части.\n"},"notes/Vim":{"title":"Vim","links":["notes/Vim","notes/Основы-Vim","notes/Перемещение-по-тексту-Vim","notes/Работа-с-регистрами-Vim"],"tags":[],"content":"Vim\n\nОсновы Vim\nПеремещение по тексту Vim\nРабота с регистрами Vim\n"},"notes/VirtualBox-with-UEFI-Secure-Boot":{"title":"VirtualBox with UEFI Secure Boot","links":["notes/VirtualBox-with-UEFI-Secure-Boot"],"tags":[],"content":"VirtualBox with UEFI Secure Boot\nSource:: superuser.com/questions/1438279/how-to-sign-a-kernel-module-ubuntu-18-04\n\nCreate a personal public/private RSA key pair to sign the kernel modules. As recommended in the link below, I chose to store the key/pair in the /root/module-signing/ directory.\n\nsudo -i\nmkdir /root/module-signing\ncd /root/module-signing\nopenssl req -new -x509 -newkey rsa:2048 -keyout MOK.priv -outform DER -out MOK.der -nodes -days 36500 -subj &quot;/CN=YOUR_NAME/&quot;\nchmod 600 MOK.priv \n\nUse mokutil, a tool to import or delete the machine owner keys (MOK), to import the public key, and then enroll it when the machine is rebooted. The password in this step is a temporary use password you’ll only need to remember for a few minutes.\n\nmokutil --import /root/module-signing/MOK.der\ninput password:\ninput password again:\n\n\nReboot the machine. When the bootloader starts, you should see a screen asking you to press a button to enter the MOK manager EFI utility. Note that any external external keyboards won’t work in this step. Select Enroll MOK in the first menu, then continue, and then select Yes to enroll the keys, and re-enter the password established in step 2. Then select OK to continue the system boot.\n\n\nFuture kernel updates would require the updated kernels to be signed again, so it makes sense to put the signing commands in a script that can be run at a later date as necessary. A sample script /root/module-signing/sign-vbox-modules is given below.\n\n\n#!/bin/bash\n \nfor modfile in $(dirname $(modinfo -n vboxdrv))/*.ko; do\n  echo &quot;Signing $modfile&quot;\n  /usr/src/linux-headers-$(uname -r)/scripts/sign-file sha256 \\\n                                /root/module-signing/MOK.priv \\\n                                /root/module-signing/MOK.der &quot;$modfile&quot;\ndone\n\nAdd execution permission, and run the script above as root from the /root/module-signing/ directory.\n\nsudo -i\ncd /root/module-signing\nchmod 700 /root/module-signing/sign-vbox-modules\n./sign-vbox-modules\n\nLoad vboxdrv module and launch VirtualBox.\n\nmodprobe vboxdrv "},"notes/Xiaomi-Mi-Cloud-from-python":{"title":"Xiaomi Mi Cloud from python","links":["notes/Xiaomi-Mi-Cloud-from-python"],"tags":["reference/python"],"content":"Xiaomi Mi Cloud from python\nНастройка\nПолучение токена от Gateway\npip install micloud\nmicloud -u maksim77ster@gmail.com -p &lt;password&gt; -c cn &gt; result.json\nНадо найти Gateway в полученном списке. Предполагаю, что он будет первым.\nСоответственно нас интересует:\n\nIP: cat result.json| jq &quot;.[0].localip&quot;\nTOKEN: cat result.json| jq &quot;.[0].token&quot;\n\nУстановка библиотеки\npip install python-miio==0.5.12\n\nВерсия на самом деле может быть и более новой. Пишу просто работающую у меня на 2022-11-16.\nКод\nfrom miio.gateway.gateway import Gateway\n \ng = Gateway(&#039;100.64.88.74&#039;, &#039;31fc********d8007*****0f&#039;)\n# g.discover_devices()\n{&#039;lumi.158d00025c03e4&#039;: &lt;Subdevice SensorHT: lumi.158d00025c03e4, model: WSDCGQ11LM, zigbee: lumi.weather.v1, fw: 3, bat: 60, vol: None, props: {&#039;temperature&#039;: None, &#039;humidity&#039;: None, &#039;pressure&#039;: None}&gt;,\n &#039;lumi.158d000326dc60&#039;: &lt;Subdevice Switch: lumi.158d000326dc60, model: QBKG03LM, zigbee: lumi.ctrl_neutral2, fw: 1, bat: None, vol: None, props: {&#039;status_ch0&#039;: None, &#039;status_ch1&#039;: None}&gt;,\n &#039;lumi.158d000233b33c&#039;: &lt;Subdevice WaterLeakSensor: lumi.158d000233b33c, model: SJCGQ11LM, zigbee: lumi.sensor_wleak.aq1, fw: 4, bat: 60, vol: None, props: {}&gt;,\n &#039;lumi.158d00033aeb98&#039;: &lt;Subdevice Motion: lumi.158d00033aeb98, model: RTCGQ11LM, zigbee: lumi.sensor_motion.aq2, fw: 5, bat: 60, vol: None, props: {&#039;motion&#039;: False}&gt;,\n &#039;lumi.158d0004830970&#039;: &lt;Subdevice Switch: lumi.158d0004830970, model: QBKG03LM, zigbee: lumi.ctrl_neutral2, fw: 1, bat: None, vol: None, props: {&#039;status_ch0&#039;: None, &#039;status_ch1&#039;: None}&gt;,\n &#039;lumi.158d000345660b&#039;: &lt;Subdevice Switch: lumi.158d000345660b, model: QBKG04LM, zigbee: lumi.ctrl_neutral1.v1, fw: 1, bat: None, vol: None, props: {&#039;status_ch0&#039;: None}&gt;,\n &#039;lumi.158d0004515e61&#039;: &lt;Subdevice Switch: lumi.158d0004515e61, model: QBKG04LM, zigbee: lumi.ctrl_neutral1.v1, fw: 1, bat: None, vol: None, props: {&#039;status_ch0&#039;: None}&gt;,\n &#039;lumi.158d00032165d8&#039;: &lt;Subdevice Magnet: lumi.158d00032165d8, model: MCCGQ11LM, zigbee: lumi.sensor_magnet.aq2, fw: 3, bat: 60, vol: None, props: {&#039;is_open&#039;: False}&gt;,\n &#039;lumi.158d00045167bf&#039;: &lt;Subdevice Switch: lumi.158d00045167bf, model: QBKG04LM, zigbee: lumi.ctrl_neutral1.v1, fw: 1, bat: None, vol: None, props: {&#039;status_ch0&#039;: None}&gt;}\n\nsensor = g.discover_devices()[&#039;lumi.158d00025c03e4&#039;]\nsensor.update()\n \n# print(sensor._props)\n# {&#039;temperature&#039;: 9.31, &#039;humidity&#039;: 26.75, &#039;pressure&#039;: 994.6}\n \nprint(f&quot;Temperature: {sensor._props[&#039;temperature&#039;]}&quot;)\nprint(f&quot;Humidity: {sensor._props[&#039;humidity&#039;]}&quot;)\nTemperature: 18.03\nHumidity: 24.39\n"},"notes/YandexGPT-в-Obsidian-TextGenerator":{"title":"YandexGPT в Obsidian TextGenerator","links":["notes/YandexGPT-в-Obsidian-TextGenerator","notes/Получение-IAM_TOKEN-в-YC","notes/Получение-API-ключа-в-YC","notes/Получение-ID-каталога-в-Yandex-Cloud","notes/Температура-запроса-LLM","notes/Роль-модели-в-AI"],"tags":[],"content":"YandexGPT в Obsidian TextGenerator\nДля того чтобы работать с API YandexGPT необходимо быть зарегистрированным в Yandex Cloud и иметь действующий платежный аккаунт.\nДля авторизации в API потребуется либо IAM токен либо API ключ.\n\nПолучение IAM_TOKEN в YC\nПолучение API ключа в YC\n\nObsidian\n\nУстановить плагин TextGenerator\nВыбрать Provider Profile - Custom или клонировать его нажав +\n\nВ поле Endpoint указать llm.api.cloud.yandex.net/foundationModels/v1/completion\nВ поле API Key указать либо IAM_TOKEN либо API ключ полученный ранее\n\nAdvanced mode\nДальнейшие пункты настраиваются после включения переключателя Advanced mode.\n\nВ секции Headers указываем следующее при использовании ключа API.\n\n{\n    &quot;Content-Type&quot;: &quot;application/json&quot;,\n    &quot;Authorization&quot;: &quot;Api-Key {{api_key}}&quot;, \n    &quot;x-folder-id&quot;: &quot;b1gjpq05r3ppsou34c7d&quot;\n}\nИли вот так при при использовании IAM токена:\n{\n    &quot;Content-Type&quot;: &quot;application/json&quot;,\n    &quot;Authorization&quot;: &quot;Bearer {{api_key}}&quot;, \n    &quot;x-folder-id&quot;: &quot;b1gjpq05r3ppsou34c7d&quot;\n}\nВ x-folder-id необходимо подставить идентификатор того каталога для которого создавался ключ/токен.\n\nВ секции Body пропишем тело запроса.\n\n{\n  &quot;modelUri&quot;: &quot;gpt://b1gjpq05r3ppsou34c7d/yandexgpt/latest&quot;,\n  &quot;completionOptions&quot;: {\n    &quot;stream&quot;: false,\n    &quot;temperature&quot;: {{temperature}},\n    &quot;maxTokens&quot;: {{max_tokens}}\n  },\n  &quot;messages&quot;:  [{&quot;text&quot;:  {{stringify tg_selection}}, &quot;role&quot;:&quot;user&quot;}] \n}\nГде\n\nmodelUri это адрес модели выключающий в себя идентификатор каталога из шагов выше. Список существующих моделей можно посмотреть тут.\ntemperature - температура запроса.\nВ списке messages возможно стоит определить роль модели. Что-то типа:\n\n\nТы AI асистент встроенный в Obsidian. Твоё назначение помогать создавать и редактировать статьи внутри PKM.\n\n\nВ секции Response Sanatization прописываем обработчик ответов API:\n\nif (res.status &gt;= 300) {\n  const err = data?.error?.message || JSON.stringify(data);\n  throw err;\n}\n \nconst choices = data.result.alternatives.map(c =&gt; ({ content: c.message.text }));\n \nreturn choices;\n\nОбязательно устанавливаем галочку CORS Bypass\n\nЭкспортированный профиль\nTextGenerator поддерживает импорт-экспорт профилей. Ниже приведен сохраненный результат описывающий действия выше.\n{\n  id: &#039;Default (Custom) 2&#039;,\n  profile: {\n    extends: &#039;Default (Custom)&#039;,\n    name: &#039;YandexGPT&#039;,\n  },\n  config: {\n    endpoint: &#039;llm.api.cloud.yandex.net/foundationModels/v1/completion&#039;,\n    custom_header: &#039;{\\n    &quot;Content-Type&quot;: &quot;application/json&quot;,\\n    &quot;Authorization&quot;: &quot;Api-Key {{api_key}}&quot;, \\n&quot;x-folder-id&quot;: &quot;b1gjpq05r3ppsou34c7d&quot;\\n}&#039;,\n    custom_body: &#039;{\\n  &quot;modelUri&quot;: &quot;gpt://b1gjpq05r3ppsou34c7d/yandexgpt/latest&quot;,\\n  &quot;completionOptions&quot;: {\\n    &quot;stream&quot;: false,\\n    &quot;temperature&quot;: {{temperature}},\\n    &quot;maxTokens&quot;: {{max_tokens}}\\n  },\\n  &quot;messages&quot;:  [{&quot;text&quot;:  {{stringify tg_selection}}, &quot;role&quot;:&quot;user&quot;}] \\n}\\n&#039;,\n    model: &#039;gpt-3.5-turbo-16k&#039;,\n    sanatization_streaming: &#039;// catch error\\nif (res.status &gt;= 300) {\\n  const err = data?.error?.message || JSON.stringify(data);\\n  throw err;\\n}\\nlet resultText = &quot;&quot;;\\nconst lines = chunk.split(&quot;\\ndata: &quot;);\\n\\nconst parsedLines = lines\\n    .map((line) =&gt; line.replace(/^data: /, &quot;&quot;).trim()) // Remove the &quot;data: &quot; prefix\\n    .filter((line) =&gt; line !== &quot;&quot; &amp;&amp; line !== &quot;[DONE]&quot;) // Remove empty lines and &quot;[DONE]&quot;\\n    .map((line) =&gt; {\\n        try {\\n            return JSON.parse(line)\\n        } catch { }\\n    }) // Parse the JSON string\\n    .filter(Boolean);\\n\\nfor (const parsedLine of parsedLines) {\\n    const { choices } = parsedLine;\\n    const { delta } = choices[0];\\n    const { content } = delta;\\n    // Update the UI with the new content\\n    if (content) {\\n        resultText += content;\\n    }\\n}\\nreturn resultText;&#039;,\n    sanatization_response: &#039;if (res.status &gt;= 300) {\\n  const err = data?.error?.message || JSON.stringify(data);\\n  throw err;\\n}\\n\\nconst choices = data.result.alternatives.map(c =&gt; ({ content: c.message.text }));\\n\\nreturn choices;&#039;,\n    frequency_penalty: 0,\n    presence_penalty: 0.5,\n    top_p: 1,\n    CORSBypass: true,\n    streamable: false,\n    api_key: &#039;&#039;,\n  },\n}"},"notes/ZNode":{"title":"ZNode","links":["notes/ZNode","notes/ZooKeeper"],"tags":[],"content":"ZNode\nZNode — это базовая единица хранения данных в системе координации Apache ZooKeeper.\nОсновные характеристики ZNode:\nИерархическая структура:\nZNode организованы в виде иерархической структуры, похожей на файловую систему. Каждый ZNode может содержать данные и иметь дочерние ZNode.\nДанные и метаданные:\nКаждый ZNode может хранить данные и метаданные. Метаданные включают информацию о версии данных, времени создания и модификации, а также ACL (список контроля доступа).\nТипы ZNode:\n\nPersistent ZNode: Создаются с помощью команды create, и они остаются в системе до тех пор, пока не будут удалены явно.\nEphemeral ZNode: Создаются с помощью команды create -e, и они автоматически удаляются, когда клиент, создавший их, отключается от ZooKeeper.\nSequential ZNode: Создаются с помощью команды create -s, и им автоматически присваивается уникальный порядковый номер.\n\nНаблюдение (Watch):\nКлиенты могут установить наблюдение (watch) на ZNode. Если происходит изменение данных или структуры ZNode, клиенты, установившие наблюдение, получают уведомление.\nТранзакции\nВсе операции с ZNode являются атомарными. Это означает, что либо вся операция выполняется успешно, либо ничего не происходит."},"notes/ZooKeeper-GUI":{"title":"ZooKeeper GUI","links":["notes/ZooKeeper-GUI","notes/ZooKeeper","tags/reference/ubuntu","tags/reference/macos"],"tags":["reference/ubuntu","reference/macos"],"content":"ZooKeeper GUI\nСписок GUI клиентов, что я использовал для работы с ZooKeeper.\nPrettyZoo\nSource:: github.com/vran-dev/PrettyZoo\n\n\n                  \n                  Project archived \n                  \n                \n\nВ июне 2024-ого проект заархивировн.\n\n\nВubuntu устанавливается как deb пакет.\nВmacos есть dmg образ.\nПриятный GUI, работающий достаточно быстро\nZoonavigator\nSource:: github.com/elkozmon/zoonavigator\nЖивой проект по состоянию на ноябрь 2024-ого.\nЗапускается как веб-сервис, доступ через браузер. В Ubuntu это snap или docker образ."},"notes/ZooKeeper":{"title":"ZooKeeper","links":["notes/ZooKeeper","notes/ZNode","notes/Kafka/Apache-Kafka","notes/ZooKeeper-GUI"],"tags":[],"content":"ZooKeeper\nsource:: zookeeper.apache.org/\nApache Zookeeper — это централизованная служба для управления конфигурацией, синхронизации и предоставления групповых услуг в распределенных системах.\nОсновные характеристики\n\nЦентрализованное управление: Позволяет управлять конфигурацией и состоянием распределенных приложений.\nСинхронизация: Обеспечивает механизмы для синхронизации процессов в распределенной среде.\nВысокая доступность: Поддерживает репликацию данных для обеспечения отказоустойчивости.\n\nАрхитектура\n\nСерверы Zookeeper: Состоят из набора серверов, которые хранят данные и обрабатывают запросы.\n\nОсновная единица хранения информации в Zookeeper - ZNode\n\n\nКлиенты: Приложения, которые взаимодействуют с Zookeeper для получения конфигурации и состояния.\n\nПрименение\n\nКоординация распределенных приложений: Используется для управления состоянием и конфигурацией в таких системах, как Hadoop и Kafka.\nСинхронизация: Позволяет синхронизировать доступ к ресурсам между различными узлами.\n\nFriend:: Apache Kafka, ZooKeeper GUI"},"notes/debug-container-k8s":{"title":"debug container k8s","links":[],"tags":["reference/kubernetes"],"content":"Debug Container\nЗапуск debug container’а в K8S\nkubectl run tmp-shell --rm -i --tty --image nicolaka/netshoot -- /bin/bash"},"notes/ingres":{"title":"ingres","links":["notes/ingres","notes/Настройка-ssl-microk8s"],"tags":["reference/kubernetes"],"content":"ingres\n\nВключение аддона microk8s enable ingress\nПосле этого можно создавать ингресы примерно вот так:\n\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  annotations:\n    cert-manager.io/cluster-issuer: lets-encrypt\n    meta.helm.sh/release-name: grafana\n    meta.helm.sh/release-namespace: monitoring\n  creationTimestamp: &quot;2024-08-23T10:19:10Z&quot;\n  generation: 3\n  labels:\n    app.kubernetes.io/instance: grafana\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: grafana\n    app.kubernetes.io/version: 11.1.4\n    helm.sh/chart: grafana-8.4.7\n  name: grafana\n  namespace: monitoring\n  resourceVersion: &quot;4379574&quot;\n  uid: e2fe91d3-bcad-4476-b523-7ddea8f279be\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: grafana.mak-sim.ru\n    http:\n      paths:\n      - backend:\n          service:\n            name: grafana\n            port:\n              number: 80\n        path: /\n        pathType: Prefix\n  tls:\n  - hosts:\n    - grafana.mak-sim.ru\n    secretName: grafana-tls\nstatus:\n  loadBalancer:\n    ingress:\n    - ip: 127.0.0.1\n \n\nНастройка ssl microk8s\n"},"notes/konfig":{"title":"konfig","links":["[](https:/github.com/corneliusweig/konfig)","notes/Krew"],"tags":["reference/kubernetes"],"content":"Konfig\nУтилита позволяющая управлять файлами конфигурации kubeconfig. Склеивать их, вытаскивать какой-то один контекст и многое другое.\nGitHub\nУстановка\nЧерез Krew\nkubectl krew install konfig\nВручную\ncurl -Lo konfig github.com/corneliusweig/konfig/raw/v0.2.6/konfig \\\n  &amp;&amp; chmod +x konfig \\\n  &amp;&amp; sudo mv -i konfig /usr/local/bin\nИспользование\nИмпорт Kubeconfig\nСледующая команда добавит новый файл new-cfg в стандартный конфиг.\nkonfig import --save new-cfg\nОна же без ключа save покажет как будет изменён файл конфига, но не запишет изменений.\nОбъединение двух файлов\nСледующая команда объединить два конфигурационных файла.\nkonfig merge config1 config2 &gt; merged-config\nИзвлечение минимального Kubeconfig для определённого контекста\nkonfig export minikube &gt; minikube.config\nFriend:: Krew"},"notes/microk8s":{"title":"microk8s","links":["notes/microk8s","notes/ingres","notes/Добавление-IP-и-DNS-в-сертификат-microk8s"],"tags":["reference/kubernetes"],"content":"microk8s\n\ningres\nДобавление IP и DNS в сертификат microk8s\n"},"notes/neo4j-в-Golang":{"title":"neo4j в Golang","links":["notes/neo4j-в-Golang","notes/OTEL/Инструментирование-OTEL-neo4j"],"tags":[],"content":"neo4j в Golang\nChildren:: Инструментирование OTEL neo4j\nЗапись данных\n\t// Создаем сессию\n\tsession := driver.NewSession(ctx, neo4j.SessionConfig{AccessMode: neo4j.AccessModeWrite})\n\tdefer func() {\n\t\t_ = session.Close(ctx)\n\t}()\n \n\t// Запись данных\n\t_, err = session.ExecuteWrite(ctx, func(tx neo4j.ManagedTransaction) (any, error) {\n\t\t// Создание пользователей\n\t\tqueries := []struct {\n\t\t\tquery  string\n\t\t\tparams map[string]interface{}\n\t\t}{\n\t\t\t{query: &quot;MERGE (a:Person {name: $name, age: $age})&quot;, params: map[string]interface{}{&quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 30}},\n\t\t\t{query: &quot;MERGE (b:Person {name: $name, age: $age})&quot;, params: map[string]interface{}{&quot;name&quot;: &quot;Bob&quot;, &quot;age&quot;: 25}},\n\t\t\t{query: &quot;MERGE (c:Person {name: $name, age: $age})&quot;, params: map[string]interface{}{&quot;name&quot;: &quot;Charlie&quot;, &quot;age&quot;: 35}},\n\t\t}\n\t\tfor _, q := range queries {\n\t\t\t_, err := tx.Run(ctx, q.query, q.params)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\nЧтение данных\n\t// Чтение данных: находим друзей для Alice\n\t_, err = session.ExecuteRead(ctx, func(tx neo4j.ManagedTransaction) (any, error) {\n\t\tresult, err := tx.Run(ctx,\n\t\t\t&quot;MATCH (a:Person {name: $name})-[:FRIENDS]-&gt;(friend) &quot;+\n\t\t\t\t&quot;RETURN friend.name AS name, friend.age AS age&quot;,\n\t\t\tmap[string]interface{}{&quot;name&quot;: &quot;Alice&quot;})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n \n\t\t// Обработка результата\n\t\tfmt.Println(&quot;Друзья Alice:&quot;)\n\t\tfor result.Next(ctx) {\n\t\t\trecord := result.Record()\n\t\t\tname, _ := record.Get(&quot;name&quot;)\n\t\t\tage, _ := record.Get(&quot;age&quot;)\n\t\t\tfmt.Printf(&quot;- %s (Возраст: %d)\\n&quot;, name, age)\n\t\t}\n \n\t\treturn nil, result.Err()\n\t})\n\tif err != nil {\n\t\tlog.Fatalf(&quot;Ошибка выполнения чтения: %v&quot;, err)\n\t}"},"notes/tcpdump":{"title":"tcpdump","links":["notes/tcpdump"],"tags":[],"content":"tcpdump\nВот так можно прослушать траффик с определенного хоста на определенном интерфейсе\ntcpdump -i ens192 host 11.222.10.249 -n\n"},"notes/Архитектура-Greenplum":{"title":"Архитектура Greenplum","links":["notes/Архитектура-Greenplum","notes/Принципы-параллельной-обработки-в-Greenplum"],"tags":[],"content":"Архитектура Greenplum\nКластер Greenplum должен состоять из нескольких хостов.\n\nМастер-хост - через него подключаются клиенты к кластеру.\nРезервный мастер-хост - standbay для мастера.\nСегмент хосты. Подключение к ним напрямую не возможно, они хранят и обрабатывают сами данные.\n\nВсе хосты объединены одной сетью интерконнект отличающейся от той по которой подключаются пользователи.\n\nНа каждом хосте Greenplum запущены один или несколько экземпляров PostgreSQL. У каждого экземпляра свои процессы, директория с данными, логами и конфигурационными файлами. Эти экземпляры называются сегментами Greenplum.\nТипы сегментов Greenplum:\nМастер (Master)\nМастер присутствует в кластере в единственном экземпляре, резервируется standby мастером и располагается на мастер-хосте. Он принимает подключения клиентов, выдаёт результаты запросов, обеспечивает координацию работы всего кластера.\nТак же может называться coordinator\nРезервный мастер (Standby)\nПринимает поток репликации с мастера. Располагается на отдельном резервном мастер-хосте. При нормальной работе к нему невозможно подключиться, но в случае отказа мастера можно активировать резеврный мастер и перевести его в режим мастера.\nПервичные сегменты (Primary segments).\nЭтих сегментов в кластере несколько. Они располагаются на сегмент-хостах. В своих директориях первичные сегменты хранят пользовательские данные и реплику каталога БД. На первичных сегментах обрабатываются SQL- и DML-операции, они несут основную пользовательскую нагрузку.\nСегменты-зеркала (Mirror segments)\nЭтих сегментов в кластере столько же, сколько и первичных. Зеркала располагаются на сегмент-хостах и хранят реплики данных с первичных сегментов. Они не обрабатывают запросы, а только принимают поток репликации данных, поэтому почти не создают нагрузку на процессор и память. Репликация на зеркалах синхронная: при записи данных на первичный сегмент транзакция не закончится, пока данные не реплицируются на зеркало.\n\n\n                  \n                  NOTE\n                  \n                \n\nКоличество сегментов на сегмент-хостах всегда одинаково для обеспечения равномерности нагрузки по хостам.\n\n\n\n\n\n                  \n                  NOTE\n                  \n                \n\nУ одного первичного сегмента одно и только одно зеркало, которое располагается на другом сегмент-хосте. Количество зеркал совпадает с количеством первичных сегментов.\n\n\nМожно посмотреть список всех сегментов вместе с мастером и резервным мастером в системной таблице gp_segment_configuration.\nselect * from gp_segment_configuration;\nTransclude of Принципы-параллельной-обработки-в-Greenplum\nЗагрузка-выгрузка данных из внешних источников\nНесмотря на то, что управление GP и запросы к кластеру идут через мастер ноду загрузка и выгрузка внешних данных может осуществляться через сегменты, что увеличивает производительность.\nСо стороны клиента параллельная загрузка данных в Greenplum выглядит как SELECT из таблицы, которая ссылается на внешний источник, а выгрузка данных из Greenplum — как INSERT в неё."},"notes/Высоконагруженные-приложения":{"title":"Высоконагруженные приложения","links":["notes/Cypher","notes/Neo4j","notes/OLTP-vs-OLAP","notes/Olap-Cube"],"tags":[],"content":"Высоконагруженные приложения\nZotero\nPDF\nПредисловие\n\n\n                  \n                   DIA (data-intensive application)\n                  \n                \n\nВысоконагруженные данными приложения. Узким местом является количество, скорость поступления или сложность данных.\n\n\n\n\n                  \n                   CIA (compute-intensive application)\n                  \n                \n\nВысоконагруженные вычислениями приложения. Узким местом является CPU.\n\n\nI. Основы информационных систем\n1. Надежные, масштабируемые и удобные в сопровождении приложения\nНадёжность\nПроблемы с надежностью можно верхнеуровнево разделить на три категории.\n\nАппаратные сбои. В современном мире обычно решаются многократным резервированием или возможностью быстро масштабироваться.\nПрограммные то сбои. Код не совершенен, баги могут всплывать где угодно. Решается грамотной архитектурой, тестированием и многими другими подходами.\nЧеловеческий фактор. Люди допускают ошибки и это неизбежно.\n\nМасштабируемость\n\nАвтор пишет, что Масштабируемость - это способность системы справляться с возросшей нагрузкой. Мне кажется, что в современном мире способность системы масштабироваться вниз не менее важна.\nВажно выбрать корректные параметры нагрузки на которые будем опираться при анализе проблемы масштабирования. Это может быть экстремумы или наоборот низкие процентили.\nОписание производительности. После того как описали нагрузку важно выяснить, что конкретно произойдёт при ее возрастании.\n\nУдобство сопровождения\nМожно выделить три основных принципа разработки ПО облегчающих его сопровождение.\n\nУдобство эксплуатации. Облегчает обслуживающему персоналу поддержание беспрепятственной работы системы.\n\nВ самом коде сервиса могут быть заложены компоненты облегчающие его эксплуатацию. Например встроенный мониторинг, масштабируемость между узлами, внятная документация и так далее.\n\n\nПростота. Облегчает понимание системы новыми инженерами путем максимально возможного ее упрощения.\n\nУпрощение системы не обязательно означает сокращение ее функциональности. Оно может означать также исключение побочной сложности. Сложность можно понимать как побочную если она возникает вследствие конкретной реализации, а не является неотъемлемой частью решаемой задачи (с точки зрения пользователей).\nАбстракция - хороший и наверное главный инструмент сохранения простоты. Примером такой абстракции может являться SQL скрывающий сложность хранения и структур данных. Или язык программирования высокого уровня скрывающий сложности работы.\n\n\nВозможность развития. Упрощает разработчикам внесение в будущем изменений в систему, адаптацию ее для непредвиденных сценариев использования при смене требований. Известна под названиями «расширяемость» (extensibility), «модифицируемость» (modifiability) и «пластичность» (plasticity).\n\n2. Модели данных и языки запросов\n\nМодели данных вложены друг в друга как матрешка и описывают по сути разные уровни абстракций.\n\nНапример мы можем описать модель данных на уровне бизнес элементов и API, что представляют доступ как ним. На следующем уровне это будет уже модель сериализации, дальше модель хранения. Так можно абстрагироваться вплоть до физического хранения на уровне электронов.\n\n\n\nРеляционная модель в сравнении с документоориентированной моделью\n\n\n                  \n                  Объектно-реляционное несоответствие (impedance mismatch) \n                  \n                \n\nРасстыковка между реаляционной моделью и абстракциями языка. Необходимо реализовывать переходную логику между таблицами и сущностями языка. Например ORM.\n\n\n\nВ главе по верхам описывается сравнение реляционных и документориентированных БД. Основными отличием представляется возможности объединения и связи многие ко многим. В случае РСУБД этим задачи решает оптимизатор запросов, в случае документориентрованных БД код программы.\nИнтересная идея. NoSQL это не “schemaless” подход, а скорее “schema-on-read”. Ведь наш код все равно ждет какую-то схему даже если она не валидируется в момент записи.\n\nЯзыки запросов данных\n\nАвтор сравнивает императивные языки запросов к данным которые были распространенны в прошлом с декларативных.\n\nК декларативным можно отнести SQL или CSS-селекторы в браузере.\n\n\nMapReduce. Короткий обзор фреймворка на примере MongoDB.\n\nИнтересна мысль, что синтаксис aggregated pipeline в MongoDB по факту есть шаг в сторону декларативного похода от классического императивного MapReduce.\n\n\n\nГрафоподобные модели данных\n\nГрафы удобны своими возможностями расширения: по мере добавления в приложение новых свойств можно легко расширить граф с целью учесть изменения в структурах данных приложения.\n\n\nИнтересным для меня моментом является идея нахождения на одном графе разного рода сущностей.\n\nЛюди и города в которых они проживают.\nГород может быть связан линками со штатами, округами и странами и так далее.\nХороший пример: на этом же графе аллергия на тот или иной продукт человека.\n\n\nCypher - декларативный язык запросов графовых данных созданный для Neo4j.\nВ главе так же был обзор на следующие темы которые не показались мне интересными в настоящий момент. Полагаю они носят сугубо исторический характер:\n\nХранилище тройных кортежей и SPARQL.\n\nХранилище на базе подхода что данные это (субъект, предикат, модель). Где субъект это вершина графа, а объект может быть как атрибутом вершины, а может другой вершиной и тогда этот кортеж описывает ребро.\n\n\nМодель данных RDF. Концепция сохранения в вебе помимо человекочитаемых данных ещё и машиночитаемых, что позволяет построить глобальную БД. Технология толком не взлетела и смысла в ней вроде как нет.\nЯзык запросов Datalog. Фундамент для многих других языков но по факту мало используется. После первого прочтения ничего не понял в механизмах его работы.\n\n\n\n3. Подсистемы хранения и извлечения данных\nЕсли в прошлой главе разбиралось как положить данные в БД и каким запросом потом их оттуда извлечь то в этой автор планирует обсудить тоже самое с точки зрения БД.\nБазовые структуры данных БД\nКраткое введение в идею индексов упрощающих поиск необходимых строк а базе.\n\nХеш-индексы.\n\nПростейшая идея индекса. Отлично подходит для БД типа KV.\nПредставляет из себя hash-map где K это ключ из БД, а value это например смещение по файлу лога БД.\n\n\nSSTable.\n\nОтсортированный по ключам индекс.\nРабочий блок индекса находится в оперативной памяти, что делает процедуру вставки дешёвой.\nДаже если требуемый сегмент не в оперативной то за счет сортировки мы как минимум примерно знаем где он.\nПринцип работы.\n\nВсе пишем в сбалансированное дерево в памяти (например красно-черное дерево). Это MemTable.\nКак только MemTable превысит заданный порог записываем новый файл SSTable на диск.\n\n\n\n\nB-деревья.\n\nСемейство B-Tree индексов — это наиболее часто используемый тип индексов, организованных как сбалансированное дерево, упорядоченных ключей.\nWAL или redo лог частый вспомогательный инструмент для индексов типа b-tree.\n\n\n\nОбработка транзакций или аналитика?\nTransclude of OLTP-vs-OLAP\nData warehouse\n\nНа предприятии могут одновременно работать десятки разных OLTP БД.\n\nАдминистраторы этих систем не охотно представляют доступ к ним аналитикам так как их запросы могут быть весьма дорогими и поднимать большие выборки.\n\n\nDW хранилище представляет собой собранные и обработанные данные из всех этих OLTP БД.\n\nПроцесс загрузки этих данных - ETL.\n\n\nАлгоритмы индексации из предыдущего раздела хороши для OLTP но существенно хуже подходят для OLAP хранилищ.\nВ центре DW может находиться так называемая таблица фактов. Каждая строка это событие (продажа товара, посещение сайта) представляющее собой основную цель сбора DW.\n\nБольшинство столбцов в таких таблицах будут ключами на другие таблицы которые содержат можно назвать таблицами измерений.\nТаблица фактов - событие. Таблицы измерений ответ на вопросы по этому событию - “кто”, “что”, “где”, “когда” и так далее.\nДаже дата и время могут быть сущностью таблицы измерений.\nЭта схема называется “звезда”.\n\nЕсли же таблицы измерений в свою очередь ветвятся дальше то такую схему условно можно назвать “снежинка”.\n\n\n\n\n\nСтолбцовое хранилище\n\nВ Data Warehouse часто количество столбцов в таблицах может измеряться сотнями. При этом запросы вида SELECT * FROM… встречаются крайне редко. При этом могут запрашиваться огромное количество строк.\nИдея столбцовых хранилищ проста: нужно хранить рядом значения не из одной строки, а из одного столбца. Если каждый столбец хранится в отдельном файле, то запросу требуется только прочитать и выполнить синтаксический разбор необходимых запросов столбцов, что может сэкономить массу усилий. (с. 128)\nПомимо преимуществ для построения запросов описанных выше столбцовые хранилища, а точнее отдельные столбцы в них отлично подходят для сжатия.\n\nНапример с помощью битовой карты (bitmap encoding).\n\n\nTransclude of Olap-Cube\n\n4. Кодирование и эволюция\n\nОчевидно что с течением времени приложение будет меняться. В том числе будет меняться и представление данных в БД.\n\nРеляционные БД решают эту задачу через миграции.\nSchemaless БД по идее из коробки способы к эволюции.\n\n\nВажной задачей разработки сервиса является поддержка не только обратной но и прямой совместимость. То есть старое приложение должно уметь работать с новыми данными.\n\nФорматы кодирования данных\nJSON и XML\n\nДостаточно обычные мысли про плюсы и минусы. Автор похоже воспринимает подобные форматы как неизбежное зло или компромиcс.\n\nБинарные форматы\n\nИнтересная идея с бинарной упаковкой JSON в формат MessagePack.\n\nФормат используется автором просто для демонстрации идеи. Так как выигрыша практически нет. Это бинарное представление хранит даже полностью название полей и выигрыш минимальный. (с. 149)\n\n\nThrift и Protobuf не имеют существенных отличий в описании. Схема, теги полей и бинарное представление отличающееся лишь реализацией.\nApache Avro интересен тем, что позволяет не кодировать теги полей в спецификации.\n\nРежимы движения данных\nПоток данных через БД\n\nОчевидно самое простое решение. Но даже при таком подходе следует учесть возможность того, что часть кода читающая и пишущая код мог разойтись по версиям.\n\nТак же не стоит забывать про rolling update. Когда к одной БД может получать доступ как новый так и старый код.\n\n\n\nПоток данных через сервисы: REST и RPC\nREST, RESTful и SOAP\n\nREST - подход к проектированию API где за основу взят протокол HTTP с его глаголами, сроками жизни кэша и, например механизмами авторизации.\n\nRESTful эпитет применяемый к API если оно реализовано на базе REST.\n\n\nSOAP в отличии от REST хоть и базируется на HTTP но старается абстрагироваться от его возможностей.\n\nЛогика API описывается в XML и определяется с помощью основанного на XML языка, именуемого языком описания веб-сервисов (web services description language, WSDL).\n\nWSDL обычно позволяет генерировать код но без такой генерации использовать его крайне сложно.\n\n\n\n\n\nRPC\n\nОсновная идея модели RPC состоит в том, что выполнение запроса к удаленному сетевому сервису должно выглядеть так же, как и вызов функции или метода на обычном языке программирования, в пределах одного процесса (эта абстракция называется независимостью от расположения (location transparency)).\n\nПроблемы RPC:\n\nСама природа семьи накладывает массу ограничений на способ вызова.\n\nПадение сети.\nСкорость обработки.\nНевозможность в общем случае понять дошёл ли запрос.\n\n\nТак же к минусам можно отнести невозможность передать указатель на объект. Любая передача объекта обязательно будет сопровождаться его стерилизацией.\nПриведение типов между разными языками программирования может вызвать сложности.\n\nПоток данных передачи сообщений\n\nВ разделе о брокерах сообщений рассказывается история вопроса и основные термины.\n\nConsumer, producer, topic, queue и так далее.\n\n\nАкторная модель разработки предполагает обмен сообщениями, через асинхронную очередь даже в случае одного экземпляра сервиса. Сама сущность очереди может быть инкапсулирована в сервис.\n\nII. Распределенные данные\nСуществует несколько основных мотивов распределения данных по нескольким машинам:\n\nМасштабируемость. Если объем данных, нагрузка по чтению или записи перерастают возможности одной машины, то можно распределить эту нагрузку на несколько компьютеров.\nОтказоустойчивость/высокая доступность. Если приложение должно продолжать работать даже в случае сбоя одной из машин (или нескольких машин, или сети, или даже всего ЦОДа), то можно использовать избыточные компьютеры. При отказе одного из них выполнение задач делигируется другому.\nЗадержка. При наличии пользователей по всему миру необходимы серверы в разных точках земного шара, чтобы каждый пользователь обслуживался ЦОДом, географически расположенным максимально близко от него. При этом пользователям не нужно будет ждать, пока сетевые пакеты обойдут половину земного шара.\n\nЕсли цель масштабирования это всего лишь обеспечение большей производительности то можно рассмотреть следующие виды архитектуры:\n\nShared-memory architecture (архитектура с разделяемой памятью) - по сути классический сервер который можно до какого-то предела растить вертикально. Из очевидных минусов - привязка к одной географической точке.\nShared-disk architecture (архитектура с разделяемым диском) - группа сервера по высокоскоростной сети подключается к единому массиву дисков.\n\nАрхитектуры без разделения ресурсов. Напротив, архитектуры без разделения ресурсов (shared-nothing architectures), известные под названием горизонтального масштабирования (horizontal scaling, scaling out).\n\nРепликация (replication) - подход при котором копии одних и тех же данных хранятся на различных узлах с целью обеспечения избыточности.\nСекционирование (partitions) - подход разбиения большой БД на отдельные кусочки секции.\nОба похода часто используются совместно.\n\n5. Репликация\nДопущение по тексту этой главы в том, что набор данных с которым мы оперируем достаточно мал для того чтобы влезть на одну машину.\nСуществуют три основных подхда к репликации:\n\nSingle-leader\nMulti-leader\nLeaderless\n\n5.1 Ведущие и ведомые узлы\n\nУзлы делятся на ведущие и ведомые (master/slave). Запись разрешается только в мастер откуда через специальный лог изменения раскатываются на ведомые узлы.\nВажным фактором работы системы является синхронно или асинхронно выполняется репликация.\n\nРепликация может быть настроена в одном кластере не однородно. То есть например межу ведущим узлом и первым ведомым она синхронна, тогда как репликация на второй ведомый уже асинхронна.\nДелать все ведомые узлы синхронными не разумно.\nСуществует подход (semi-synchronous) при котором при возникновении проблем с единственной синхронной репликой синхронный режим переключается на другой узел.\n\nЭто гарантирует наличие как минимум двух машин с актуальным набором данных.\n\n\n\n\n"},"notes/Добавление-IP-и-DNS-в-сертификат-microk8s":{"title":"Добавление IP и DNS в сертификат microk8s","links":["notes/Добавление-IP-и-DNS-в-сертификат-microk8s"],"tags":["reference/kubernetes"],"content":"Добавление IP и DNS в сертификат microk8s\n\nDNS запись или IP необходимо внести в файл /var/snap/microk8s/current/certs/csr.conf.template. Секция alt_names\n\n[ alt_names ]\nDNS.1 = kubernetes\nDNS.2 = kubernetes.default\nDNS.3 = kubernetes.default.svc\nDNS.4 = kubernetes.default.svc.cluster\nDNS.5 = kubernetes.default.svc.cluster.local\nDNS.6 = mydomain.com\n\n\nПосле изменения перегенерить сертификат командой\n\nsudo microk8s refresh-certs --cert server.crt"},"notes/Добавление-нового-ядра-в-Jupyter-notebook":{"title":"Добавление нового ядра в Jupyter notebook","links":["notes/Добавление-нового-ядра-в-Jupyter-notebook"],"tags":["reference/python"],"content":"Добавление нового ядра в Jupyter notebook\n\nActivate the virtualenv\n\n$ source your-venv/bin/activate\n\nInstall jupyter in the virtualenv\n\n(your-venv)$ pip install jupyter\n\n\nAdd the virtualenv as a jupyter kernel\n\n(your-venv)$ ipython kernel install --name &quot;local-venv&quot; --user\n\n\nYou can now select the created kernel your-env when you start Jupyter\n"},"notes/Запуск-LogSeq-в-Ubuntu":{"title":"Запуск LogSeq в Ubuntu","links":["notes/Запуск-LogSeq-в-Ubuntu"],"tags":["reference/ubuntu"],"content":"Запуск LogSeq в Ubuntu\nПри запуске некоторых AppImage в Ubuntu (например, LogSeq) может возникнуть следующая ошибка:\n❯ ./Logseq-linux-x64-0.10.9_dcf8b41b9db5c9fe9f84938688e17f23.AppImage\nQSocketNotifier: Can only be used with threads started with QThread\nAppImageLauncher error: appimage_shall_not_be_integrated() failed (returned -1)\nAppImageLauncher error: appimage_is_terminal_app() failed (returned -1)\n[15329:1028/094210.939162:FATAL:setuid_sandbox_host.cc(158)] The SUID sandbox helper binary was found, but is not configured correctly. Rather than run without sandboxing I&#039;m aborting now. You need to make sure that /tmp/.mount_LogseqWQcXdE/chrome-sandbox is owned by root and has mode 4755.\n\nЭта ошибка связана с неправильной конфигурацией SUID sandbox helper binary. В идеале, проблема должна решаться разработчиками пакета, однако для временного исправления ситуации можно выполнить следующую команду:\nsudo sysctl -w kernel.apparmor_restrict_unprivileged_userns=0\nДля того чтобы не выполнять данную команду каждый раз после перезагрузки системы, можно добавить строку kernel.apparmor_restrict_unprivileged_userns=0 в файл /etc/sysctl.conf."},"notes/Запуск-minio-в-docker":{"title":"Запуск minio в docker","links":["notes/Запуск-minio-в-docker"],"tags":[],"content":"Запуск minio в docker\ndocker run \\\n   -p 9000:9000 \\\n   -p 9090:9090 \\\n   --name minio \\\n   -v /Users/maksim/trino/data/minio:/data \\\n   -e &quot;MINIO_ROOT_USER=ROOTNAME&quot; \\\n   -e &quot;MINIO_ROOT_PASSWORD=CHANGEME123&quot; \\\n   quay.io/minio/minio server /data --console-address &quot;:9090&quot;"},"notes/Инсталляция-Ansible-на-старых-серверах":{"title":"Инсталляция Ansible на старых серверах","links":["notes/Инсталляция-Ansible-на-старых-серверах","notes/Ansible-become-pass"],"tags":["reference/unix","reference/python"],"content":"Инсталляция Ansible на старых серверах\n\nОбновить pip до версии &lt;21: python3.6 -m pip install -U &quot;pip&lt;21&quot;\nУстановить ansible версии 2.5: python3.6 -m pip install ansible==2.5\n\n\n\n                  \n                  Внимание \n                  \n                \n\nНельзя обновлять pip командой upgrade. Он перестанет работать со старым python.\n\n\nFriend:: Ansible become pass"},"notes/Как-заблокировать-доступ-до-определенного-IP-в-Ubuntu":{"title":"Как заблокировать доступ до определенного IP в Ubuntu","links":["notes/Как-заблокировать-доступ-до-определенного-IP-в-Ubuntu"],"tags":["reference/ubuntu","reference/unix"],"content":"Как заблокировать доступ до определенного IP в Ubuntu\nВ целях тестирования работы кода может потребоваться имитировать сетевую недоступность какого-то IP.\nВот простейший способ это сделать:\nsudo route add -host 10.73.152.23 reject\nЧтобы отменить можно просто заменить add на del."},"notes/Как-посчитать-количество-планок-памяти-в-Linux":{"title":"Как посчитать количество планок памяти в Linux","links":["notes/Как-посчитать-количество-планок-памяти-в-Linux"],"tags":["reference/unix"],"content":"Как посчитать количество планок памяти в Linux\nsudo dmidecode -t memory | grep -i size\nДля этого можно использовать команду “sudo dmidecode -t memory | grep -i size”. Она выведет информацию о размере каждой установленной планки памяти, а также общее количество физических планок."},"notes/Компиляция-proto-файла-для-Golang":{"title":"Компиляция proto файла для Golang","links":["notes/Компиляция-proto-файла-для-Golang"],"tags":["reference/golang"],"content":"Компиляция proto файла для Golang\nsyntax = &quot;proto3&quot;;\npackage ecommerce;\n \nservice ProductInfo {\n    rpc addProduct(Product) returns (ProductID);\n    rpc getProduct(ProductID) returns(Product);\n};\n \nmessage Product {\n    string id = 1;\n    string name = 2;\n    string description = 3;\n};\n \nmessage ProductID {\n    string value = 1;\n};\nprotoc --go-grpc_out=. --go-grpc_opt=Mecommerce/product_info.proto=./ecommerce --go_out=. --go_opt=Mecommerce/product_info.proto=./ecommerce  ecommerce/product_info.proto\nАльтернативой указания значений Mecommerce/product_info.proto=./ecommerce может стать определение значений go_package в proto:\noption go_package = &quot;./;investapi&quot;;\n"},"notes/Компиляция-swagger-для-Golang":{"title":"Компиляция swagger для Golang","links":["notes/Компиляция-swagger-для-Golang"],"tags":["reference/golang"],"content":"Компиляция swagger для Golang\nswagger-codegen generate --input-spec developers.strava.com/swagger/swagger.json --lang go --output api"},"notes/Логическая-репликация-PostgreSQL":{"title":"Логическая репликация PostgreSQL","links":["notes/Логическая-репликация-PostgreSQL"],"tags":[],"content":"Логическая репликация PostgreSQL\nЛогическая репликация в отличии от физической копирует не сами данные, а sql выражения эти данные изменяющие.\n\nНа мастере в postgresql.conf указать wal_level=&quot;logical&quot; после чего перезапустить сервер.\nНа реплике выполнить следующие команды:\n\npg_dumpall --database=postgres --host=db.mak-sim.ru --no-password --globals-only --no-privileges | psql\n \npg_dump --dbname db_name --host=db.mak-sim.ru --no-password --create --schema-only | psql\nПервая перенесет пользователей и прочие глобальные объекты. Вторая схему данных.\n\nПодключившись на мастере к нужной бд создадим публикацию:\n\nCREATE PUBLICATION db_pub FOR ALL TABLES;\n\nНа реплике создадим подписку\n\nCREATE SUBSCRIPTION health_sub CONNECTION &#039;host=db.mak-sim.ru dbname=health user=postgres password=**** sslmode=require&#039; PUBLICATION db_pub;\nПричём health_sub это имя слота на источнике репликации, а значит должно быть уникальным!\nРепликация новых таблиц\nЕсли после создания подписки на источнике появились новые таблицы то сначала необходимо создать на приемнике ту же таблицу (DDL), а затем выполнить команду:\nALTER SUBSCRIPTION sub_name REFRESH PUBLICATION;\nкоманду следует выполнить от лица пользователя владельца подписки. Узнать его можно так:\nselect\n\trolname\nfrom \n\tpg_authid\nwhere\n\toid =\n\t\t(select\n\t\t\tpubowner\n\t\tfrom\n\t\t\tpg_publication\n\t\twhere\n\t\t\tpubname=&#039;main&#039;);"},"notes/Настройка-OpenSearch-для-локальной-разработки":{"title":"Настройка OpenSearch для локальной разработки","links":["notes/Настройка-OpenSearch-для-локальной-разработки"],"tags":["reference/unix","reference/macos"],"content":"Настройка OpenSearch для локальной разработки\n❯ curl -XPUT -H &quot;Content-Type: application/json&quot; http://localhost:9200/_cluster/settings -d &#039;{ &quot;transient&quot;: { &quot;cluster.routing.allocation.disk.threshold_enabled&quot;: false } }&#039;\n \n{&quot;acknowledged&quot;:true,&quot;persistent&quot;:{},&quot;transient&quot;:{&quot;cluster&quot;:{&quot;routing&quot;:{&quot;allocation&quot;:{&quot;disk&quot;:{&quot;threshold_enabled&quot;:&quot;false&quot;}}}}}}\n \n❯ curl -XPUT -H &quot;Content-Type: application/json&quot; http://localhost:9200/_all/_settings -d &#039;{&quot;index.blocks.read_only_allow_delete&quot;: null}&#039;\n \n{&quot;acknowledged&quot;:true}\nsudo /usr/local/opt/logstash/bin/logstash\n/usr/local/opt/filebeat/bin/filebeat run -e\n\nkeywords: elasticsearch, opensearch, kibana, logstash, filebeat"},"notes/Настройка-WebDAV-на-nginx":{"title":"Настройка WebDAV на nginx","links":["notes/Настройка-WebDAV-на-nginx","notes/Создание-htpasswd-файла"],"tags":["reference/unix"],"content":"Настройка WebDAV на nginx\nОказывается WebDAV это не какой-то сервер, а просто расширение спецификации HTTP позволяющее манипулировать файлами на сервере. Соответственно его серверной частью является фактически любой http-сервер.\nNginx\nВот пример конфигурационного файла для nginx:\nserver {\n    server_name webdav.mak-sim.ru;\n    listen 443 ssl;\n    index index.html;\n \ncreate_full_put_path  on;\n    access_log /var/log/nginx/webdav.log;\n    error_log /var/log/nginx/webdav_error.log;\n \n    location / {\n#        try_files $uri $uri/ =404;\n        root /opt/webdav;\n        dav_methods PUT DELETE MKCOL COPY MOVE;\n        dav_ext_methods PROPFIND OPTIONS;\n        client_max_body_size 100m;\n        create_full_put_path on;\n        auth_basic &quot;Restricted&quot;;\n        auth_basic_user_file /etc/nginx/.webdav_htpasswd;\n}\n    ssl_certificate /etc/letsencrypt/live/ssch.ru/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/ssch.ru/privkey.pem; # managed by Certbot\n}\nВ Ubuntu необходимо так же установить пакет libnginx-mod-http-dav-ext.\nChild:: Создание htpasswd файла"},"notes/Настройка-WireGuard":{"title":"Настройка WireGuard","links":["notes/Настройка-WireGuard"],"tags":["reference/ubuntu","reference/unix"],"content":"Настройка WireGuard\nУстановка сервера\n\nУстановить wg-easy. Это упакованный в Docker wireguard + web интерфейс к нему\n\ndocker run -d \\\n  --name=wg-easy \\\n  -e LANG=en \\\n  -e WG_HOST=192.168.1.1 \\\n  -e PASSWORD=password \\\n  -v ~/.wg-easy:/etc/wireguard \\\n  -p 51820:51820/udp \\\n  -p 51821:51821/tcp \\\n  --cap-add=NET_ADMIN \\\n  --cap-add=SYS_MODULE \\\n  --sysctl=&quot;net.ipv4.conf.all.src_valid_mark=1&quot; \\\n  --sysctl=&quot;net.ipv4.ip_forward=1&quot; \\\n  --restart unless-stopped \\\n  ghcr.io/wg-easy/wg-easy\n \nНеобходимо заменить переменные WG_HOST и PASSWORD.\n2. По адресу http://192.168.1.1:51821 будет доступна простая панель управления где можно добавлять новых пользователей.\nНастройка клиентов\nAndroid\nПросто скачать приложение и отсканировать QR-код из web-интерфейса.\nUbuntu\n\nСкачать конфигурационный файл из веб интерфейса\nУстановить wireguard\n\nsudo apt install wireguard\n\n\nПочинить симлинк которого ждёт wireguard `ln -s /usr/bin/resolvectl /usr/local/bin/resolvconf\nС помощью утилиты wg-quick поднять интерфейс командой wg-quick up ./wg0.conf\n\nИмя интерфейса будет равно имени файла.\nФайл должен находиться по абсолютному или относительному пути. Если это не путь, а просто строка то тогда соответствующий конфиг будет искаться в папке /etc/wireguard.\n\nУдобнее сразу его туда скопировать.\n\n\n\n\n"},"notes/Настройка-ssl-microk8s":{"title":"Настройка ssl microk8s","links":["notes/Настройка-ssl-microk8s","notes/ingres"],"tags":[],"content":"Настройка ssl microk8s\n\nmicrok8s enable cert-manager\nНеобходимо создать ClusterIssuer\n\n---\napiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n name: lets-encrypt\nspec:\n acme:\n   email: microk8s@example.com\n   server: acme-v02.api.letsencrypt.org/directory\n   privateKeySecretRef:\n     # Secret resource that will be used to store the account&#039;s private key.\n     name: lets-encrypt-priviate-key\n   # Add a single challenge solver, HTTP01 using nginx\n   solvers:\n   - http01:\n       ingress:\n         class: public\nДалее в описании ingres необходимо обязательно:\nmetadata:\n name: microbot-ingress\n annotations:\n   cert-manager.io/cluster-issuer: lets-encrypt\nspec:\n tls:\n - hosts:\n   - my-service.example.com\n   secretName: microbot-ingress-tls\n"},"notes/Общая-информация-по-Greenplum":{"title":"Общая информация по Greenplum","links":["notes/Общая-информация-по-Greenplum","notes/MPP"],"tags":[],"content":"Общая информация по Greenplum\n\nGreenplum обладает признаками и функциональностью реляционной СУБД.\nУ Greenplum массивно-параллельная архитектура.\n\nВысокие накладные расходы на запуск запроса. Так как Greenplum работает на кластере, любой запрос порождает сетевые соединения между хостами и процессы на каждом из хостов. Запрос завершается, только когда все хосты успешно отработали свою часть запроса.\nОперации обновления и удаления данных в Greenplum возможны, но приводят к дополнительному расходу места и необходимости периодической очистки.\nОграничения на конкурентность нагрузки — количество одновременно выполняемых запросов. Все операции выполняются симметрично на всех хостах кластера. Это ограничение не жёсткое и продиктовано возможностями аппаратного обеспечения и операционной системы. Greenplum распараллеливает нагрузку и в полной мере утилизирует ресурсы на всех хостах кластера, благодаря чему запросы выполняются быстро. На практике производительность начинает существенно падать при конкурентности в несколько десятков запросов.\n\n\nGreenplum способна хранить и быстро обрабатывать большие объёмы данных.\nGreenplum поддерживает различные форматы физического хранения данных в таблицах:\n\nпострочно или поколоночно, со сжатием или без сжатия.\n\n\nВ основе Greenplum лежит СУБД PostgreSQL.\n\n\n\n                  \n                  Warn\n                  \n                \n\nУчитывая эти особенности MPP, Greenplum не нужно выбирать для систем с преимущественной OLTP-нагрузкой — систем, где нагрузка характеризуется большим количеством «быстрых» запросов, возвращающих небольшое количество строк, а также точечным обновлением данных.\n\n"},"notes/Основы-Vim":{"title":"Основы Vim","links":["notes/Основы-Vim"],"tags":[],"content":"Основы Vim\nИзучение базовых команд и концепций для эффективного использования текстового редактора Vim. Напиши заметку на эту тем\nVim: основы работы с текстовым редактором\nVim — это мощный текстовый редактор, который может быть полезен для программистов, системных администраторов и других специалистов, работающих с текстом. В этой заметке мы рассмотрим основные команды и концепции, которые помогут вам эффективно использовать Vim.\n\n\nОсновы навигации:\n\nh, j, k, l — перемещение по тексту влево, вниз, вверх и вправо соответственно.\nw — переход к следующему слову.\nb — возврат к предыдущему слову.\n0 (ноль) — переход в начало строки.\n$ — переход в конец строки.\ngg — переход в начало файла.\nG — переход в конец файла.\n\n\n\nРедактирование текста:\n\ni — переключение в режим вставки.\na — добавление текста после курсора.\nc — изменение текста под курсором.\nd — удаление текста.\nx — удаление символа под курсором.\nu — отмена последнего изменения.\np — вставка удалённого текста.\n\n\n\nПоиск и замена:\n\n/pattern — поиск текста, соответствующего шаблону pattern.\n:s/pattern/replacement/ — замена всех вхождений pattern на replacement.\nn — повторение предыдущей команды поиска и замены.\n\n\n\nРабота с буферами:\n\n:e filename — открытие нового файла.\n:split — разделение окна редактора на две части.\n:vsplit — разделение окна редактора по вертикали.\n:q — выход из Vim без сохранения изменений.\n:wq — сохранение изменений и выход из Vim.\n:w! — принудительное сохранение изменений в файл.\n\n\n\nМакросы:\n\nq key — запись макроса.\n@ key — выполнение записанного макроса.\n\n\n\nЭто лишь некоторые из основных команд и концепций Vim. Для более глубокого изучения этого мощного инструмента рекомендуется обратиться к официальной документации или онлайн-курсам.у"},"notes/Переключение-между-различными-Java.-Linux":{"title":"Переключение между различными Java. Linux","links":["notes/Переключение-между-различными-Java.-Linux"],"tags":["reference/ubuntu"],"content":"Переключение между различными Java. Linux\nTo switch between installed java versions, use the update-java-alternatives command.\nList all java versions:\nupdate-java-alternatives --list\nSet java version as default (needs root permissions):\nsudo update-java-alternatives --set /path/to/java/version\n…where /path/to/java/version is one of those listed by the previous command (e.g. /usr/lib/jvm/java-7-openjdk-amd64).\n\n\n                  \n                  Additional information \n                  \n                \n\nupdate-java-alternatives is a convenience tool that uses Debian’s alternatives system (update-alternatives) to set a bunch of links to the specified java version (e.g. java, javac, …).\n\n"},"notes/Перемещение-по-тексту-Vim":{"title":"Перемещение по тексту Vim","links":["notes/Перемещение-по-тексту-Vim"],"tags":[],"content":"Перемещение по тексту Vim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nКлавишаДействиеhВлево на один символjВниз на одну строкуkВверх на одну строкуlВправо на один символwВперёд на одно словоWВперёд на один блок текста (игнорируя знаки)bНазад на одно словоBНазад на один блок текстаeК концу словаEК концу блока текста0В начало строки^К первому непустому символу в строке$В конец строкиggВ начало файлаGВ конец файлаHК первому видимому символу в верхней части экранаMК первому видимому символу в середине экранаLК первому видимому символу в нижней части экранаCtrl + uПрокрутка вверх на пол-страницыCtrl + dПрокрутка вниз на пол-страницыCtrl + bПрокрутка вверх на страницуCtrl + fПрокрутка вниз на страницуCtrl + oПереход к предыдущему местоположениюCtrl + iПереход к следующему местоположению"},"notes/Подключение-к-GRPC-server'у":{"title":"Подключение к GRPC server'у","links":["notes/Подключение-к-GRPC-server'у"],"tags":["reference/golang"],"content":"Подключение к GRPC server’у\nSimple server\nСоздание сервера\ntype server struct {\n\tproductMap map[string]*pb.Product\n\tecommerce.UnimplementedProductInfoServer\n}\n \nconst (\n\tport = &quot;:50051&quot;\n)\n \nfunc main() {\n\tlis, err := net.Listen(&quot;tcp&quot;, port)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\ts := grpc.NewServer()\n\tecommerce.RegisterProductInfoServer(s, &amp;server{})\n\tlog.Printf(&quot;Starting gRPC listener on port %s&quot;, port)\n\tif err := s.Serve(lis); err != nil {\n\t\tlog.Fatalf(&quot;failed serve: %v&quot;, err)\n\t}\n}\nСоздание клиента\npackage main\n \nimport (\n\t&quot;context&quot;\n\t&quot;log&quot;\n\t&quot;time&quot;\n \n\t&quot;client/ecommerce&quot;\n \n\t&quot;google.golang.org/grpc&quot;\n\t&quot;google.golang.org/grpc/credentials/insecure&quot;\n)\n \nconst (\n\taddress = &quot;localhost:50051&quot;\n)\n \nfunc main() {\n\tconn, err := grpc.Dial(address, grpc.WithTransportCredentials(insecure.NewCredentials()))\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer conn.Close()\n \n\tc := ecommerce.NewProductInfoClient(conn)\n\tname := &quot;Apple iPhone 11&quot;\n\tdescription := &quot;Some phone&quot;\n \n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tr, err := c.AddProduct(ctx, &amp;ecommerce.Product{Name: name, Description: description})\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tlog.Printf(&quot;Product ID: %s added successfully&quot;, r.Value)\n \n\tproduct, err := c.GetProduct(ctx, &amp;ecommerce.ProductID{Value: r.Value})\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tlog.Printf(&quot;Product: %s&quot;, product.String())\n}\nTinkoff OpenAPI\nconn, err := grpc.Dial(&quot;invest-public-api.tinkoff.ru:443&quot;,\n\tgrpc.WithTransportCredentials(credentials.NewTLS(&amp;tls.Config{})),\n\tgrpc.WithPerRPCCredentials(oauth.TokenSource{\n\t\tTokenSource: oauth2.StaticTokenSource(&amp;oauth2.Token{\n\t\t\tAccessToken: &quot;token&quot;,\n\t\t\t}),\n\t\t}))\n\tif err != nil {\n\t\tlog.Fatalf(&quot;did not connect: %v&quot;, err)\n\t}\n\tdefer conn.Close()\nПосле чего объект conn можно передавать в функции создание новых сервисов."},"notes/Поиск-процесса-слушающего-порт":{"title":"Поиск процесса слушающего порт","links":["notes/Поиск-процесса-слушающего-порт"],"tags":["reference/unix","reference/macos"],"content":"Поиск процесса слушающего порт\nДля того чтобы найти какой процесс в Unix или MacOS слушает некий порт необходимо выполнить:\nlsof -nP -iTCP -sTCP:LISTEN | grep 3000\nили\nnetstat -tulpn | grep 3000\nГде 3000 это искомый порт."},"notes/Получение-API-ключа-в-YC":{"title":"Получение API ключа в YC","links":["notes/Получение-API-ключа-в-YC","notes/Получение-списка-Service-Account-в-YC"],"tags":[],"content":"Получение API ключа в YC\nЭто инструкция по созданию API-ключа для сервисного аккаунта. API-ключ — секретный ключ, используемый для упрощенной авторизации в API Yandex Cloud.\nЕсли у вас еще нет сервисного аккаунта, создайте его и назначьте ему роли.\nЧтобы создать API-ключ:\n\nСоздайте API-ключ с помощью метода REST API create для ресурса ApiKey:\n\nexport SERVICEACCOUNT_ID=&lt;идентификатор_сервисного_аккаунта&gt;\nexport IAM_TOKEN=&lt;токен&gt;\ncurl -X POST \\\n  -H &quot;Content-Type: application/json&quot; \\\n  -H &quot;Authorization: Bearer $IAM_TOKEN&quot; \\\n  -d &quot;{\n      \\&quot;serviceAccountId\\&quot;: \\&quot;$SERVICEACCOUNT_ID\\&quot;,\n      \\&quot;scope\\&quot;: \\&quot;&lt;область_действия&gt;\\&quot;,\n      \\&quot;expiresAt\\&quot;: \\&quot;&lt;дата_и_время&gt;\\&quot;\n  }&quot; \\\n  iam.api.cloud.yandex.net/iam/v1/apiKeys\nГде:\n\nSERVICEACCOUNT_ID — идентификатор сервисного аккаунта. Обязательный параметр.\nIAM_TOKEN — IAM-токен. Обязательный параметр.\nscope — область действия для ключа с ограниченным доступом. Необязательный параметр.\nexpiresAt — дата и время истечения срока действия ключа с ограниченным доступом. Необязательный параметр.\n"},"notes/Получение-IAM_TOKEN-в-YC":{"title":"Получение IAM_TOKEN в YC","links":["notes/Получение-IAM_TOKEN-в-YC"],"tags":[],"content":"Получение IAM_TOKEN в YC\n\nВойдите- в ваш аккаунт на Яндексе.\nПолучите OAuth-токен в сервисе Яндекс.OAuth. Для этого перейдите по ссылке, нажмите Разрешить и скопируйте полученный OAuth-токен.\nОбменяйте OAuth-токен на IAM-токен:\n\ncurl -X POST \\\n  -d &#039;{&quot;yandexPassportOauthToken&quot;:&quot;&lt;OAuth-токен&gt;&quot;}&#039; \\\n  iam.api.cloud.yandex.net/iam/v1/tokens"},"notes/Получение-ID-каталога-в-Yandex-Cloud":{"title":"Получение ID каталога в Yandex Cloud","links":["notes/Получение-ID-каталога-в-Yandex-Cloud","notes/Получение-ID-облака-в-Yandex-Cloud"],"tags":[],"content":"Получение ID каталога в Yandex Cloud\nДля использования многих методов API YC требуется знать идентификатор каталога в облаке.\nПолучение id облака\nИдентификатор самого облака в свою очередь можно получить вот так:\nTransclude of Получение-ID-облака-в-Yandex-Cloud\nПолучение id каталога(в)\nhttp GET resource-manager.api.cloud.yandex.net/resource-manager/v1/folders Authorization:&quot;Bearer $IAM_TOKEN&quot; cloud_id=b1gp230h62h8oavhctri\nОтвет:\n{\n    &quot;folders&quot;: [\n        {\n            &quot;cloudId&quot;: &quot;b1gp230h62h8oavhctri&quot;,\n            &quot;createdAt&quot;: &quot;2020-09-19T07:20:09Z&quot;,\n            &quot;id&quot;: &quot;b1gjpq05r3ppsou34c7d&quot;,\n            &quot;name&quot;: &quot;default&quot;,\n            &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n    ]\n}"},"notes/Получение-ID-облака-в-Yandex-Cloud":{"title":"Получение ID облака в Yandex Cloud","links":["notes/Получение-ID-облака-в-Yandex-Cloud","notes/Получение-IAM_TOKEN-в-YC"],"tags":[],"content":"Получение ID облака в Yandex Cloud\nДля того чтобы узнать id облаков доступных в YC необходимо выполнить следующий запрос (необходим I AM токен):\nhttp GET resource-manager.api.cloud.yandex.net/resource-manager/v1/clouds  Authorization:&quot;Bearer $IAM_TOKEN&quot;\nОтвет:\n{\n    &quot;clouds&quot;: [\n        {\n            &quot;createdAt&quot;: &quot;2020-09-19T07:20:09Z&quot;,\n            &quot;id&quot;: &quot;b1gp230h62h8oavhctri&quot;,\n            &quot;name&quot;: &quot;maksim77&quot;,\n            &quot;organizationId&quot;: &quot;bpfulqitoarhlo1a29ln&quot;\n        }\n    ]\n}"},"notes/Получение-списка-Service-Account-в-YC":{"title":"Получение списка Service Account в YC","links":["notes/Получение-списка-Service-Account-в-YC","notes/Получение-IAM_TOKEN-в-YC"],"tags":[],"content":"Получение списка Service Account в YC\nНеобходимо получить IAM_TOKEN и знать идентификатор каталога (FOLDER_ID).\nexport FOLDER_ID=b1gvmob95yys********\nexport IAM_TOKEN=CggaATEVAgA...\ncurl -H &quot;Authorization: Bearer ${IAM_TOKEN}&quot; \\\n  &quot;iam.api.cloud.yandex.net/iam/v1/serviceAccounts${FOLDER_ID}&quot;\n \n{\n &quot;serviceAccounts&quot;: [\n  {\n   &quot;id&quot;: &quot;ajebqtreob2d********&quot;,\n   &quot;folderId&quot;: &quot;b1gvmob95yys********&quot;,\n   &quot;createdAt&quot;: &quot;2018-10-18T13:42:40Z&quot;,\n   &quot;name&quot;: &quot;my-robot&quot;,\n   &quot;description&quot;: &quot;my description&quot;\n  }\n ]\n}"},"notes/Работа-с-JQ":{"title":"Работа с JQ","links":["notes/Работа-с-JQ"],"tags":[],"content":"Работа с JQ\nПросмотр всех ключей документа\ncat file.json | jq &#039;keys&#039;\nСоставной запрос\ncat rules.json | jq -c &#039;[[.[][].user | select( . != null ) | split(&quot;|&quot;)] | flatten[] | sub(&quot;\\\\(&quot;;&quot;&quot;) | sub(&quot;\\\\)&quot;;&quot;&quot;)] | map(.+&quot;@mts.ru&quot;)[]&#039;\nВ этом запросе:\n\nselect(. != null) используется для фильтрации полей которые удовлетворяют условию.\nsplit(&quot;|&quot;) каждую строку полученного списка (каждый входящий элемент) разбивает по символу ”|“.\nflatten[] схлопывает вложенные списки на один уровень и предоставляет их в виде нового списка. Здесь flatten это функция, а [] формирует список.\nsub(&quot;\\\\(&quot;;&quot;&quot;) | sub(&quot;\\\\)&quot;;&quot;&quot;) убирает из каждой строки символы открывающейся и закрывающейся скобки.\nmap(.+&quot;@mts.ru&quot;) добавляет для каждой строки окончание @mts.ru.\n\nТак же тут немного магии вокруг где список, а где просто входной поток документов и конвертации между ними."},"notes/Работа-с-oauth2-в-golang":{"title":"Работа с oauth2 в golang","links":["notes/Работа-с-oauth2-в-golang"],"tags":["reference/golang"],"content":"Работа с oauth2 в golang\nЗа работу с методом авторизации oauth2 в golang отвечает пакет golang.org/x/oauth2.\nСоздание объекта Config\nПрежде всего нам необходимо создать объект конфигурации Oauth:\n&amp;oauth2.Config{\n\t\t\tClientID:     &quot;46197&quot;,\n\t\t\tClientSecret: &quot;4759912abdd765ac1bba5f7d8ded0c112b3ee1ec&quot;,\n\t\t\tRedirectURL:  &quot;http://localhost:8000/callback&quot;,\n\t\t\tEndpoint:     endpoints.Strava,\n\t\t\tScopes: []string{\n\t\t\t\t&quot;activity:read_all&quot;,\n\t\t\t},\n\t\t}\nВ пакете golang.org/x/oauth2/endpoints можно найти эндопойнты для популярных сервисов.\nПолучение URL для авторизации\nУ этого объекта можно запросить сформированный URL по которому пользователь должен пройти чтобы выдать права на API:\noauthConf.AuthCodeURL(&quot;state&quot;)\nОбработка callback’а\nВ handler’е который будет обрабатывать http://localhost:8000/callback необходимо обменять код авторизации на токен:\nfunc CallbackHandler(c *oauth2.Config) http.HandlerFunc {\n\treturn func(rw http.ResponseWriter, r *http.Request) {\n\t\ttoken, _ := c.Exchange(r.Context(), r.URL.Query().Get(&quot;code&quot;))\n\t\tfmt.Println(token.AccessToken)\n\t\tfmt.Println(token.RefreshToken)\nПолучение HTTP клиента\nПолученный токен можно передать в метод Client исходного объекта\nHTTPClient = c.Client(r.Context(), token)\nтак как объект токен содержит в себе и refresh token то его обновление пройдет автоматически.\nЭтот клиент будет автоматически подставлять нужные headers в заголовки запросов.\nПолучение HTTP клиента из сохраненного токена\nvar t oauth2.Token\njson.Unmarshal(store[&quot;s&quot;], &amp;t)\n \nclient := oauth2.NewClient(context.Background(), oauth2.StaticTokenSource(&amp;t))"},"notes/Работа-с-restic":{"title":"Работа с restic","links":["notes/Работа-с-restic"],"tags":[],"content":"Работа с restic\nПеременные\n\nAWS_ACCESS_KEY_ID\nAWS_SECRET_ACCESS_KEY\nRESTIC_PASSWORD\nRESTIC_REPOSITORY\n\nИнициализация репозитория\nrestic init\nПросмотр снэпшотов\nrestic snapshot покажет существующие в репозитории снэпшоты. Их можно фильтровать с помощью ключей --tag и/или --host.\nУдаление снэпшотов\nСнэпошоты удаляются с помощью команды forget. Без ключа --prune данные реально останутся в репозитории.\nНеобходимо указывать либо ID конкретных снэпшотов либо policy для удаления.\nrestic forget --tag oci --keep-last 1\nrestic prune\nrestic snapshots --tag oci --json | jq &quot;.[0].id&quot;\n&quot;3c30e03cbd77b734a674cd9f3d7077c6b6d3d1ed93c26914e3269bac2b14e5bf&quot;\nrestic forget --prune 3c30e03cbd77b734a674cd9f3d7077c6b6d3d1ed93c26914e3269bac2b14e5bf\nВосстановление из бэкапа\nrestic restore 834f9282 --target tmp/restic\nГде 834f9282 это идентификатор снэпшота."},"notes/Работа-с-teleport":{"title":"Работа с teleport","links":["notes/Работа-с-teleport","notes/Teleport-CLI","notes/Teleport.-Golang"],"tags":[],"content":"Работа с teleport\n&gt; Платформа доступа Teleport — это набор программного обеспечения и управляемых услуг, который предоставляет доступ к инфраструктуре по запросу с минимальными привилегиями на основе криптографической идентичности и модели Zero Trust, с встроенной безопасностью идентификации и управлением политиками.\n\nChildren:: Teleport CLI\nChildren:: Teleport. Golang\n\nSource:: goteleport.com/"},"notes/Работа-с-регистрами-Vim":{"title":"Работа с регистрами Vim","links":["notes/Работа-с-регистрами-Vim"],"tags":[],"content":"Работа с регистрами Vim\nРегистры в Vim — это ячейки памяти, куда можно сохранять текст или команды для последующего использования, аналогично буферу обмена.\nОсновные типы регистров:\n\nРегистр по умолчанию (&quot;): автоматически используется для копирования и вставки текста, если не указан другой регистр.\nНумерованные регистры (0-9): хранят историю удалений текста, начиная с самого последнего.\nИменованные регистры (a-z): регистры, которые пользователь может выбрать для сохранения текста.\nРегистры поиска (/, ?): сохраняют последние строки поиска.\nРегистры команд (:): хранят последние введенные команды.\nЧерновой регистр (_): “чёрная дыра”, в него можно удалять текст, который не нужно сохранять.\nСистемный буфер обмена (+ и *): позволяют взаимодействовать с системным буфером обмена для копирования и вставки между Vim и другими приложениями.\n\nПримеры использования именованных регистров в Vim\n\n\nКопирование в именованный регистр\nЧтобы скопировать текст в регистр, нужно перед командой указать его имя:\n\nКопируем строку в регистр a:\n&quot;ayy\n\nЭто скопирует текущую строку в регистр a.\n\n\n\nВставка из именованного регистра\nЧтобы вставить текст из регистра a, нужно использовать команду вставки с указанием регистра:\n\nВставляем содержимое регистра a:\n&quot;ap\n\nЭто вставит текст из регистра a после курсора.\n\n\n\nУдаление с сохранением в регистр\nМожно удалить текст и сохранить его в регистр:\n\nУдаляем строку и сохраняем в регистр b:\n&quot;bdd\n\nЭто удалит текущую строку и сохранит её в регистр b.\n\n\n\nЗамена содержимого регистра\nЕсли нужно заменить содержимое регистра, просто повторно используем тот же регистр:\n\nКопируем другую строку в регистр a, заменяя его содержимое:\n&quot;ayy\n\nТеперь в регистре a сохранится новая строка.\n\n\n\nПримеры использования нумерованных регистров в Vim\n\n\nУдаление и восстановление текста\nVim автоматически сохраняет удаленный текст в нумерованный регистр &quot;:\n\nУдаляем строку с помощью dd, затем вставляем её снова:\ndd\n&quot;0p\n\nЭто удалит текущую строку и вставит её после курсора.\n\n\n\nИспользование последнего удаления\nЧтобы использовать текст из последнего удаления (до 9 операций назад), используйте &quot;&lt;номер регистра&gt;p:\n\nВставляем текст из предпоследнего удаления:\n&quot;2p\n\nЭто вставит текст, который был удалён две операции назад.\n\n\n\nУправление историей удалений\nVim хранит до 9 последних удалений в нумерованных регистрах 1-9:\n\nВставляем текст из пятого последнего удаления:\n&quot;5p\n\nЭто вставит текст из пятого удаления назад.\n\n\n\nИспользование содержимого нумерованных регистров в макросах\nНумерованные регистры полезны при создании макросов для повторения операций:\n\nСоздаем макрос, который удаляет строку и вставляет её снова:\nqq\ndd\n&quot;qp\n\nЗдесь макрос q начинает запись, dd удаляет строку, а &quot;qp вставляет её снова.\n\n\n"},"notes/Роль-модели-в-AI":{"title":"Роль модели в AI","links":["notes/Роль-модели-в-AI"],"tags":[],"content":"Роль модели в AI\nПри использовании API для общения с языковыми моделями можно задавать роль модели. Это позволяет адаптировать её поведение под конкретные задачи или сценарии. Роль системы (system role) задаёт инструкции, которые влияют на последующее взаимодействие.\nОсновные роли\n\nsystem — определяет поведение модели и задаёт её стиль.\nuser — сообщение от пользователя с запросом или задачей.\nassistant — ответы от модели на запросы.\n\nПример использования API с указанием роли системы\n{\n  &quot;model&quot;: &quot;advanced-llm&quot;,\n  &quot;messages&quot;: [\n    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant that specializes in product management and databases.&quot;},\n    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What are the key benefits of using the latest database version for large-scale applications?&quot;}\n  ]\n}"},"notes/Смена-имен-папок-в-home-dir-на-английский":{"title":"Смена имен папок в home dir на английский","links":["notes/Смена-имен-папок-в-home-dir-на-английский"],"tags":[],"content":"Смена имен папок в home dir на английский\nИзменение имен папок в Linux на обычные английские названия типа Downloads и Documents:\nLANG=C xdg-user-dirs-update --force"},"notes/Создание-ServiceAccount-и-токена-к-нему":{"title":"Создание ServiceAccount и токена к нему","links":["notes/Создание-ServiceAccount-и-токена-к-нему"],"tags":[],"content":"Создание ServiceAccount и токена к нему\nkind: ServiceAccount\napiVersion: v1\nmetadata:\n  name: broker-prod\n  namespace: prod\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: broker-prod-admin\n  namespace: prod\nsubjects:\n- kind: ServiceAccount\n  name: broker-prod\nroleRef:\n  kind: ClusterRole\n  name: some-role\n  apiGroup: rbac.authorization.k8s.io\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: broker-prod-sa-token\n  namespace: prod\n  annotations:\n    kubernetes.io/service-account.name: broker-prod\ntype: kubernetes.io/service-account-token\nПосле применения этого манифеста в namespace prod будет создан секрет содержащий токен нового SA.\nПолучить проще всего вот так:\nk get secrets --namespace prod broker-prod-sa-token -o json | jq -r .data.token | base64 -d"},"notes/Создание-htpasswd-файла":{"title":"Создание htpasswd файла","links":["notes/Создание-htpasswd-файла"],"tags":[],"content":"Создание htpasswd файла\n\napt-get install apache2-utils\nhtpasswd -c /etc/nginx/.webdav_htpasswd maksim77\n\nOnline генерация\nhostingcanada.org/htpasswd-generator/"},"notes/Создание-перехватчика-GRPC":{"title":"Создание перехватчика GRPC","links":["notes/Создание-перехватчика-GRPC","notes/OTEL/OpenTelemetry"],"tags":["reference/golang"],"content":"Создание перехватчика GRPC\nМожет быть полезно для OpenTelemetry.\nServer Unary Intercepter\nfunc MyInter(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface{}, error) {\n\tfmt.Println(ctx)\n\tfmt.Println(info.FullMethod)\n\treturn handler(ctx, req)\n}\n \nfunc main() {\n\tlis, err := net.Listen(&quot;tcp&quot;, port)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\ts := grpc.NewServer(grpc.UnaryInterceptor(MyInter))\n\tecommerce.RegisterProductInfoServer(s, &amp;server{})\n\tlog.Printf(&quot;Starting gRPC listener on port %s&quot;, port)\n\tif err := s.Serve(lis); err != nil {\n\t\tlog.Fatalf(&quot;failed serve: %v&quot;, err)\n\t}\n}"},"notes/Температура-запроса-LLM":{"title":"Температура запроса LLM","links":["notes/Температура-запроса-LLM"],"tags":[],"content":"Температура запроса LLM\nОписание:\nПараметр temperature (температура) используется в моделях генерации текста, таких как LLM (Large Language Models), для управления степенью случайности в процессе генерации.\nФункция:\n\nНизкие значения temperature (например, 0.1) приводят к более детерминированным и предсказуемым результатам, где модель выбирает наиболее вероятные слова.\nВысокие значения temperature (например, 1.0 и выше) увеличивают разнообразие и креативность генерируемого текста, позволяя модели делать более рискованные и неожиданные выборы.\n\nПрименение:\n\nНастройка temperature позволяет пользователям контролировать баланс между креативностью и предсказуемостью в сгенерированном контенте, в зависимости от конкретных задач и целей.\n"},"notes/Управление-зависимостями-C++.-CMake":{"title":"Управление зависимостями C++. CMake","links":["notes/Управление-зависимостями-C++.-CMake"],"tags":[],"content":"Управление зависимостями C++. CMake\n\n\n                  \n                  Работает только с проектами которые так же собираются CMake \n                  \n                \n\nМинимальная структура проекта\n.\n├── CMakeLists.txt\n└── src\n    └── hello.cpp\n\nCMakeLists.txt\ncmake_minimum_required(VERSION 3.15)\n \nproject(Tutorial)\n \nadd_executable(${PROJECT_NAME} src/hello.cpp)\n \ninclude(FetchContent)\nFetchContent_Declare(\n    json\n    GIT_REPOSITORY github.com/nlohmann/json.git\n    GIT_TAG v3.11.2 \n)\nFetchContent_Declare(\n    zlib\n    GIT_REPOSITORY github.com/madler/zlib.git\n    GIT_TAG v1.3\n)\nFetchContent_MakeAvailable(json)\nFetchContent_MakeAvailable(zlib)\n \ntarget_link_libraries(${PROJECT_NAME} PRIVATE nlohmann_json::nlohmann_json)\ntarget_link_libraries(${PROJECT_NAME} PRIVATE zlib)\n \nhello.cpp\n#include &lt;iostream&gt;\n#include &lt;zlib.h&gt;\n#include &lt;nlohmann/json.hpp&gt;\nusing json = nlohmann::json;\n \nint main()\n{\n    std::cout &lt;&lt; zlibVersion();\n    std::cout &lt;&lt; &quot;\\n&quot;;\n \n    json ex1 = json::parse(R&quot;(\n    {\n        &quot;pi&quot;: 3.141,\n        &quot;happy&quot;: true\n    }\n)&quot;);\n \n    std::cout &lt;&lt; ex1.contains(&quot;pi2&quot;);\n    std::cout &lt;&lt; &quot;\\n&quot;;\n    std::cout &lt;&lt; ex1;\n    return 0;\n}\n \nСборка\n\nmkdir build &amp;&amp; cd build\ncmake ..\nmake\n"},"notes/Управление-зависимостями-C++.-Conan":{"title":"Управление зависимостями C++. Conan","links":["notes/Управление-зависимостями-C++.-Conan"],"tags":[],"content":"Управление зависимостями C++. Conan\nМинимальная структура проекта\n.\n├── CMakeLists.txt\n├── conanfile.txt\n└── src\n    └── hello.cpp\n\nCMakeLists.txt\ncmake_minimum_required(VERSION 3.15)\n \nproject(Tutorial)\n \nfind_package(ZLIB REQUIRED)\n \nadd_executable(${PROJECT_NAME} src/hello.cpp)\ntarget_link_libraries(${PROJECT_NAME} ZLIB::ZLIB)\nconanfile.txt\n[requires]\nzlib/1.3\n \n[generators]\nCMakeDeps\nCMakeToolchain\nhello.cpp\n#include &lt;iostream&gt;\n#include &lt;zlib.h&gt;\n \nint main()\n{\n    std::cout &lt;&lt; zlibVersion();   \n    return 0;\n}\nСборка\n\nconan install . --output-folder=build --build=missing\ncd build &amp;&amp; cmake .. -DCMAKE_TOOLCHAIN_FILE=conan_toolchain.cmake -DCMAKE_BUILD_TYPE=Release\ncmake --build .\n"},"notes/Установка-GRPC-в-Golang":{"title":"Установка GRPC в Golang","links":["notes/Установка-GRPC-в-Golang"],"tags":["reference/golang"],"content":"Установка GRPC в Golang\nLinux\n$ apt install -y protobuf-compiler\n$ protoc --version  # Ensure compiler version is 3+\nMac OS\n$ brew install protobuf\n$ protoc --version  # Ensure compiler version is 3+\nGolang\n$ go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.28\n$ go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.2"},"notes/Установка-шрифтов-в-Ubuntu":{"title":"Установка шрифтов в Ubuntu","links":["notes/Установка-шрифтов-в-Ubuntu"],"tags":["reference/ubuntu"],"content":"Установка шрифтов в Ubuntu\nSource:: askubuntu.com/questions/3697/how-do-i-install-fonts\n\nMany fonts are packaged for Ubuntu and available via the “Fonts” category of the Ubuntu Software Center. If you prefer apt-get, search for packages starting with otfor ttf-.\nFont files that are placed in the hidden .fonts directory of your home folder will automatically be available (but /etc/fonts/fonts.conf indicates it will be removed soon.). You can also place them in the ~/.local/share/fonts directory on newer versions of Ubuntu per the comments below.\nYou can also double-click on the font file (or select Open with Font Viewer in the right-click menu). Then click the Install Font button.\nIf you need the fonts to be available system-wide, you’ll need to copy them to /usr/local/share/fonts and reboot (or manually rebuild the font cache with fc-cache -f -v).\nYou can confirm they are installed correctly by running fc-list | grep &quot;&quot;\n"},"notes/Учебник-по-awk":{"title":"Учебник по awk","links":["notes/Учебник-по-awk"],"tags":["reference/unix"],"content":"Учебник по awk\n"},"notes/Частичный-коммит-изменений-файла-в-git":{"title":"Частичный коммит изменений файла в git","links":["notes/Squash-commit-in-git"],"tags":["reference/git"],"content":"Для того чтобы в git добавить в следующий коммит только часть изменений осуществленных в файле необходимо добавить его с ключом patch или p в короткой записи:\ngit add -p &lt;filename&gt;\nпосле чего в консоли будет отображаться последовательно все изменения и задаваться вопрос для каждого из них:\nStage this hunk [y,n,q,a,d,/,j,J,g,s,e,?]?\n\nГде:\n\ny - записать изменение\nn - пропустить\na - записать это и все последующие\nd - пропустить это и все последующие\n? - справка по всем остальным клавишам\n\nFriend:: Squash commit in git"}}